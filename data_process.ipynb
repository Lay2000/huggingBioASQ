{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import random\n",
    "\n",
    "with open('/home/aoyuli/Project/AI6127-Group-Project/data/BioASQ-7b/train/Full-Abstract/BioASQ-train-factoid-7b-full-annotated.json', 'r') as f:\n",
    "    factoid_7b = json.load(f)\n",
    "\n",
    "with open('/home/aoyuli/Project/AI6127-Group-Project/data/BioASQ-7b/train/Full-Abstract/BioASQ-train-list-7b-full-annotated.json', 'r') as f:\n",
    "    list_7b = json.load(f)\n",
    "\n",
    "with open('/home/aoyuli/Project/AI6127-Group-Project/data/BioASQ-7b/train/Full-Abstract/BioASQ-train-yesno-7b.json', 'r') as f:\n",
    "    yesno_7b = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5537, 8598, 6676)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factoid_7b['data'][0]['paragraphs']), len(list_7b['data'][0]['paragraphs']), len(yesno_7b['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/aoyuli/Project/AI6127-Group-Project/data/BioASQ-6b/train/Full-Abstract/BioASQ-train-factoid-6b-full-annotated.json', 'r') as f:\n",
    "    factoid_6b = json.load(f)\n",
    "\n",
    "with open('/home/aoyuli/Project/AI6127-Group-Project/data/BioASQ-6b/train/Full-Abstract/BioASQ-train-list-6b-full-annotated.json', 'r') as f:\n",
    "    list_6b = json.load(f)\n",
    "\n",
    "with open('/home/aoyuli/Project/AI6127-Group-Project/data/BioASQ-6b/train/Full-Abstract/BioASQ-train-yesno-6b.json', 'r') as f:\n",
    "    yesno_6b = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4772, 7641, 5921)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factoid_6b['data'][0]['paragraphs']), len(list_6b['data'][0]['paragraphs']), len(yesno_6b['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data1, data2):\n",
    "    merged_data = copy.deepcopy(data1)\n",
    "    merged_data['data'][0]['paragraphs'].extend(data2['data'][0]['paragraphs'])\n",
    "\n",
    "    merged_data['version'] = 'BioASQ'\n",
    "    merged_data['data'][0]['title'] = 'BioASQ'\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "def split_data(data):\n",
    "    paragraphs = data['data'][0]['paragraphs']\n",
    "    total_size = len(paragraphs)\n",
    "    train_size = int(total_size * 0.8)\n",
    "    val_size = int(total_size * 0.1)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # 随机打乱列表顺序\n",
    "    random.seed(1024)\n",
    "    random.shuffle(paragraphs)\n",
    "\n",
    "    print(\"Train size:{}, Val_size:{}, Test_size:{}\".format(train_size, val_size, test_size))\n",
    "\n",
    "    # 使用切片操作将列表分成三个部分\n",
    "    train_paragraphs = paragraphs[:train_size]\n",
    "    val_paragraphs = paragraphs[train_size:train_size+val_size]\n",
    "    test_paragraphs = paragraphs[-test_size:]\n",
    "\n",
    "    train_data = copy.deepcopy(data)\n",
    "    test_data = copy.deepcopy(data)\n",
    "    val_data = copy.deepcopy(data)\n",
    "\n",
    "    train_data['data'][0]['paragraphs'] = train_paragraphs\n",
    "    val_data['data'][0]['paragraphs'] = val_paragraphs\n",
    "    test_data['data'][0]['paragraphs'] = test_paragraphs\n",
    "\n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "factoid_merged = merge_data(factoid_6b, factoid_7b)\n",
    "list_merged = merge_data(list_6b, list_7b)\n",
    "yesno_merged = merge_data(yesno_6b, yesno_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10309, 16239, 12597)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factoid_merged['data'][0]['paragraphs']), len(list_merged['data'][0]['paragraphs']), len(yesno_merged['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [item['qas'][0]['id'] for item in factoid_merged['data'][0]['paragraphs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10309, 5537)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids), len(set(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:4429, Val_size:553, Test_size:555\n",
      "Train size:6878, Val_size:859, Test_size:861\n",
      "Train size:5340, Val_size:667, Test_size:669\n"
     ]
    }
   ],
   "source": [
    "factoid_train, factoid_val, factoid_test = split_data(factoid_7b)\n",
    "list_train, list_val, list_test = split_data(list_7b)\n",
    "yesno_train, yesno_val, yesno_test = split_data(yesno_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/BioASQ/train/BioASQ-train-factoid.json', 'w') as f:\n",
    "    json.dump(factoid_train, f, indent=2)\n",
    "\n",
    "with open('data/BioASQ/val/BioASQ-val-factoid.json', 'w') as f:\n",
    "    json.dump(factoid_val, f, indent=2)\n",
    "\n",
    "with open('data/BioASQ/test/BioASQ-test-factoid.json', 'w') as f:\n",
    "    json.dump(factoid_test, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/BioASQ/train/BioASQ-train-list.json', 'w') as f:\n",
    "    json.dump(list_train, f, indent=2)\n",
    "\n",
    "with open('data/BioASQ/val/BioASQ-val-list.json', 'w') as f:\n",
    "    json.dump(list_val, f, indent=2)\n",
    "\n",
    "with open('data/BioASQ/test/BioASQ-test-list.json', 'w') as f:\n",
    "    json.dump(list_test, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/BioASQ/train/BioASQ-train-yesno.json', 'w') as f:\n",
    "    json.dump(yesno_train, f, indent=2)\n",
    "\n",
    "with open('data/BioASQ/val/BioASQ-val-yesno.json', 'w') as f:\n",
    "    json.dump(yesno_val, f, indent=2)\n",
    "\n",
    "with open('data/BioASQ/test/BioASQ-test-yesno.json', 'w') as f:\n",
    "    json.dump(yesno_test, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
