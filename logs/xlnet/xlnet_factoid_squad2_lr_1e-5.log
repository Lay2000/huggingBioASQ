2023-04-12 13:24:16 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepakvk/xlnet-base-cased-squad2'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 1e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_factoid_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 558.25it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1216.49 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1428.11 examples/s]Map:  68%|██████▊   | 3000/4429 [00:02<00:00, 1477.86 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1509.15 examples/s]Map: 100%|██████████| 4429/4429 [00:03<00:00, 1518.60 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1215.45 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1229.89 examples/s]                                                               2023-04-12 13:25:16 - training - INFO - First Test - Val Metrics:{'exact_match': 0.3616636528028933, 'f1': 4.288024128918328} Test Metrics: {'exact_match': 0.18018018018018017, 'f1': 3.8611520082108313}
2023-04-12 13:25:17 - training - INFO - Epoch [1/5][1/438] lr: 1.0e-05, eta: 1 day, 6:51:06.090542, loss: 6.4757
2023-04-12 13:25:25 - training - INFO - Epoch [1/5][11/438] lr: 9.9e-06, eta: 3:13:05.126343, loss: 5.2995
2023-04-12 13:25:33 - training - INFO - Epoch [1/5][21/438] lr: 9.9e-06, eta: 1:53:55.453839, loss: 4.4850
2023-04-12 13:25:40 - training - INFO - Epoch [1/5][31/438] lr: 9.9e-06, eta: 1:26:03.561555, loss: 4.8438
2023-04-12 13:25:48 - training - INFO - Epoch [1/5][41/438] lr: 9.8e-06, eta: 1:11:29.107438, loss: 3.8897
2023-04-12 13:25:56 - training - INFO - Epoch [1/5][51/438] lr: 9.8e-06, eta: 1:02:43.040028, loss: 4.8794
2023-04-12 13:26:04 - training - INFO - Epoch [1/5][61/438] lr: 9.7e-06, eta: 0:56:40.928470, loss: 3.2691
2023-04-12 13:26:12 - training - INFO - Epoch [1/5][71/438] lr: 9.7e-06, eta: 0:52:36.782369, loss: 3.3669
2023-04-12 13:26:20 - training - INFO - Epoch [1/5][81/438] lr: 9.6e-06, eta: 0:49:15.995490, loss: 3.8787
2023-04-12 13:26:27 - training - INFO - Epoch [1/5][91/438] lr: 9.6e-06, eta: 0:46:32.350076, loss: 2.7731
2023-04-12 13:26:35 - training - INFO - Epoch [1/5][101/438] lr: 9.5e-06, eta: 0:44:25.643382, loss: 3.3582
2023-04-12 13:26:43 - training - INFO - Epoch [1/5][111/438] lr: 9.5e-06, eta: 0:42:44.822799, loss: 3.1719
2023-04-12 13:26:51 - training - INFO - Epoch [1/5][121/438] lr: 9.4e-06, eta: 0:41:13.768815, loss: 3.1041
2023-04-12 13:26:59 - training - INFO - Epoch [1/5][131/438] lr: 9.4e-06, eta: 0:39:56.083008, loss: 2.8218
2023-04-12 13:27:07 - training - INFO - Epoch [1/5][141/438] lr: 9.4e-06, eta: 0:38:48.274602, loss: 2.9198
2023-04-12 13:27:15 - training - INFO - Epoch [1/5][151/438] lr: 9.3e-06, eta: 0:37:53.964165, loss: 2.5405
2023-04-12 13:27:22 - training - INFO - Epoch [1/5][161/438] lr: 9.3e-06, eta: 0:37:00.131800, loss: 2.9938
2023-04-12 13:27:30 - training - INFO - Epoch [1/5][171/438] lr: 9.2e-06, eta: 0:36:09.694122, loss: 2.5512
2023-04-12 13:27:38 - training - INFO - Epoch [1/5][181/438] lr: 9.2e-06, eta: 0:35:24.863048, loss: 2.7229
2023-04-12 13:27:46 - training - INFO - Epoch [1/5][191/438] lr: 9.1e-06, eta: 0:34:46.250353, loss: 2.5964
2023-04-12 13:27:53 - training - INFO - Epoch [1/5][201/438] lr: 9.1e-06, eta: 0:34:07.691412, loss: 2.1075
2023-04-12 13:28:01 - training - INFO - Epoch [1/5][211/438] lr: 9.0e-06, eta: 0:33:32.496554, loss: 1.7827
2023-04-12 13:28:08 - training - INFO - Epoch [1/5][221/438] lr: 9.0e-06, eta: 0:32:59.167916, loss: 2.1438
2023-04-12 13:28:16 - training - INFO - Epoch [1/5][231/438] lr: 8.9e-06, eta: 0:32:30.819216, loss: 1.9026
2023-04-12 13:28:24 - training - INFO - Epoch [1/5][241/438] lr: 8.9e-06, eta: 0:32:02.555968, loss: 2.1029
2023-04-12 13:28:32 - training - INFO - Epoch [1/5][251/438] lr: 8.9e-06, eta: 0:31:35.289123, loss: 1.8310
2023-04-12 13:28:39 - training - INFO - Epoch [1/5][261/438] lr: 8.8e-06, eta: 0:31:10.140423, loss: 1.8786
2023-04-12 13:28:48 - training - INFO - Epoch [1/5][271/438] lr: 8.8e-06, eta: 0:30:49.812374, loss: 2.3471
2023-04-12 13:28:56 - training - INFO - Epoch [1/5][281/438] lr: 8.7e-06, eta: 0:30:29.814680, loss: 1.1918
2023-04-12 13:29:03 - training - INFO - Epoch [1/5][291/438] lr: 8.7e-06, eta: 0:30:08.729136, loss: 1.9530
2023-04-12 13:29:12 - training - INFO - Epoch [1/5][301/438] lr: 8.6e-06, eta: 0:29:50.758777, loss: 2.5168
2023-04-12 13:29:19 - training - INFO - Epoch [1/5][311/438] lr: 8.6e-06, eta: 0:29:31.083393, loss: 2.1765
2023-04-12 13:29:27 - training - INFO - Epoch [1/5][321/438] lr: 8.5e-06, eta: 0:29:11.550171, loss: 1.8135
2023-04-12 13:29:35 - training - INFO - Epoch [1/5][331/438] lr: 8.5e-06, eta: 0:28:52.502486, loss: 2.3229
2023-04-12 13:29:43 - training - INFO - Epoch [1/5][341/438] lr: 8.4e-06, eta: 0:28:36.391569, loss: 2.7309
2023-04-12 13:29:50 - training - INFO - Epoch [1/5][351/438] lr: 8.4e-06, eta: 0:28:18.224550, loss: 1.9956
2023-04-12 13:29:58 - training - INFO - Epoch [1/5][361/438] lr: 8.4e-06, eta: 0:28:01.668563, loss: 2.0402
2023-04-12 13:30:06 - training - INFO - Epoch [1/5][371/438] lr: 8.3e-06, eta: 0:27:45.343613, loss: 1.4446
2023-04-12 13:30:14 - training - INFO - Epoch [1/5][381/438] lr: 8.3e-06, eta: 0:27:30.580443, loss: 1.8652
2023-04-12 13:30:22 - training - INFO - Epoch [1/5][391/438] lr: 8.2e-06, eta: 0:27:15.846891, loss: 1.9349
2023-04-12 13:30:29 - training - INFO - Epoch [1/5][401/438] lr: 8.2e-06, eta: 0:26:59.978858, loss: 1.7934
2023-04-12 13:30:37 - training - INFO - Epoch [1/5][411/438] lr: 8.1e-06, eta: 0:26:44.259504, loss: 1.0427
2023-04-12 13:30:45 - training - INFO - Epoch [1/5][421/438] lr: 8.1e-06, eta: 0:26:30.125796, loss: 1.5871
2023-04-12 13:30:53 - training - INFO - Epoch [1/5][431/438] lr: 8.0e-06, eta: 0:26:16.285634, loss: 1.4782
2023-04-12 13:31:48 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 2.6112, Validation Metrics: {'exact_match': 52.260397830018086, 'f1': 58.22273307798401}, Test Metrics: {'exact_match': 53.513513513513516, 'f1': 61.15215647632037}
2023-04-12 13:31:48 - training - INFO - Epoch [2/5][1/438] lr: 8.0e-06, eta: 11 days, 4:49:00.081913, loss: 1.0593
2023-04-12 13:31:56 - training - INFO - Epoch [2/5][11/438] lr: 7.9e-06, eta: 1 day, 0:44:55.533793, loss: 1.5992
2023-04-12 13:32:04 - training - INFO - Epoch [2/5][21/438] lr: 7.9e-06, eta: 13:07:19.683444, loss: 1.2547
2023-04-12 13:32:12 - training - INFO - Epoch [2/5][31/438] lr: 7.9e-06, eta: 9:00:07.736429, loss: 0.9032
2023-04-12 13:32:20 - training - INFO - Epoch [2/5][41/438] lr: 7.8e-06, eta: 6:53:34.971482, loss: 1.6592
2023-04-12 13:32:28 - training - INFO - Epoch [2/5][51/438] lr: 7.8e-06, eta: 5:36:26.662770, loss: 1.6500
2023-04-12 13:32:36 - training - INFO - Epoch [2/5][61/438] lr: 7.7e-06, eta: 4:44:35.395407, loss: 1.5216
2023-04-12 13:32:44 - training - INFO - Epoch [2/5][71/438] lr: 7.7e-06, eta: 4:07:30.307992, loss: 1.3420
2023-04-12 13:32:52 - training - INFO - Epoch [2/5][81/438] lr: 7.6e-06, eta: 3:39:17.374011, loss: 1.5838
2023-04-12 13:32:59 - training - INFO - Epoch [2/5][91/438] lr: 7.6e-06, eta: 3:17:11.229697, loss: 1.6365
2023-04-12 13:33:07 - training - INFO - Epoch [2/5][101/438] lr: 7.5e-06, eta: 2:59:34.660912, loss: 1.3520
2023-04-12 13:33:16 - training - INFO - Epoch [2/5][111/438] lr: 7.5e-06, eta: 2:45:15.254118, loss: 1.3156
2023-04-12 13:33:24 - training - INFO - Epoch [2/5][121/438] lr: 7.4e-06, eta: 2:33:14.832555, loss: 1.8067
2023-04-12 13:33:32 - training - INFO - Epoch [2/5][131/438] lr: 7.4e-06, eta: 2:22:51.244321, loss: 0.8042
2023-04-12 13:33:39 - training - INFO - Epoch [2/5][141/438] lr: 7.4e-06, eta: 2:13:58.190118, loss: 2.1731
2023-04-12 13:33:47 - training - INFO - Epoch [2/5][151/438] lr: 7.3e-06, eta: 2:06:13.690146, loss: 1.1966
2023-04-12 13:33:55 - training - INFO - Epoch [2/5][161/438] lr: 7.3e-06, eta: 1:59:24.950888, loss: 1.9473
2023-04-12 13:34:03 - training - INFO - Epoch [2/5][171/438] lr: 7.2e-06, eta: 1:53:22.996272, loss: 1.1411
2023-04-12 13:34:11 - training - INFO - Epoch [2/5][181/438] lr: 7.2e-06, eta: 1:48:08.037374, loss: 2.0434
2023-04-12 13:34:19 - training - INFO - Epoch [2/5][191/438] lr: 7.1e-06, eta: 1:43:20.460219, loss: 1.1593
2023-04-12 13:34:27 - training - INFO - Epoch [2/5][201/438] lr: 7.1e-06, eta: 1:38:59.740755, loss: 1.2549
2023-04-12 13:34:34 - training - INFO - Epoch [2/5][211/438] lr: 7.0e-06, eta: 1:35:01.681068, loss: 1.4906
2023-04-12 13:34:42 - training - INFO - Epoch [2/5][221/438] lr: 7.0e-06, eta: 1:31:28.682012, loss: 1.2796
2023-04-12 13:34:50 - training - INFO - Epoch [2/5][231/438] lr: 6.9e-06, eta: 1:28:09.560547, loss: 1.2070
2023-04-12 13:34:58 - training - INFO - Epoch [2/5][241/438] lr: 6.9e-06, eta: 1:25:06.461858, loss: 1.5055
2023-04-12 13:35:06 - training - INFO - Epoch [2/5][251/438] lr: 6.9e-06, eta: 1:22:18.169579, loss: 1.8910
2023-04-12 13:35:14 - training - INFO - Epoch [2/5][261/438] lr: 6.8e-06, eta: 1:19:44.330877, loss: 1.2416
2023-04-12 13:35:21 - training - INFO - Epoch [2/5][271/438] lr: 6.8e-06, eta: 1:17:18.309355, loss: 1.0776
2023-04-12 13:35:29 - training - INFO - Epoch [2/5][281/438] lr: 6.7e-06, eta: 1:15:04.434402, loss: 1.8033
2023-04-12 13:35:37 - training - INFO - Epoch [2/5][291/438] lr: 6.7e-06, eta: 1:12:59.732064, loss: 1.5765
2023-04-12 13:35:46 - training - INFO - Epoch [2/5][301/438] lr: 6.6e-06, eta: 1:11:03.304879, loss: 1.0379
2023-04-12 13:35:53 - training - INFO - Epoch [2/5][311/438] lr: 6.6e-06, eta: 1:09:10.447940, loss: 1.6038
2023-04-12 13:36:01 - training - INFO - Epoch [2/5][321/438] lr: 6.5e-06, eta: 1:07:25.889715, loss: 1.6998
2023-04-12 13:36:09 - training - INFO - Epoch [2/5][331/438] lr: 6.5e-06, eta: 1:05:46.751809, loss: 1.7681
2023-04-12 13:36:17 - training - INFO - Epoch [2/5][341/438] lr: 6.4e-06, eta: 1:04:14.869160, loss: 1.3005
2023-04-12 13:36:25 - training - INFO - Epoch [2/5][351/438] lr: 6.4e-06, eta: 1:02:45.852708, loss: 1.5818
2023-04-12 13:36:33 - training - INFO - Epoch [2/5][361/438] lr: 6.4e-06, eta: 1:01:20.922857, loss: 1.3549
2023-04-12 13:36:41 - training - INFO - Epoch [2/5][371/438] lr: 6.3e-06, eta: 1:00:03.098847, loss: 1.9623
2023-04-12 13:36:49 - training - INFO - Epoch [2/5][381/438] lr: 6.3e-06, eta: 0:58:46.057575, loss: 0.9926
2023-04-12 13:36:57 - training - INFO - Epoch [2/5][391/438] lr: 6.2e-06, eta: 0:57:32.768529, loss: 1.2464
2023-04-12 13:37:05 - training - INFO - Epoch [2/5][401/438] lr: 6.2e-06, eta: 0:56:23.609049, loss: 1.1853
2023-04-12 13:37:12 - training - INFO - Epoch [2/5][411/438] lr: 6.1e-06, eta: 0:55:16.216110, loss: 0.9698
2023-04-12 13:37:20 - training - INFO - Epoch [2/5][421/438] lr: 6.1e-06, eta: 0:54:12.198591, loss: 1.4677
2023-04-12 13:37:28 - training - INFO - Epoch [2/5][431/438] lr: 6.0e-06, eta: 0:53:10.836554, loss: 1.5516
2023-04-12 13:38:23 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.4517, Validation Metrics: {'exact_match': 46.835443037974684, 'f1': 52.21394370990268}, Test Metrics: {'exact_match': 50.810810810810814, 'f1': 55.948512861457004}
2023-04-12 13:38:24 - training - INFO - Epoch [3/5][1/438] lr: 6.0e-06, eta: 21 days, 5:04:39.940861, loss: 0.9320
2023-04-12 13:38:31 - training - INFO - Epoch [3/5][11/438] lr: 5.9e-06, eta: 1 day, 22:29:21.747004, loss: 1.0127
2023-04-12 13:38:39 - training - INFO - Epoch [3/5][21/438] lr: 5.9e-06, eta: 1 day, 0:27:55.780470, loss: 1.4194
2023-04-12 13:38:47 - training - INFO - Epoch [3/5][31/438] lr: 5.9e-06, eta: 16:38:48.144558, loss: 1.2504
2023-04-12 13:38:54 - training - INFO - Epoch [3/5][41/438] lr: 5.8e-06, eta: 12:38:16.766966, loss: 0.6622
2023-04-12 13:39:02 - training - INFO - Epoch [3/5][51/438] lr: 5.8e-06, eta: 10:12:17.566707, loss: 1.3888
2023-04-12 13:39:10 - training - INFO - Epoch [3/5][61/438] lr: 5.7e-06, eta: 8:34:17.902707, loss: 1.4988
2023-04-12 13:39:18 - training - INFO - Epoch [3/5][71/438] lr: 5.7e-06, eta: 7:23:30.264265, loss: 1.2922
2023-04-12 13:39:26 - training - INFO - Epoch [3/5][81/438] lr: 5.6e-06, eta: 6:30:18.578535, loss: 0.7292
2023-04-12 13:39:33 - training - INFO - Epoch [3/5][91/438] lr: 5.6e-06, eta: 5:48:41.469749, loss: 1.3964
2023-04-12 13:39:41 - training - INFO - Epoch [3/5][101/438] lr: 5.5e-06, eta: 5:15:20.935757, loss: 1.7147
2023-04-12 13:39:49 - training - INFO - Epoch [3/5][111/438] lr: 5.5e-06, eta: 4:48:02.552364, loss: 1.6699
2023-04-12 13:39:57 - training - INFO - Epoch [3/5][121/438] lr: 5.4e-06, eta: 4:25:15.556979, loss: 1.2235
2023-04-12 13:40:05 - training - INFO - Epoch [3/5][131/438] lr: 5.4e-06, eta: 4:05:50.614230, loss: 1.3722
2023-04-12 13:40:12 - training - INFO - Epoch [3/5][141/438] lr: 5.4e-06, eta: 3:49:09.130134, loss: 0.7190
2023-04-12 13:40:20 - training - INFO - Epoch [3/5][151/438] lr: 5.3e-06, eta: 3:34:39.900147, loss: 1.0487
2023-04-12 13:40:28 - training - INFO - Epoch [3/5][161/438] lr: 5.3e-06, eta: 3:22:01.576727, loss: 1.1883
2023-04-12 13:40:36 - training - INFO - Epoch [3/5][171/438] lr: 5.2e-06, eta: 3:10:47.798646, loss: 1.0591
2023-04-12 13:40:44 - training - INFO - Epoch [3/5][181/438] lr: 5.2e-06, eta: 3:00:50.831999, loss: 1.0310
2023-04-12 13:40:52 - training - INFO - Epoch [3/5][191/438] lr: 5.1e-06, eta: 2:51:56.842998, loss: 1.6165
2023-04-12 13:41:00 - training - INFO - Epoch [3/5][201/438] lr: 5.1e-06, eta: 2:43:55.541352, loss: 1.0801
2023-04-12 13:41:09 - training - INFO - Epoch [3/5][211/438] lr: 5.0e-06, eta: 2:36:40.139176, loss: 1.5097
2023-04-12 13:41:16 - training - INFO - Epoch [3/5][221/438] lr: 5.0e-06, eta: 2:29:58.897072, loss: 1.4462
2023-04-12 13:41:24 - training - INFO - Epoch [3/5][231/438] lr: 4.9e-06, eta: 2:23:51.790857, loss: 1.0691
2023-04-12 13:41:32 - training - INFO - Epoch [3/5][241/438] lr: 4.9e-06, eta: 2:18:13.661558, loss: 1.1106
2023-04-12 13:41:40 - training - INFO - Epoch [3/5][251/438] lr: 4.9e-06, eta: 2:13:04.160191, loss: 1.6394
2023-04-12 13:41:48 - training - INFO - Epoch [3/5][261/438] lr: 4.8e-06, eta: 2:08:16.017489, loss: 0.8823
2023-04-12 13:41:56 - training - INFO - Epoch [3/5][271/438] lr: 4.8e-06, eta: 2:03:49.819166, loss: 0.9042
2023-04-12 13:42:03 - training - INFO - Epoch [3/5][281/438] lr: 4.7e-06, eta: 1:59:40.155617, loss: 1.1770
2023-04-12 13:42:11 - training - INFO - Epoch [3/5][291/438] lr: 4.7e-06, eta: 1:55:50.153898, loss: 1.2977
2023-04-12 13:42:19 - training - INFO - Epoch [3/5][301/438] lr: 4.6e-06, eta: 1:52:13.799527, loss: 1.8013
2023-04-12 13:42:27 - training - INFO - Epoch [3/5][311/438] lr: 4.6e-06, eta: 1:48:50.199561, loss: 1.2828
2023-04-12 13:42:35 - training - INFO - Epoch [3/5][321/438] lr: 4.5e-06, eta: 1:45:39.365781, loss: 1.9749
2023-04-12 13:42:44 - training - INFO - Epoch [3/5][331/438] lr: 4.5e-06, eta: 1:42:42.404677, loss: 0.8505
2023-04-12 13:42:52 - training - INFO - Epoch [3/5][341/438] lr: 4.4e-06, eta: 1:39:53.735041, loss: 1.5492
2023-04-12 13:42:59 - training - INFO - Epoch [3/5][351/438] lr: 4.4e-06, eta: 1:37:12.059319, loss: 0.7936
2023-04-12 13:43:07 - training - INFO - Epoch [3/5][361/438] lr: 4.4e-06, eta: 1:34:37.773845, loss: 0.9532
2023-04-12 13:43:15 - training - INFO - Epoch [3/5][371/438] lr: 4.3e-06, eta: 1:32:12.433930, loss: 1.5936
2023-04-12 13:43:22 - training - INFO - Epoch [3/5][381/438] lr: 4.3e-06, eta: 1:29:54.479607, loss: 1.6283
2023-04-12 13:43:30 - training - INFO - Epoch [3/5][391/438] lr: 4.2e-06, eta: 1:27:43.283928, loss: 0.7690
2023-04-12 13:43:38 - training - INFO - Epoch [3/5][401/438] lr: 4.2e-06, eta: 1:25:37.129601, loss: 1.4602
2023-04-12 13:43:45 - training - INFO - Epoch [3/5][411/438] lr: 4.1e-06, eta: 1:23:36.902751, loss: 0.8854
2023-04-12 13:43:53 - training - INFO - Epoch [3/5][421/438] lr: 4.1e-06, eta: 1:21:42.992242, loss: 0.8516
2023-04-12 13:44:01 - training - INFO - Epoch [3/5][431/438] lr: 4.0e-06, eta: 1:19:54.555552, loss: 0.8025
2023-04-12 13:44:55 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.2054, Validation Metrics: {'exact_match': 49.36708860759494, 'f1': 55.13307210663717}, Test Metrics: {'exact_match': 53.153153153153156, 'f1': 57.68229175709635}
2023-04-12 13:44:56 - training - INFO - Epoch [4/5][1/438] lr: 4.0e-06, eta: 31 days, 3:41:05.925575, loss: 0.8880
2023-04-12 13:45:03 - training - INFO - Epoch [4/5][11/438] lr: 3.9e-06, eta: 2 days, 20:04:22.344111, loss: 1.1072
2023-04-12 13:45:11 - training - INFO - Epoch [4/5][21/438] lr: 3.9e-06, eta: 1 day, 11:42:36.076905, loss: 1.1410
2023-04-12 13:45:19 - training - INFO - Epoch [4/5][31/438] lr: 3.9e-06, eta: 1 day, 0:13:36.414848, loss: 1.0288
2023-04-12 13:45:26 - training - INFO - Epoch [4/5][41/438] lr: 3.8e-06, eta: 18:20:49.289355, loss: 0.7996
2023-04-12 13:45:35 - training - INFO - Epoch [4/5][51/438] lr: 3.8e-06, eta: 14:46:30.996414, loss: 0.8242
2023-04-12 13:45:42 - training - INFO - Epoch [4/5][61/438] lr: 3.7e-06, eta: 12:22:15.759012, loss: 1.0991
2023-04-12 13:45:50 - training - INFO - Epoch [4/5][71/438] lr: 3.7e-06, eta: 10:38:41.727223, loss: 0.7220
2023-04-12 13:45:58 - training - INFO - Epoch [4/5][81/438] lr: 3.6e-06, eta: 9:20:33.924963, loss: 0.6672
2023-04-12 13:46:06 - training - INFO - Epoch [4/5][91/438] lr: 3.6e-06, eta: 8:19:30.265046, loss: 1.2062
2023-04-12 13:46:13 - training - INFO - Epoch [4/5][101/438] lr: 3.5e-06, eta: 7:30:35.322017, loss: 0.9375
2023-04-12 13:46:21 - training - INFO - Epoch [4/5][111/438] lr: 3.5e-06, eta: 6:50:30.260193, loss: 0.8291
2023-04-12 13:46:29 - training - INFO - Epoch [4/5][121/438] lr: 3.4e-06, eta: 6:16:54.956220, loss: 0.5015
2023-04-12 13:46:37 - training - INFO - Epoch [4/5][131/438] lr: 3.4e-06, eta: 5:48:32.803843, loss: 0.7839
2023-04-12 13:46:45 - training - INFO - Epoch [4/5][141/438] lr: 3.4e-06, eta: 5:24:06.511917, loss: 1.6568
2023-04-12 13:46:52 - training - INFO - Epoch [4/5][151/438] lr: 3.3e-06, eta: 5:02:53.908772, loss: 0.4942
2023-04-12 13:47:00 - training - INFO - Epoch [4/5][161/438] lr: 3.3e-06, eta: 4:44:16.569368, loss: 1.0965
2023-04-12 13:47:07 - training - INFO - Epoch [4/5][171/438] lr: 3.2e-06, eta: 4:27:50.297127, loss: 0.9498
2023-04-12 13:47:15 - training - INFO - Epoch [4/5][181/438] lr: 3.2e-06, eta: 4:13:12.188585, loss: 0.9973
2023-04-12 13:47:23 - training - INFO - Epoch [4/5][191/438] lr: 3.1e-06, eta: 4:00:05.877458, loss: 1.4168
2023-04-12 13:47:31 - training - INFO - Epoch [4/5][201/438] lr: 3.1e-06, eta: 3:48:18.738261, loss: 1.0794
2023-04-12 13:47:38 - training - INFO - Epoch [4/5][211/438] lr: 3.0e-06, eta: 3:37:36.579156, loss: 1.5937
2023-04-12 13:47:46 - training - INFO - Epoch [4/5][221/438] lr: 3.0e-06, eta: 3:27:52.738795, loss: 0.8127
2023-04-12 13:47:54 - training - INFO - Epoch [4/5][231/438] lr: 2.9e-06, eta: 3:18:59.156844, loss: 0.7218
2023-04-12 13:48:02 - training - INFO - Epoch [4/5][241/438] lr: 2.9e-06, eta: 3:10:49.281611, loss: 1.0936
2023-04-12 13:48:10 - training - INFO - Epoch [4/5][251/438] lr: 2.9e-06, eta: 3:03:16.986147, loss: 0.8128
2023-04-12 13:48:17 - training - INFO - Epoch [4/5][261/438] lr: 2.8e-06, eta: 2:56:17.320422, loss: 0.5923
2023-04-12 13:48:25 - training - INFO - Epoch [4/5][271/438] lr: 2.8e-06, eta: 2:49:47.853941, loss: 1.2432
2023-04-12 13:48:33 - training - INFO - Epoch [4/5][281/438] lr: 2.7e-06, eta: 2:43:45.762357, loss: 1.0496
2023-04-12 13:48:41 - training - INFO - Epoch [4/5][291/438] lr: 2.7e-06, eta: 2:38:10.045509, loss: 0.6081
2023-04-12 13:48:48 - training - INFO - Epoch [4/5][301/438] lr: 2.6e-06, eta: 2:32:55.162017, loss: 1.3833
2023-04-12 13:48:56 - training - INFO - Epoch [4/5][311/438] lr: 2.6e-06, eta: 2:27:59.231411, loss: 1.1685
2023-04-12 13:49:04 - training - INFO - Epoch [4/5][321/438] lr: 2.5e-06, eta: 2:23:21.384708, loss: 1.2341
2023-04-12 13:49:12 - training - INFO - Epoch [4/5][331/438] lr: 2.5e-06, eta: 2:19:01.745698, loss: 1.3746
2023-04-12 13:49:19 - training - INFO - Epoch [4/5][341/438] lr: 2.4e-06, eta: 2:14:54.901661, loss: 1.5676
2023-04-12 13:49:27 - training - INFO - Epoch [4/5][351/438] lr: 2.4e-06, eta: 2:11:02.841273, loss: 1.0468
2023-04-12 13:49:35 - training - INFO - Epoch [4/5][361/438] lr: 2.4e-06, eta: 2:07:23.259312, loss: 0.9741
2023-04-12 13:49:43 - training - INFO - Epoch [4/5][371/438] lr: 2.3e-06, eta: 2:03:55.997421, loss: 0.9750
2023-04-12 13:49:51 - training - INFO - Epoch [4/5][381/438] lr: 2.3e-06, eta: 2:00:37.608201, loss: 0.9400
2023-04-12 13:49:59 - training - INFO - Epoch [4/5][391/438] lr: 2.2e-06, eta: 1:57:29.888818, loss: 1.1366
2023-04-12 13:50:07 - training - INFO - Epoch [4/5][401/438] lr: 2.2e-06, eta: 1:54:32.006984, loss: 0.9182
2023-04-12 13:50:15 - training - INFO - Epoch [4/5][411/438] lr: 2.1e-06, eta: 1:51:41.923518, loss: 0.9893
2023-04-12 13:50:23 - training - INFO - Epoch [4/5][421/438] lr: 2.1e-06, eta: 1:49:00.417560, loss: 1.0610
2023-04-12 13:50:31 - training - INFO - Epoch [4/5][431/438] lr: 2.0e-06, eta: 1:46:23.783908, loss: 0.6973
2023-04-12 13:51:26 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 1.0642, Validation Metrics: {'exact_match': 56.962025316455694, 'f1': 61.40662992283182}, Test Metrics: {'exact_match': 60.54054054054054, 'f1': 64.18394637648537}
2023-04-12 13:51:26 - training - INFO - Epoch [5/5][1/438] lr: 2.0e-06, eta: 41 days, 1:07:12.107130, loss: 1.1318
2023-04-12 13:51:34 - training - INFO - Epoch [5/5][11/438] lr: 1.9e-06, eta: 3 days, 17:34:48.367607, loss: 0.6148
2023-04-12 13:51:42 - training - INFO - Epoch [5/5][21/438] lr: 1.9e-06, eta: 1 day, 22:56:08.394711, loss: 1.0305
2023-04-12 13:51:50 - training - INFO - Epoch [5/5][31/438] lr: 1.9e-06, eta: 1 day, 7:47:57.231294, loss: 0.9053
2023-04-12 13:51:58 - training - INFO - Epoch [5/5][41/438] lr: 1.8e-06, eta: 1 day, 0:02:36.384033, loss: 0.7506
2023-04-12 13:52:05 - training - INFO - Epoch [5/5][51/438] lr: 1.8e-06, eta: 19:19:38.570589, loss: 0.7288
2023-04-12 13:52:13 - training - INFO - Epoch [5/5][61/438] lr: 1.7e-06, eta: 16:09:29.112830, loss: 0.5657
2023-04-12 13:52:21 - training - INFO - Epoch [5/5][71/438] lr: 1.7e-06, eta: 13:52:49.045932, loss: 1.3815
2023-04-12 13:52:28 - training - INFO - Epoch [5/5][81/438] lr: 1.6e-06, eta: 12:09:49.884060, loss: 0.8861
2023-04-12 13:52:36 - training - INFO - Epoch [5/5][91/438] lr: 1.6e-06, eta: 10:49:25.342735, loss: 1.5112
2023-04-12 13:52:44 - training - INFO - Epoch [5/5][101/438] lr: 1.5e-06, eta: 9:45:09.179588, loss: 0.8205
2023-04-12 13:52:51 - training - INFO - Epoch [5/5][111/438] lr: 1.5e-06, eta: 8:52:16.772637, loss: 1.0038
2023-04-12 13:52:59 - training - INFO - Epoch [5/5][121/438] lr: 1.4e-06, eta: 8:08:05.004627, loss: 0.9677
2023-04-12 13:53:07 - training - INFO - Epoch [5/5][131/438] lr: 1.4e-06, eta: 7:30:39.420113, loss: 0.7342
2023-04-12 13:53:14 - training - INFO - Epoch [5/5][141/438] lr: 1.4e-06, eta: 6:58:33.070593, loss: 0.9494
2023-04-12 13:53:22 - training - INFO - Epoch [5/5][151/438] lr: 1.3e-06, eta: 6:30:38.684254, loss: 1.1394
2023-04-12 13:53:30 - training - INFO - Epoch [5/5][161/438] lr: 1.3e-06, eta: 6:06:10.965630, loss: 1.2027
2023-04-12 13:53:37 - training - INFO - Epoch [5/5][171/438] lr: 1.2e-06, eta: 5:44:35.127339, loss: 0.6780
2023-04-12 13:53:45 - training - INFO - Epoch [5/5][181/438] lr: 1.2e-06, eta: 5:25:22.017529, loss: 0.8972
2023-04-12 13:53:53 - training - INFO - Epoch [5/5][191/438] lr: 1.1e-06, eta: 5:08:06.336208, loss: 0.8211
2023-04-12 13:54:00 - training - INFO - Epoch [5/5][201/438] lr: 1.1e-06, eta: 4:52:35.870709, loss: 1.0477
2023-04-12 13:54:08 - training - INFO - Epoch [5/5][211/438] lr: 1.0e-06, eta: 4:38:31.568529, loss: 0.9536
2023-04-12 13:54:16 - training - INFO - Epoch [5/5][221/438] lr: 9.9e-07, eta: 4:25:45.660995, loss: 1.5349
2023-04-12 13:54:24 - training - INFO - Epoch [5/5][231/438] lr: 9.5e-07, eta: 4:14:02.369751, loss: 0.8455
2023-04-12 13:54:31 - training - INFO - Epoch [5/5][241/438] lr: 9.0e-07, eta: 4:03:17.134899, loss: 1.0241
2023-04-12 13:54:39 - training - INFO - Epoch [5/5][251/438] lr: 8.5e-07, eta: 3:53:22.878239, loss: 1.2551
2023-04-12 13:54:47 - training - INFO - Epoch [5/5][261/438] lr: 8.1e-07, eta: 3:44:15.994128, loss: 0.8114
2023-04-12 13:54:55 - training - INFO - Epoch [5/5][271/438] lr: 7.6e-07, eta: 3:35:45.645003, loss: 0.8415
2023-04-12 13:55:02 - training - INFO - Epoch [5/5][281/438] lr: 7.2e-07, eta: 3:27:51.909344, loss: 1.1383
2023-04-12 13:55:10 - training - INFO - Epoch [5/5][291/438] lr: 6.7e-07, eta: 3:20:33.778797, loss: 0.4961
2023-04-12 13:55:18 - training - INFO - Epoch [5/5][301/438] lr: 6.3e-07, eta: 3:13:41.949715, loss: 0.9943
2023-04-12 13:55:26 - training - INFO - Epoch [5/5][311/438] lr: 5.8e-07, eta: 3:07:17.506062, loss: 1.7205
2023-04-12 13:55:34 - training - INFO - Epoch [5/5][321/438] lr: 5.3e-07, eta: 3:01:13.559781, loss: 0.8297
2023-04-12 13:55:42 - training - INFO - Epoch [5/5][331/438] lr: 4.9e-07, eta: 2:55:33.612661, loss: 0.7119
2023-04-12 13:55:50 - training - INFO - Epoch [5/5][341/438] lr: 4.4e-07, eta: 2:50:12.359820, loss: 1.0864
2023-04-12 13:55:57 - training - INFO - Epoch [5/5][351/438] lr: 4.0e-07, eta: 2:45:08.305803, loss: 1.3617
2023-04-12 13:56:06 - training - INFO - Epoch [5/5][361/438] lr: 3.5e-07, eta: 2:40:22.963425, loss: 2.1447
2023-04-12 13:56:14 - training - INFO - Epoch [5/5][371/438] lr: 3.1e-07, eta: 2:35:51.062449, loss: 0.8461
2023-04-12 13:56:21 - training - INFO - Epoch [5/5][381/438] lr: 2.6e-07, eta: 2:31:32.158821, loss: 0.6855
2023-04-12 13:56:29 - training - INFO - Epoch [5/5][391/438] lr: 2.1e-07, eta: 2:27:26.553716, loss: 0.9312
2023-04-12 13:56:37 - training - INFO - Epoch [5/5][401/438] lr: 1.7e-07, eta: 2:23:32.993802, loss: 1.1452
2023-04-12 13:56:45 - training - INFO - Epoch [5/5][411/438] lr: 1.2e-07, eta: 2:19:50.000607, loss: 1.0609
2023-04-12 13:56:52 - training - INFO - Epoch [5/5][421/438] lr: 7.8e-08, eta: 2:16:17.244956, loss: 0.7035
2023-04-12 13:57:00 - training - INFO - Epoch [5/5][431/438] lr: 3.2e-08, eta: 2:12:53.459050, loss: 1.3765
2023-04-12 13:57:56 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.9970, Validation Metrics: {'exact_match': 54.249547920434, 'f1': 58.44748396228677}, Test Metrics: {'exact_match': 58.01801801801802, 'f1': 61.19813132370599}
2023-04-12 13:58:22 - training - INFO - Final Test - Train Loss: 0.9970, Test Metrics: {'exact_match': 58.01801801801802, 'f1': 61.19813132370599}
