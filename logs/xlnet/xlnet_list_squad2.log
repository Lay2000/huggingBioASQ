2023-04-12 19:12:08 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-44a167365c0b341b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepakvk/xlnet-base-cased-squad2'}, 'data': {'task_type': 'list', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_list_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 596.04it/s]
Map:   0%|          | 0/6878 [00:00<?, ? examples/s]Map:  15%|█▍        | 1000/6878 [00:00<00:04, 1405.02 examples/s]Map:  29%|██▉       | 2000/6878 [00:01<00:03, 1470.67 examples/s]Map:  44%|████▎     | 3000/6878 [00:02<00:02, 1478.12 examples/s]Map:  58%|█████▊    | 4000/6878 [00:02<00:01, 1463.68 examples/s]Map:  73%|███████▎  | 5000/6878 [00:03<00:01, 1493.43 examples/s]Map:  87%|████████▋ | 6000/6878 [00:04<00:00, 1499.24 examples/s]Map: 100%|██████████| 6878/6878 [00:04<00:00, 1415.39 examples/s]                                                                 Map:   0%|          | 0/859 [00:00<?, ? examples/s]Map: 100%|██████████| 859/859 [00:00<00:00, 1222.68 examples/s]                                                               Map:   0%|          | 0/861 [00:00<?, ? examples/s]Map: 100%|██████████| 861/861 [00:00<00:00, 1228.14 examples/s]                                                               2023-04-12 19:13:36 - training - INFO - First Test - Val Metrics:{'exact_match': 0.46565774155995343, 'f1': 2.111707080855453} Test Metrics: {'exact_match': 0.4645760743321719, 'f1': 2.558276426289279}
2023-04-12 19:13:37 - training - INFO - Epoch [1/5][1/690] lr: 4.5e-05, eta: 3 days, 1:09:53.894208, loss: 6.8472
2023-04-12 19:13:45 - training - INFO - Epoch [1/5][11/690] lr: 4.5e-05, eta: 7:17:45.967764, loss: 4.4758
2023-04-12 19:13:53 - training - INFO - Epoch [1/5][21/690] lr: 4.5e-05, eta: 4:10:15.789882, loss: 3.5219
2023-04-12 19:14:01 - training - INFO - Epoch [1/5][31/690] lr: 4.5e-05, eta: 3:04:07.127481, loss: 3.5997
2023-04-12 19:14:09 - training - INFO - Epoch [1/5][41/690] lr: 4.5e-05, eta: 2:29:57.520287, loss: 3.5511
2023-04-12 19:14:17 - training - INFO - Epoch [1/5][51/690] lr: 4.5e-05, eta: 2:09:01.599789, loss: 2.2772
2023-04-12 19:14:25 - training - INFO - Epoch [1/5][61/690] lr: 4.5e-05, eta: 1:54:55.771139, loss: 2.6528
2023-04-12 19:14:32 - training - INFO - Epoch [1/5][71/690] lr: 4.4e-05, eta: 1:44:35.897796, loss: 2.5728
2023-04-12 19:14:41 - training - INFO - Epoch [1/5][81/690] lr: 4.4e-05, eta: 1:37:05.772501, loss: 2.2692
2023-04-12 19:14:48 - training - INFO - Epoch [1/5][91/690] lr: 4.4e-05, eta: 1:30:54.720408, loss: 2.0784
2023-04-12 19:14:57 - training - INFO - Epoch [1/5][101/690] lr: 4.4e-05, eta: 1:26:18.833318, loss: 2.7065
2023-04-12 19:15:05 - training - INFO - Epoch [1/5][111/690] lr: 4.4e-05, eta: 1:22:15.586257, loss: 2.9293
2023-04-12 19:15:14 - training - INFO - Epoch [1/5][121/690] lr: 4.4e-05, eta: 1:19:21.581886, loss: 2.1135
2023-04-12 19:15:21 - training - INFO - Epoch [1/5][131/690] lr: 4.4e-05, eta: 1:16:20.153620, loss: 2.0994
2023-04-12 19:15:29 - training - INFO - Epoch [1/5][141/690] lr: 4.4e-05, eta: 1:13:40.737966, loss: 2.2031
2023-04-12 19:15:37 - training - INFO - Epoch [1/5][151/690] lr: 4.3e-05, eta: 1:11:21.402612, loss: 2.0714
2023-04-12 19:15:44 - training - INFO - Epoch [1/5][161/690] lr: 4.3e-05, eta: 1:09:19.404249, loss: 2.5230
2023-04-12 19:15:52 - training - INFO - Epoch [1/5][171/690] lr: 4.3e-05, eta: 1:07:28.079613, loss: 2.5403
2023-04-12 19:15:59 - training - INFO - Epoch [1/5][181/690] lr: 4.3e-05, eta: 1:05:51.112809, loss: 2.7192
2023-04-12 19:16:07 - training - INFO - Epoch [1/5][191/690] lr: 4.3e-05, eta: 1:04:21.269718, loss: 2.7255
2023-04-12 19:16:15 - training - INFO - Epoch [1/5][201/690] lr: 4.3e-05, eta: 1:03:01.982205, loss: 2.0009
2023-04-12 19:16:22 - training - INFO - Epoch [1/5][211/690] lr: 4.3e-05, eta: 1:01:51.353087, loss: 1.4638
2023-04-12 19:16:30 - training - INFO - Epoch [1/5][221/690] lr: 4.2e-05, eta: 1:00:43.726302, loss: 2.3844
2023-04-12 19:16:38 - training - INFO - Epoch [1/5][231/690] lr: 4.2e-05, eta: 0:59:41.700825, loss: 2.0685
2023-04-12 19:16:45 - training - INFO - Epoch [1/5][241/690] lr: 4.2e-05, eta: 0:58:43.982604, loss: 1.7516
2023-04-12 19:16:53 - training - INFO - Epoch [1/5][251/690] lr: 4.2e-05, eta: 0:57:49.369883, loss: 1.8420
2023-04-12 19:17:01 - training - INFO - Epoch [1/5][261/690] lr: 4.2e-05, eta: 0:57:00.097263, loss: 1.9848
2023-04-12 19:17:08 - training - INFO - Epoch [1/5][271/690] lr: 4.2e-05, eta: 0:56:13.351344, loss: 1.6346
2023-04-12 19:17:16 - training - INFO - Epoch [1/5][281/690] lr: 4.2e-05, eta: 0:55:30.568296, loss: 1.8407
2023-04-12 19:17:24 - training - INFO - Epoch [1/5][291/690] lr: 4.2e-05, eta: 0:54:52.218189, loss: 1.9357
2023-04-12 19:17:32 - training - INFO - Epoch [1/5][301/690] lr: 4.1e-05, eta: 0:54:16.270685, loss: 1.8541
2023-04-12 19:17:40 - training - INFO - Epoch [1/5][311/690] lr: 4.1e-05, eta: 0:53:39.841806, loss: 2.2169
2023-04-12 19:17:48 - training - INFO - Epoch [1/5][321/690] lr: 4.1e-05, eta: 0:53:06.905274, loss: 1.7378
2023-04-12 19:17:55 - training - INFO - Epoch [1/5][331/690] lr: 4.1e-05, eta: 0:52:32.498060, loss: 1.8830
2023-04-12 19:18:03 - training - INFO - Epoch [1/5][341/690] lr: 4.1e-05, eta: 0:52:00.553044, loss: 1.5354
2023-04-12 19:18:11 - training - INFO - Epoch [1/5][351/690] lr: 4.1e-05, eta: 0:51:30.741165, loss: 2.5323
2023-04-12 19:18:18 - training - INFO - Epoch [1/5][361/690] lr: 4.1e-05, eta: 0:51:00.494708, loss: 2.5214
2023-04-12 19:18:26 - training - INFO - Epoch [1/5][371/690] lr: 4.1e-05, eta: 0:50:31.392502, loss: 1.1819
2023-04-12 19:18:33 - training - INFO - Epoch [1/5][381/690] lr: 4.0e-05, eta: 0:50:02.964327, loss: 1.9233
2023-04-12 19:18:41 - training - INFO - Epoch [1/5][391/690] lr: 4.0e-05, eta: 0:49:35.761551, loss: 0.8944
2023-04-12 19:18:49 - training - INFO - Epoch [1/5][401/690] lr: 4.0e-05, eta: 0:49:10.947209, loss: 1.8963
2023-04-12 19:18:56 - training - INFO - Epoch [1/5][411/690] lr: 4.0e-05, eta: 0:48:45.487272, loss: 0.9649
2023-04-12 19:19:04 - training - INFO - Epoch [1/5][421/690] lr: 4.0e-05, eta: 0:48:21.588144, loss: 2.5073
2023-04-12 19:19:12 - training - INFO - Epoch [1/5][431/690] lr: 4.0e-05, eta: 0:47:59.193129, loss: 1.2909
2023-04-12 19:19:19 - training - INFO - Epoch [1/5][441/690] lr: 4.0e-05, eta: 0:47:37.292238, loss: 1.9363
2023-04-12 19:19:27 - training - INFO - Epoch [1/5][451/690] lr: 3.9e-05, eta: 0:47:15.278592, loss: 1.9789
2023-04-12 19:19:35 - training - INFO - Epoch [1/5][461/690] lr: 3.9e-05, eta: 0:46:54.032907, loss: 1.4069
2023-04-12 19:19:42 - training - INFO - Epoch [1/5][471/690] lr: 3.9e-05, eta: 0:46:33.190833, loss: 1.5554
2023-04-12 19:19:50 - training - INFO - Epoch [1/5][481/690] lr: 3.9e-05, eta: 0:46:12.155300, loss: 2.1997
2023-04-12 19:19:57 - training - INFO - Epoch [1/5][491/690] lr: 3.9e-05, eta: 0:45:52.736987, loss: 2.0130
2023-04-12 19:20:05 - training - INFO - Epoch [1/5][501/690] lr: 3.9e-05, eta: 0:45:33.363222, loss: 1.8659
2023-04-12 19:20:13 - training - INFO - Epoch [1/5][511/690] lr: 3.9e-05, eta: 0:45:14.672008, loss: 2.4791
2023-04-12 19:20:20 - training - INFO - Epoch [1/5][521/690] lr: 3.9e-05, eta: 0:44:56.633643, loss: 1.3474
2023-04-12 19:20:28 - training - INFO - Epoch [1/5][531/690] lr: 3.8e-05, eta: 0:44:38.833437, loss: 1.1450
2023-04-12 19:20:35 - training - INFO - Epoch [1/5][541/690] lr: 3.8e-05, eta: 0:44:20.923389, loss: 1.5607
2023-04-12 19:20:43 - training - INFO - Epoch [1/5][551/690] lr: 3.8e-05, eta: 0:44:03.273412, loss: 1.6969
2023-04-12 19:20:51 - training - INFO - Epoch [1/5][561/690] lr: 3.8e-05, eta: 0:43:45.881436, loss: 2.4696
2023-04-12 19:20:58 - training - INFO - Epoch [1/5][571/690] lr: 3.8e-05, eta: 0:43:30.325962, loss: 2.2510
2023-04-12 19:21:06 - training - INFO - Epoch [1/5][581/690] lr: 3.8e-05, eta: 0:43:13.969053, loss: 1.8861
2023-04-12 19:21:14 - training - INFO - Epoch [1/5][591/690] lr: 3.8e-05, eta: 0:42:58.540677, loss: 1.3526
2023-04-12 19:21:21 - training - INFO - Epoch [1/5][601/690] lr: 3.7e-05, eta: 0:42:42.706839, loss: 1.2066
2023-04-12 19:21:29 - training - INFO - Epoch [1/5][611/690] lr: 3.7e-05, eta: 0:42:27.006011, loss: 2.4805
2023-04-12 19:21:36 - training - INFO - Epoch [1/5][621/690] lr: 3.7e-05, eta: 0:42:12.031383, loss: 1.7476
2023-04-12 19:21:44 - training - INFO - Epoch [1/5][631/690] lr: 3.7e-05, eta: 0:41:56.853942, loss: 0.5860
2023-04-12 19:21:52 - training - INFO - Epoch [1/5][641/690] lr: 3.7e-05, eta: 0:41:43.886420, loss: 1.6188
2023-04-12 19:22:00 - training - INFO - Epoch [1/5][651/690] lr: 3.7e-05, eta: 0:41:29.500575, loss: 1.7317
2023-04-12 19:22:08 - training - INFO - Epoch [1/5][661/690] lr: 3.7e-05, eta: 0:41:16.645945, loss: 1.4645
2023-04-12 19:22:15 - training - INFO - Epoch [1/5][671/690] lr: 3.7e-05, eta: 0:41:02.638640, loss: 2.9114
2023-04-12 19:22:23 - training - INFO - Epoch [1/5][681/690] lr: 3.6e-05, eta: 0:40:51.323706, loss: 0.9184
2023-04-12 19:23:51 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 2.0063, Validation Metrics: {'exact_match': 27.70663562281723, 'f1': 32.22784524928632}, Test Metrics: {'exact_match': 29.849012775842045, 'f1': 33.851947558816725}
2023-04-12 19:23:51 - training - INFO - Epoch [2/5][1/690] lr: 3.6e-05, eta: 27 days, 13:44:46.399245, loss: 1.1098
2023-04-12 19:23:59 - training - INFO - Epoch [2/5][11/690] lr: 3.6e-05, eta: 2 days, 12:41:00.298113, loss: 1.7321
2023-04-12 19:24:07 - training - INFO - Epoch [2/5][21/690] lr: 3.6e-05, eta: 1 day, 8:02:15.080226, loss: 1.2995
2023-04-12 19:24:15 - training - INFO - Epoch [2/5][31/690] lr: 3.6e-05, eta: 21:52:57.582442, loss: 1.5783
2023-04-12 19:24:23 - training - INFO - Epoch [2/5][41/690] lr: 3.6e-05, eta: 16:40:37.116013, loss: 1.2855
2023-04-12 19:24:30 - training - INFO - Epoch [2/5][51/690] lr: 3.6e-05, eta: 13:30:29.649354, loss: 1.4421
2023-04-12 19:24:38 - training - INFO - Epoch [2/5][61/690] lr: 3.6e-05, eta: 11:22:45.306803, loss: 1.2738
2023-04-12 19:24:45 - training - INFO - Epoch [2/5][71/690] lr: 3.5e-05, eta: 9:50:49.852654, loss: 1.6168
2023-04-12 19:24:53 - training - INFO - Epoch [2/5][81/690] lr: 3.5e-05, eta: 8:41:37.006038, loss: 1.7162
2023-04-12 19:25:01 - training - INFO - Epoch [2/5][91/690] lr: 3.5e-05, eta: 7:47:32.151060, loss: 1.1528
2023-04-12 19:25:08 - training - INFO - Epoch [2/5][101/690] lr: 3.5e-05, eta: 7:04:11.505817, loss: 0.8047
2023-04-12 19:25:16 - training - INFO - Epoch [2/5][111/690] lr: 3.5e-05, eta: 6:28:36.086745, loss: 0.8282
2023-04-12 19:25:23 - training - INFO - Epoch [2/5][121/690] lr: 3.5e-05, eta: 5:58:55.810337, loss: 1.6091
2023-04-12 19:25:31 - training - INFO - Epoch [2/5][131/690] lr: 3.5e-05, eta: 5:33:42.634189, loss: 1.9634
2023-04-12 19:25:38 - training - INFO - Epoch [2/5][141/690] lr: 3.4e-05, eta: 5:12:04.366962, loss: 1.6826
2023-04-12 19:25:46 - training - INFO - Epoch [2/5][151/690] lr: 3.4e-05, eta: 4:53:19.716336, loss: 0.8420
2023-04-12 19:25:54 - training - INFO - Epoch [2/5][161/690] lr: 3.4e-05, eta: 4:36:53.692810, loss: 1.8992
2023-04-12 19:26:01 - training - INFO - Epoch [2/5][171/690] lr: 3.4e-05, eta: 4:22:18.176952, loss: 1.2754
2023-04-12 19:26:09 - training - INFO - Epoch [2/5][181/690] lr: 3.4e-05, eta: 4:09:21.709574, loss: 1.0826
2023-04-12 19:26:17 - training - INFO - Epoch [2/5][191/690] lr: 3.4e-05, eta: 3:57:45.636995, loss: 2.1338
2023-04-12 19:26:24 - training - INFO - Epoch [2/5][201/690] lr: 3.4e-05, eta: 3:47:16.956222, loss: 1.2216
2023-04-12 19:26:32 - training - INFO - Epoch [2/5][211/690] lr: 3.4e-05, eta: 3:37:46.262038, loss: 1.0455
2023-04-12 19:26:40 - training - INFO - Epoch [2/5][221/690] lr: 3.3e-05, eta: 3:29:10.167216, loss: 1.4509
2023-04-12 19:26:47 - training - INFO - Epoch [2/5][231/690] lr: 3.3e-05, eta: 3:21:17.932644, loss: 1.4341
2023-04-12 19:26:55 - training - INFO - Epoch [2/5][241/690] lr: 3.3e-05, eta: 3:14:01.927891, loss: 1.2285
2023-04-12 19:27:03 - training - INFO - Epoch [2/5][251/690] lr: 3.3e-05, eta: 3:07:19.964813, loss: 0.7208
2023-04-12 19:27:10 - training - INFO - Epoch [2/5][261/690] lr: 3.3e-05, eta: 3:01:08.245938, loss: 1.4092
2023-04-12 19:27:18 - training - INFO - Epoch [2/5][271/690] lr: 3.3e-05, eta: 2:55:23.392836, loss: 1.4558
2023-04-12 19:27:25 - training - INFO - Epoch [2/5][281/690] lr: 3.3e-05, eta: 2:50:03.508172, loss: 1.2779
2023-04-12 19:27:33 - training - INFO - Epoch [2/5][291/690] lr: 3.2e-05, eta: 2:45:03.433410, loss: 1.2072
2023-04-12 19:27:41 - training - INFO - Epoch [2/5][301/690] lr: 3.2e-05, eta: 2:40:24.361127, loss: 2.4178
2023-04-12 19:27:48 - training - INFO - Epoch [2/5][311/690] lr: 3.2e-05, eta: 2:36:02.145975, loss: 1.1443
2023-04-12 19:27:56 - training - INFO - Epoch [2/5][321/690] lr: 3.2e-05, eta: 2:31:55.149351, loss: 1.4012
2023-04-12 19:28:03 - training - INFO - Epoch [2/5][331/690] lr: 3.2e-05, eta: 2:28:03.679274, loss: 0.9975
2023-04-12 19:28:11 - training - INFO - Epoch [2/5][341/690] lr: 3.2e-05, eta: 2:24:26.119870, loss: 1.5352
2023-04-12 19:28:19 - training - INFO - Epoch [2/5][351/690] lr: 3.2e-05, eta: 2:20:58.206066, loss: 1.8004
2023-04-12 19:28:26 - training - INFO - Epoch [2/5][361/690] lr: 3.2e-05, eta: 2:17:42.154478, loss: 1.4639
2023-04-12 19:28:34 - training - INFO - Epoch [2/5][371/690] lr: 3.1e-05, eta: 2:14:35.712044, loss: 1.6816
2023-04-12 19:28:41 - training - INFO - Epoch [2/5][381/690] lr: 3.1e-05, eta: 2:11:40.118523, loss: 1.1106
2023-04-12 19:28:49 - training - INFO - Epoch [2/5][391/690] lr: 3.1e-05, eta: 2:08:52.069114, loss: 1.3757
2023-04-12 19:28:57 - training - INFO - Epoch [2/5][401/690] lr: 3.1e-05, eta: 2:06:12.728124, loss: 1.6111
2023-04-12 19:29:04 - training - INFO - Epoch [2/5][411/690] lr: 3.1e-05, eta: 2:03:40.481289, loss: 0.8650
2023-04-12 19:29:12 - training - INFO - Epoch [2/5][421/690] lr: 3.1e-05, eta: 2:01:14.767474, loss: 1.2850
2023-04-12 19:29:19 - training - INFO - Epoch [2/5][431/690] lr: 3.1e-05, eta: 1:58:55.445747, loss: 0.5612
2023-04-12 19:29:27 - training - INFO - Epoch [2/5][441/690] lr: 3.1e-05, eta: 1:56:41.879811, loss: 1.4704
2023-04-12 19:29:34 - training - INFO - Epoch [2/5][451/690] lr: 3.0e-05, eta: 1:54:34.235824, loss: 1.4628
2023-04-12 19:29:42 - training - INFO - Epoch [2/5][461/690] lr: 3.0e-05, eta: 1:52:33.277853, loss: 1.1878
2023-04-12 19:29:50 - training - INFO - Epoch [2/5][471/690] lr: 3.0e-05, eta: 1:50:35.141595, loss: 1.0067
2023-04-12 19:29:57 - training - INFO - Epoch [2/5][481/690] lr: 3.0e-05, eta: 1:48:42.649542, loss: 1.5316
2023-04-12 19:30:05 - training - INFO - Epoch [2/5][491/690] lr: 3.0e-05, eta: 1:46:53.919523, loss: 2.0479
2023-04-12 19:30:12 - training - INFO - Epoch [2/5][501/690] lr: 3.0e-05, eta: 1:45:08.866476, loss: 1.2162
2023-04-12 19:30:20 - training - INFO - Epoch [2/5][511/690] lr: 3.0e-05, eta: 1:43:29.669089, loss: 0.9545
2023-04-12 19:30:28 - training - INFO - Epoch [2/5][521/690] lr: 2.9e-05, eta: 1:41:53.071965, loss: 1.1970
2023-04-12 19:30:35 - training - INFO - Epoch [2/5][531/690] lr: 2.9e-05, eta: 1:40:18.437985, loss: 1.5621
2023-04-12 19:30:43 - training - INFO - Epoch [2/5][541/690] lr: 2.9e-05, eta: 1:38:48.169648, loss: 1.6284
2023-04-12 19:30:51 - training - INFO - Epoch [2/5][551/690] lr: 2.9e-05, eta: 1:37:20.687775, loss: 1.2550
2023-04-12 19:30:58 - training - INFO - Epoch [2/5][561/690] lr: 2.9e-05, eta: 1:35:56.153382, loss: 1.0470
2023-04-12 19:31:06 - training - INFO - Epoch [2/5][571/690] lr: 2.9e-05, eta: 1:34:33.751823, loss: 1.0155
2023-04-12 19:31:13 - training - INFO - Epoch [2/5][581/690] lr: 2.9e-05, eta: 1:33:13.958986, loss: 0.9787
2023-04-12 19:31:21 - training - INFO - Epoch [2/5][591/690] lr: 2.9e-05, eta: 1:31:56.657784, loss: 1.3452
2023-04-12 19:31:29 - training - INFO - Epoch [2/5][601/690] lr: 2.8e-05, eta: 1:30:41.758091, loss: 1.0239
2023-04-12 19:31:36 - training - INFO - Epoch [2/5][611/690] lr: 2.8e-05, eta: 1:29:29.065698, loss: 1.1619
2023-04-12 19:31:44 - training - INFO - Epoch [2/5][621/690] lr: 2.8e-05, eta: 1:28:18.419955, loss: 0.8868
2023-04-12 19:31:51 - training - INFO - Epoch [2/5][631/690] lr: 2.8e-05, eta: 1:27:09.459244, loss: 1.2803
2023-04-12 19:31:59 - training - INFO - Epoch [2/5][641/690] lr: 2.8e-05, eta: 1:26:02.981326, loss: 0.9356
2023-04-12 19:32:06 - training - INFO - Epoch [2/5][651/690] lr: 2.8e-05, eta: 1:24:58.221756, loss: 1.1251
2023-04-12 19:32:14 - training - INFO - Epoch [2/5][661/690] lr: 2.8e-05, eta: 1:23:55.681739, loss: 1.4290
2023-04-12 19:32:22 - training - INFO - Epoch [2/5][671/690] lr: 2.7e-05, eta: 1:22:54.120984, loss: 1.8359
2023-04-12 19:32:29 - training - INFO - Epoch [2/5][681/690] lr: 2.7e-05, eta: 1:21:53.908935, loss: 1.3221
2023-04-12 19:33:52 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.3361, Validation Metrics: {'exact_match': 23.28288707799767, 'f1': 26.859344167148222}, Test Metrics: {'exact_match': 26.24854819976771, 'f1': 30.07554371553402}
2023-04-12 19:33:53 - training - INFO - Epoch [3/5][1/690] lr: 2.7e-05, eta: 51 days, 13:52:47.902844, loss: 1.0030
2023-04-12 19:34:00 - training - INFO - Epoch [3/5][11/690] lr: 2.7e-05, eta: 4 days, 16:51:45.294211, loss: 1.0929
2023-04-12 19:34:08 - training - INFO - Epoch [3/5][21/690] lr: 2.7e-05, eta: 2 days, 11:17:38.411538, loss: 1.0941
2023-04-12 19:34:15 - training - INFO - Epoch [3/5][31/690] lr: 2.7e-05, eta: 1 day, 16:16:59.828759, loss: 1.0453
2023-04-12 19:34:23 - training - INFO - Epoch [3/5][41/690] lr: 2.7e-05, eta: 1 day, 6:32:37.823395, loss: 1.3608
2023-04-12 19:34:31 - training - INFO - Epoch [3/5][51/690] lr: 2.7e-05, eta: 1 day, 0:37:15.145170, loss: 1.0615
2023-04-12 19:34:38 - training - INFO - Epoch [3/5][61/690] lr: 2.6e-05, eta: 20:38:22.876080, loss: 1.0271
2023-04-12 19:34:46 - training - INFO - Epoch [3/5][71/690] lr: 2.6e-05, eta: 17:46:48.991704, loss: 1.3393
2023-04-12 19:34:53 - training - INFO - Epoch [3/5][81/690] lr: 2.6e-05, eta: 15:37:39.426243, loss: 1.0915
2023-04-12 19:35:01 - training - INFO - Epoch [3/5][91/690] lr: 2.6e-05, eta: 13:56:46.579997, loss: 0.9345
2023-04-12 19:35:08 - training - INFO - Epoch [3/5][101/690] lr: 2.6e-05, eta: 12:35:52.948364, loss: 1.2791
2023-04-12 19:35:16 - training - INFO - Epoch [3/5][111/690] lr: 2.6e-05, eta: 11:29:35.742723, loss: 1.0662
2023-04-12 19:35:24 - training - INFO - Epoch [3/5][121/690] lr: 2.6e-05, eta: 10:34:14.351614, loss: 0.6051
2023-04-12 19:35:32 - training - INFO - Epoch [3/5][131/690] lr: 2.6e-05, eta: 9:47:21.560194, loss: 0.6114
2023-04-12 19:35:39 - training - INFO - Epoch [3/5][141/690] lr: 2.5e-05, eta: 9:07:08.876883, loss: 0.6609
2023-04-12 19:35:47 - training - INFO - Epoch [3/5][151/690] lr: 2.5e-05, eta: 8:32:07.987866, loss: 1.0210
2023-04-12 19:35:55 - training - INFO - Epoch [3/5][161/690] lr: 2.5e-05, eta: 8:01:27.365936, loss: 0.7721
2023-04-12 19:36:02 - training - INFO - Epoch [3/5][171/690] lr: 2.5e-05, eta: 7:34:18.681132, loss: 1.1569
2023-04-12 19:36:10 - training - INFO - Epoch [3/5][181/690] lr: 2.5e-05, eta: 7:10:12.272444, loss: 0.9569
2023-04-12 19:36:17 - training - INFO - Epoch [3/5][191/690] lr: 2.5e-05, eta: 6:48:33.666783, loss: 1.9794
2023-04-12 19:36:25 - training - INFO - Epoch [3/5][201/690] lr: 2.5e-05, eta: 6:29:05.520552, loss: 1.0524
2023-04-12 19:36:33 - training - INFO - Epoch [3/5][211/690] lr: 2.4e-05, eta: 6:11:28.812493, loss: 0.8480
2023-04-12 19:36:40 - training - INFO - Epoch [3/5][221/690] lr: 2.4e-05, eta: 5:55:26.418079, loss: 1.3341
2023-04-12 19:36:48 - training - INFO - Epoch [3/5][231/690] lr: 2.4e-05, eta: 5:40:45.214542, loss: 1.0920
2023-04-12 19:36:55 - training - INFO - Epoch [3/5][241/690] lr: 2.4e-05, eta: 5:27:17.051912, loss: 0.9539
2023-04-12 19:37:03 - training - INFO - Epoch [3/5][251/690] lr: 2.4e-05, eta: 5:14:51.515356, loss: 0.6247
2023-04-12 19:37:10 - training - INFO - Epoch [3/5][261/690] lr: 2.4e-05, eta: 5:03:24.141813, loss: 0.9878
2023-04-12 19:37:18 - training - INFO - Epoch [3/5][271/690] lr: 2.4e-05, eta: 4:52:45.767956, loss: 0.4954
2023-04-12 19:37:25 - training - INFO - Epoch [3/5][281/690] lr: 2.4e-05, eta: 4:42:51.506613, loss: 0.7880
2023-04-12 19:37:33 - training - INFO - Epoch [3/5][291/690] lr: 2.3e-05, eta: 4:33:38.665575, loss: 1.2808
2023-04-12 19:37:41 - training - INFO - Epoch [3/5][301/690] lr: 2.3e-05, eta: 4:25:03.775729, loss: 0.7111
2023-04-12 19:37:48 - training - INFO - Epoch [3/5][311/690] lr: 2.3e-05, eta: 4:17:00.196245, loss: 1.1096
2023-04-12 19:37:56 - training - INFO - Epoch [3/5][321/690] lr: 2.3e-05, eta: 4:09:26.235417, loss: 0.7201
2023-04-12 19:38:04 - training - INFO - Epoch [3/5][331/690] lr: 2.3e-05, eta: 4:02:19.742492, loss: 1.0074
2023-04-12 19:38:11 - training - INFO - Epoch [3/5][341/690] lr: 2.3e-05, eta: 3:55:38.018941, loss: 0.7861
2023-04-12 19:38:19 - training - INFO - Epoch [3/5][351/690] lr: 2.3e-05, eta: 3:49:18.757359, loss: 1.5331
2023-04-12 19:38:27 - training - INFO - Epoch [3/5][361/690] lr: 2.2e-05, eta: 3:43:19.556870, loss: 1.3960
2023-04-12 19:38:34 - training - INFO - Epoch [3/5][371/690] lr: 2.2e-05, eta: 3:37:38.851856, loss: 0.8131
2023-04-12 19:38:42 - training - INFO - Epoch [3/5][381/690] lr: 2.2e-05, eta: 3:32:15.656406, loss: 1.2437
2023-04-12 19:38:49 - training - INFO - Epoch [3/5][391/690] lr: 2.2e-05, eta: 3:27:09.854948, loss: 1.0278
2023-04-12 19:38:57 - training - INFO - Epoch [3/5][401/690] lr: 2.2e-05, eta: 3:22:17.532376, loss: 0.9328
2023-04-12 19:39:05 - training - INFO - Epoch [3/5][411/690] lr: 2.2e-05, eta: 3:17:39.657993, loss: 0.9048
2023-04-12 19:39:12 - training - INFO - Epoch [3/5][421/690] lr: 2.2e-05, eta: 3:13:14.860550, loss: 0.8032
2023-04-12 19:39:20 - training - INFO - Epoch [3/5][431/690] lr: 2.2e-05, eta: 3:09:01.682592, loss: 1.1322
2023-04-12 19:39:27 - training - INFO - Epoch [3/5][441/690] lr: 2.1e-05, eta: 3:04:58.771725, loss: 0.8861
2023-04-12 19:39:35 - training - INFO - Epoch [3/5][451/690] lr: 2.1e-05, eta: 3:01:07.959139, loss: 1.5876
2023-04-12 19:39:43 - training - INFO - Epoch [3/5][461/690] lr: 2.1e-05, eta: 2:57:25.712070, loss: 1.2832
2023-04-12 19:39:50 - training - INFO - Epoch [3/5][471/690] lr: 2.1e-05, eta: 2:53:52.645677, loss: 1.1446
2023-04-12 19:39:58 - training - INFO - Epoch [3/5][481/690] lr: 2.1e-05, eta: 2:50:28.947250, loss: 1.1042
2023-04-12 19:40:05 - training - INFO - Epoch [3/5][491/690] lr: 2.1e-05, eta: 2:47:12.388894, loss: 0.9928
2023-04-12 19:40:13 - training - INFO - Epoch [3/5][501/690] lr: 2.1e-05, eta: 2:44:04.735170, loss: 0.8409
2023-04-12 19:40:21 - training - INFO - Epoch [3/5][511/690] lr: 2.1e-05, eta: 2:41:03.552499, loss: 1.7422
2023-04-12 19:40:28 - training - INFO - Epoch [3/5][521/690] lr: 2.0e-05, eta: 2:38:08.144020, loss: 1.2285
2023-04-12 19:40:36 - training - INFO - Epoch [3/5][531/690] lr: 2.0e-05, eta: 2:35:19.211076, loss: 1.8821
2023-04-12 19:40:43 - training - INFO - Epoch [3/5][541/690] lr: 2.0e-05, eta: 2:32:36.356764, loss: 1.3479
2023-04-12 19:40:51 - training - INFO - Epoch [3/5][551/690] lr: 2.0e-05, eta: 2:29:59.342508, loss: 0.9987
2023-04-12 19:40:59 - training - INFO - Epoch [3/5][561/690] lr: 2.0e-05, eta: 2:27:27.285156, loss: 0.9619
2023-04-12 19:41:06 - training - INFO - Epoch [3/5][571/690] lr: 2.0e-05, eta: 2:25:01.098056, loss: 1.4785
2023-04-12 19:41:14 - training - INFO - Epoch [3/5][581/690] lr: 2.0e-05, eta: 2:22:38.895477, loss: 0.9418
2023-04-12 19:41:22 - training - INFO - Epoch [3/5][591/690] lr: 1.9e-05, eta: 2:20:22.059354, loss: 0.5814
2023-04-12 19:41:29 - training - INFO - Epoch [3/5][601/690] lr: 1.9e-05, eta: 2:18:08.718207, loss: 0.8595
2023-04-12 19:41:37 - training - INFO - Epoch [3/5][611/690] lr: 1.9e-05, eta: 2:16:00.024140, loss: 1.1401
2023-04-12 19:41:44 - training - INFO - Epoch [3/5][621/690] lr: 1.9e-05, eta: 2:13:54.897510, loss: 1.3638
2023-04-12 19:41:52 - training - INFO - Epoch [3/5][631/690] lr: 1.9e-05, eta: 2:11:53.147244, loss: 1.3526
2023-04-12 19:41:59 - training - INFO - Epoch [3/5][641/690] lr: 1.9e-05, eta: 2:09:55.039607, loss: 0.8238
2023-04-12 19:42:07 - training - INFO - Epoch [3/5][651/690] lr: 1.9e-05, eta: 2:08:00.688317, loss: 0.8337
2023-04-12 19:42:15 - training - INFO - Epoch [3/5][661/690] lr: 1.9e-05, eta: 2:06:09.836864, loss: 0.8151
2023-04-12 19:42:22 - training - INFO - Epoch [3/5][671/690] lr: 1.8e-05, eta: 2:04:21.381564, loss: 1.0315
2023-04-12 19:42:30 - training - INFO - Epoch [3/5][681/690] lr: 1.8e-05, eta: 2:02:36.178011, loss: 1.8515
2023-04-12 19:43:53 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.1084, Validation Metrics: {'exact_match': 24.679860302677533, 'f1': 28.859489085800874}, Test Metrics: {'exact_match': 25.900116144018583, 'f1': 29.856612196767188}
2023-04-12 19:43:53 - training - INFO - Epoch [4/5][1/690] lr: 1.8e-05, eta: 75 days, 13:29:02.202566, loss: 1.0856
2023-04-12 19:44:01 - training - INFO - Epoch [4/5][11/690] lr: 1.8e-05, eta: 6 days, 21:03:03.486976, loss: 0.9287
2023-04-12 19:44:09 - training - INFO - Epoch [4/5][21/690] lr: 1.8e-05, eta: 3 days, 14:32:38.720544, loss: 0.6082
2023-04-12 19:44:16 - training - INFO - Epoch [4/5][31/690] lr: 1.8e-05, eta: 2 days, 10:41:28.982606, loss: 1.7637
2023-04-12 19:44:24 - training - INFO - Epoch [4/5][41/690] lr: 1.8e-05, eta: 1 day, 20:25:20.117168, loss: 0.9743
2023-04-12 19:44:31 - training - INFO - Epoch [4/5][51/690] lr: 1.7e-05, eta: 1 day, 11:44:47.190291, loss: 0.6248
2023-04-12 19:44:39 - training - INFO - Epoch [4/5][61/690] lr: 1.7e-05, eta: 1 day, 5:54:49.382517, loss: 1.2265
2023-04-12 19:44:47 - training - INFO - Epoch [4/5][71/690] lr: 1.7e-05, eta: 1 day, 1:43:31.304237, loss: 1.4088
2023-04-12 19:44:54 - training - INFO - Epoch [4/5][81/690] lr: 1.7e-05, eta: 22:34:15.752064, loss: 0.9595
2023-04-12 19:45:02 - training - INFO - Epoch [4/5][91/690] lr: 1.7e-05, eta: 20:06:33.906980, loss: 1.1949
2023-04-12 19:45:09 - training - INFO - Epoch [4/5][101/690] lr: 1.7e-05, eta: 18:08:04.173568, loss: 1.0354
2023-04-12 19:45:17 - training - INFO - Epoch [4/5][111/690] lr: 1.7e-05, eta: 16:30:56.748267, loss: 0.8839
2023-04-12 19:45:25 - training - INFO - Epoch [4/5][121/690] lr: 1.7e-05, eta: 15:09:54.827672, loss: 0.7279
2023-04-12 19:45:33 - training - INFO - Epoch [4/5][131/690] lr: 1.6e-05, eta: 14:01:07.811232, loss: 0.5082
2023-04-12 19:45:40 - training - INFO - Epoch [4/5][141/690] lr: 1.6e-05, eta: 13:02:07.066614, loss: 1.1407
2023-04-12 19:45:48 - training - INFO - Epoch [4/5][151/690] lr: 1.6e-05, eta: 12:10:52.683280, loss: 0.5765
2023-04-12 19:45:55 - training - INFO - Epoch [4/5][161/690] lr: 1.6e-05, eta: 11:25:58.924235, loss: 0.9049
2023-04-12 19:46:03 - training - INFO - Epoch [4/5][171/690] lr: 1.6e-05, eta: 10:46:19.906692, loss: 0.9481
2023-04-12 19:46:11 - training - INFO - Epoch [4/5][181/690] lr: 1.6e-05, eta: 10:11:04.616919, loss: 1.0663
2023-04-12 19:46:19 - training - INFO - Epoch [4/5][191/690] lr: 1.6e-05, eta: 9:39:35.087802, loss: 1.0234
2023-04-12 19:46:26 - training - INFO - Epoch [4/5][201/690] lr: 1.6e-05, eta: 9:11:06.080190, loss: 1.0876
2023-04-12 19:46:34 - training - INFO - Epoch [4/5][211/690] lr: 1.5e-05, eta: 8:45:19.198089, loss: 0.8395
2023-04-12 19:46:42 - training - INFO - Epoch [4/5][221/690] lr: 1.5e-05, eta: 8:21:54.022106, loss: 0.7785
2023-04-12 19:46:49 - training - INFO - Epoch [4/5][231/690] lr: 1.5e-05, eta: 8:00:29.872602, loss: 0.9791
2023-04-12 19:46:57 - training - INFO - Epoch [4/5][241/690] lr: 1.5e-05, eta: 7:40:52.813012, loss: 0.6602
2023-04-12 19:47:05 - training - INFO - Epoch [4/5][251/690] lr: 1.5e-05, eta: 7:22:44.691139, loss: 0.8162
2023-04-12 19:47:13 - training - INFO - Epoch [4/5][261/690] lr: 1.5e-05, eta: 7:06:01.678242, loss: 1.0439
2023-04-12 19:47:20 - training - INFO - Epoch [4/5][271/690] lr: 1.5e-05, eta: 6:50:32.796221, loss: 1.2395
2023-04-12 19:47:28 - training - INFO - Epoch [4/5][281/690] lr: 1.4e-05, eta: 6:36:08.792952, loss: 0.4806
2023-04-12 19:47:36 - training - INFO - Epoch [4/5][291/690] lr: 1.4e-05, eta: 6:22:43.642884, loss: 0.6416
2023-04-12 19:47:44 - training - INFO - Epoch [4/5][301/690] lr: 1.4e-05, eta: 6:10:14.280408, loss: 1.0607
2023-04-12 19:47:52 - training - INFO - Epoch [4/5][311/690] lr: 1.4e-05, eta: 5:58:28.440556, loss: 0.8469
2023-04-12 19:47:59 - training - INFO - Epoch [4/5][321/690] lr: 1.4e-05, eta: 5:47:27.018822, loss: 0.6929
2023-04-12 19:48:07 - training - INFO - Epoch [4/5][331/690] lr: 1.4e-05, eta: 5:37:04.244752, loss: 1.0557
2023-04-12 19:48:15 - training - INFO - Epoch [4/5][341/690] lr: 1.4e-05, eta: 5:27:17.867922, loss: 0.9899
2023-04-12 19:48:22 - training - INFO - Epoch [4/5][351/690] lr: 1.4e-05, eta: 5:18:04.618185, loss: 1.3231
2023-04-12 19:48:30 - training - INFO - Epoch [4/5][361/690] lr: 1.3e-05, eta: 5:09:22.375554, loss: 1.2458
2023-04-12 19:48:37 - training - INFO - Epoch [4/5][371/690] lr: 1.3e-05, eta: 5:01:06.284978, loss: 0.5179
2023-04-12 19:48:45 - training - INFO - Epoch [4/5][381/690] lr: 1.3e-05, eta: 4:53:16.136052, loss: 0.5455
2023-04-12 19:48:53 - training - INFO - Epoch [4/5][391/690] lr: 1.3e-05, eta: 4:45:50.476217, loss: 0.2858
2023-04-12 19:49:00 - training - INFO - Epoch [4/5][401/690] lr: 1.3e-05, eta: 4:38:45.484636, loss: 0.8127
2023-04-12 19:49:08 - training - INFO - Epoch [4/5][411/690] lr: 1.3e-05, eta: 4:32:01.216932, loss: 0.5592
2023-04-12 19:49:16 - training - INFO - Epoch [4/5][421/690] lr: 1.3e-05, eta: 4:25:36.892673, loss: 1.2001
2023-04-12 19:49:23 - training - INFO - Epoch [4/5][431/690] lr: 1.2e-05, eta: 4:19:29.707560, loss: 0.5586
2023-04-12 19:49:31 - training - INFO - Epoch [4/5][441/690] lr: 1.2e-05, eta: 4:13:38.071662, loss: 1.5311
2023-04-12 19:49:39 - training - INFO - Epoch [4/5][451/690] lr: 1.2e-05, eta: 4:08:02.156627, loss: 0.8378
2023-04-12 19:49:46 - training - INFO - Epoch [4/5][461/690] lr: 1.2e-05, eta: 4:02:41.586025, loss: 0.4451
2023-04-12 19:49:54 - training - INFO - Epoch [4/5][471/690] lr: 1.2e-05, eta: 3:57:32.489280, loss: 1.1947
2023-04-12 19:50:02 - training - INFO - Epoch [4/5][481/690] lr: 1.2e-05, eta: 3:52:36.066555, loss: 0.8843
2023-04-12 19:50:09 - training - INFO - Epoch [4/5][491/690] lr: 1.2e-05, eta: 3:47:53.266772, loss: 0.8870
2023-04-12 19:50:17 - training - INFO - Epoch [4/5][501/690] lr: 1.2e-05, eta: 3:43:19.474515, loss: 1.1737
2023-04-12 19:50:25 - training - INFO - Epoch [4/5][511/690] lr: 1.1e-05, eta: 3:38:58.464454, loss: 1.0186
2023-04-12 19:50:33 - training - INFO - Epoch [4/5][521/690] lr: 1.1e-05, eta: 3:34:45.130853, loss: 1.2346
2023-04-12 19:50:40 - training - INFO - Epoch [4/5][531/690] lr: 1.1e-05, eta: 3:30:42.469224, loss: 1.0865
2023-04-12 19:50:48 - training - INFO - Epoch [4/5][541/690] lr: 1.1e-05, eta: 3:26:46.838456, loss: 0.8077
2023-04-12 19:50:56 - training - INFO - Epoch [4/5][551/690] lr: 1.1e-05, eta: 3:23:01.670475, loss: 0.9640
2023-04-12 19:51:04 - training - INFO - Epoch [4/5][561/690] lr: 1.1e-05, eta: 3:19:22.880982, loss: 1.0337
2023-04-12 19:51:11 - training - INFO - Epoch [4/5][571/690] lr: 1.1e-05, eta: 3:15:50.756539, loss: 1.0353
2023-04-12 19:51:19 - training - INFO - Epoch [4/5][581/690] lr: 1.1e-05, eta: 3:12:26.408129, loss: 0.8891
2023-04-12 19:51:27 - training - INFO - Epoch [4/5][591/690] lr: 1.0e-05, eta: 3:09:09.197901, loss: 1.0119
2023-04-12 19:51:34 - training - INFO - Epoch [4/5][601/690] lr: 1.0e-05, eta: 3:05:57.282290, loss: 0.7797
2023-04-12 19:51:42 - training - INFO - Epoch [4/5][611/690] lr: 1.0e-05, eta: 3:02:52.456778, loss: 0.4267
2023-04-12 19:51:50 - training - INFO - Epoch [4/5][621/690] lr: 1.0e-05, eta: 2:59:52.391706, loss: 1.2115
2023-04-12 19:51:57 - training - INFO - Epoch [4/5][631/690] lr: 9.9e-06, eta: 2:56:57.594360, loss: 0.9225
2023-04-12 19:52:05 - training - INFO - Epoch [4/5][641/690] lr: 9.7e-06, eta: 2:54:08.376063, loss: 0.7263
2023-04-12 19:52:12 - training - INFO - Epoch [4/5][651/690] lr: 9.6e-06, eta: 2:51:23.850684, loss: 1.2985
2023-04-12 19:52:20 - training - INFO - Epoch [4/5][661/690] lr: 9.5e-06, eta: 2:48:43.760421, loss: 1.3212
2023-04-12 19:52:28 - training - INFO - Epoch [4/5][671/690] lr: 9.3e-06, eta: 2:46:08.645386, loss: 1.1053
2023-04-12 19:52:35 - training - INFO - Epoch [4/5][681/690] lr: 9.2e-06, eta: 2:43:37.411968, loss: 0.9206
2023-04-12 19:53:58 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.9606, Validation Metrics: {'exact_match': 24.79627473806752, 'f1': 28.422016618991506}, Test Metrics: {'exact_match': 26.713124274099883, 'f1': 29.95061927159241}
2023-04-12 19:53:59 - training - INFO - Epoch [5/5][1/690] lr: 9.1e-06, eta: 99 days, 17:29:01.983562, loss: 0.4131
2023-04-12 19:54:06 - training - INFO - Epoch [5/5][11/690] lr: 8.9e-06, eta: 9 days, 1:36:58.898286, loss: 1.2567
2023-04-12 19:54:14 - training - INFO - Epoch [5/5][21/690] lr: 8.8e-06, eta: 4 days, 18:00:35.770059, loss: 0.6119
2023-04-12 19:54:22 - training - INFO - Epoch [5/5][31/690] lr: 8.7e-06, eta: 3 days, 5:14:13.775207, loss: 1.0665
2023-04-12 19:54:29 - training - INFO - Epoch [5/5][41/690] lr: 8.5e-06, eta: 2 days, 10:24:13.337413, loss: 0.8086
2023-04-12 19:54:37 - training - INFO - Epoch [5/5][51/690] lr: 8.4e-06, eta: 1 day, 22:57:07.154505, loss: 0.8037
2023-04-12 19:54:44 - training - INFO - Epoch [5/5][61/690] lr: 8.3e-06, eta: 1 day, 15:15:24.855061, loss: 0.9876
2023-04-12 19:54:52 - training - INFO - Epoch [5/5][71/690] lr: 8.1e-06, eta: 1 day, 9:43:45.105001, loss: 0.9043
2023-04-12 19:55:00 - training - INFO - Epoch [5/5][81/690] lr: 8.0e-06, eta: 1 day, 5:33:52.016175, loss: 0.5837
2023-04-12 19:55:07 - training - INFO - Epoch [5/5][91/690] lr: 7.9e-06, eta: 1 day, 2:18:51.441725, loss: 0.9925
2023-04-12 19:55:15 - training - INFO - Epoch [5/5][101/690] lr: 7.8e-06, eta: 23:42:29.653484, loss: 0.6509
2023-04-12 19:55:22 - training - INFO - Epoch [5/5][111/690] lr: 7.6e-06, eta: 21:34:16.291650, loss: 1.1018
2023-04-12 19:55:30 - training - INFO - Epoch [5/5][121/690] lr: 7.5e-06, eta: 19:47:16.541949, loss: 0.8621
2023-04-12 19:55:38 - training - INFO - Epoch [5/5][131/690] lr: 7.4e-06, eta: 18:16:34.966508, loss: 0.7494
2023-04-12 19:55:45 - training - INFO - Epoch [5/5][141/690] lr: 7.2e-06, eta: 16:58:42.375495, loss: 1.0094
2023-04-12 19:55:53 - training - INFO - Epoch [5/5][151/690] lr: 7.1e-06, eta: 15:51:09.255844, loss: 0.9347
2023-04-12 19:56:00 - training - INFO - Epoch [5/5][161/690] lr: 7.0e-06, eta: 14:51:56.045869, loss: 1.0295
2023-04-12 19:56:08 - training - INFO - Epoch [5/5][171/690] lr: 6.8e-06, eta: 13:59:37.765761, loss: 0.8928
2023-04-12 19:56:15 - training - INFO - Epoch [5/5][181/690] lr: 6.7e-06, eta: 13:13:05.270418, loss: 0.7983
2023-04-12 19:56:23 - training - INFO - Epoch [5/5][191/690] lr: 6.6e-06, eta: 12:31:23.471011, loss: 0.6663
2023-04-12 19:56:30 - training - INFO - Epoch [5/5][201/690] lr: 6.4e-06, eta: 11:53:52.944576, loss: 0.5580
2023-04-12 19:56:38 - training - INFO - Epoch [5/5][211/690] lr: 6.3e-06, eta: 11:19:53.812230, loss: 0.8388
2023-04-12 19:56:46 - training - INFO - Epoch [5/5][221/690] lr: 6.2e-06, eta: 10:48:57.451888, loss: 0.5971
2023-04-12 19:56:53 - training - INFO - Epoch [5/5][231/690] lr: 6.0e-06, eta: 10:20:43.656174, loss: 1.1391
2023-04-12 19:57:01 - training - INFO - Epoch [5/5][241/690] lr: 5.9e-06, eta: 9:54:46.926383, loss: 1.2709
2023-04-12 19:57:08 - training - INFO - Epoch [5/5][251/690] lr: 5.8e-06, eta: 9:30:54.261797, loss: 1.3805
2023-04-12 19:57:16 - training - INFO - Epoch [5/5][261/690] lr: 5.6e-06, eta: 9:08:52.866780, loss: 0.9951
2023-04-12 19:57:23 - training - INFO - Epoch [5/5][271/690] lr: 5.5e-06, eta: 8:48:25.816901, loss: 0.8370
2023-04-12 19:57:31 - training - INFO - Epoch [5/5][281/690] lr: 5.4e-06, eta: 8:29:26.149009, loss: 0.8188
2023-04-12 19:57:39 - training - INFO - Epoch [5/5][291/690] lr: 5.3e-06, eta: 8:11:47.047011, loss: 0.6438
2023-04-12 19:57:46 - training - INFO - Epoch [5/5][301/690] lr: 5.1e-06, eta: 7:55:17.444768, loss: 1.0223
2023-04-12 19:57:54 - training - INFO - Epoch [5/5][311/690] lr: 5.0e-06, eta: 7:39:49.885793, loss: 0.9325
2023-04-12 19:58:02 - training - INFO - Epoch [5/5][321/690] lr: 4.9e-06, eta: 7:25:20.974749, loss: 1.1561
2023-04-12 19:58:10 - training - INFO - Epoch [5/5][331/690] lr: 4.7e-06, eta: 7:11:45.350421, loss: 1.0333
2023-04-12 19:58:18 - training - INFO - Epoch [5/5][341/690] lr: 4.6e-06, eta: 6:58:56.103332, loss: 0.7063
2023-04-12 19:58:25 - training - INFO - Epoch [5/5][351/690] lr: 4.5e-06, eta: 6:46:47.689911, loss: 0.8243
2023-04-12 19:58:33 - training - INFO - Epoch [5/5][361/690] lr: 4.3e-06, eta: 6:35:20.894350, loss: 0.7803
2023-04-12 19:58:40 - training - INFO - Epoch [5/5][371/690] lr: 4.2e-06, eta: 6:24:29.795454, loss: 0.3083
2023-04-12 19:58:48 - training - INFO - Epoch [5/5][381/690] lr: 4.1e-06, eta: 6:14:12.122682, loss: 0.7904
2023-04-12 19:58:55 - training - INFO - Epoch [5/5][391/690] lr: 3.9e-06, eta: 6:04:25.227265, loss: 0.7535
2023-04-12 19:59:03 - training - INFO - Epoch [5/5][401/690] lr: 3.8e-06, eta: 5:55:08.875592, loss: 0.6578
2023-04-12 19:59:11 - training - INFO - Epoch [5/5][411/690] lr: 3.7e-06, eta: 5:46:18.782625, loss: 1.2897
2023-04-12 19:59:18 - training - INFO - Epoch [5/5][421/690] lr: 3.5e-06, eta: 5:37:53.475625, loss: 0.7930
2023-04-12 19:59:26 - training - INFO - Epoch [5/5][431/690] lr: 3.4e-06, eta: 5:29:52.093036, loss: 0.8600
2023-04-12 19:59:34 - training - INFO - Epoch [5/5][441/690] lr: 3.3e-06, eta: 5:22:10.706664, loss: 0.6585
2023-04-12 19:59:41 - training - INFO - Epoch [5/5][451/690] lr: 3.1e-06, eta: 5:14:48.988571, loss: 0.5324
2023-04-12 19:59:49 - training - INFO - Epoch [5/5][461/690] lr: 3.0e-06, eta: 5:07:47.064238, loss: 1.0916
2023-04-12 19:59:57 - training - INFO - Epoch [5/5][471/690] lr: 2.9e-06, eta: 5:01:03.300555, loss: 0.5770
2023-04-12 20:00:04 - training - INFO - Epoch [5/5][481/690] lr: 2.8e-06, eta: 4:54:34.454031, loss: 1.3609
2023-04-12 20:00:12 - training - INFO - Epoch [5/5][491/690] lr: 2.6e-06, eta: 4:48:22.450682, loss: 1.0988
2023-04-12 20:00:19 - training - INFO - Epoch [5/5][501/690] lr: 2.5e-06, eta: 4:42:24.729876, loss: 0.9546
2023-04-12 20:00:27 - training - INFO - Epoch [5/5][511/690] lr: 2.4e-06, eta: 4:36:42.569706, loss: 0.8682
2023-04-12 20:00:35 - training - INFO - Epoch [5/5][521/690] lr: 2.2e-06, eta: 4:31:11.198374, loss: 0.5098
2023-04-12 20:00:43 - training - INFO - Epoch [5/5][531/690] lr: 2.1e-06, eta: 4:25:53.181510, loss: 1.0828
2023-04-12 20:00:50 - training - INFO - Epoch [5/5][541/690] lr: 2.0e-06, eta: 4:20:46.292129, loss: 1.0361
2023-04-12 20:00:58 - training - INFO - Epoch [5/5][551/690] lr: 1.8e-06, eta: 4:15:49.315007, loss: 0.8333
2023-04-12 20:01:06 - training - INFO - Epoch [5/5][561/690] lr: 1.7e-06, eta: 4:11:03.355782, loss: 0.6063
2023-04-12 20:01:13 - training - INFO - Epoch [5/5][571/690] lr: 1.6e-06, eta: 4:06:26.293527, loss: 0.5951
2023-04-12 20:01:21 - training - INFO - Epoch [5/5][581/690] lr: 1.4e-06, eta: 4:01:58.393753, loss: 1.1449
2023-04-12 20:01:28 - training - INFO - Epoch [5/5][591/690] lr: 1.3e-06, eta: 3:57:39.376860, loss: 0.9991
2023-04-12 20:01:36 - training - INFO - Epoch [5/5][601/690] lr: 1.2e-06, eta: 3:53:29.749523, loss: 0.8801
2023-04-12 20:01:44 - training - INFO - Epoch [5/5][611/690] lr: 1.0e-06, eta: 3:49:29.025084, loss: 0.7121
2023-04-12 20:01:51 - training - INFO - Epoch [5/5][621/690] lr: 9.1e-07, eta: 3:45:33.695535, loss: 0.7944
2023-04-12 20:01:59 - training - INFO - Epoch [5/5][631/690] lr: 7.8e-07, eta: 3:41:45.598249, loss: 0.5058
2023-04-12 20:02:06 - training - INFO - Epoch [5/5][641/690] lr: 6.4e-07, eta: 3:38:04.878182, loss: 0.6873
2023-04-12 20:02:14 - training - INFO - Epoch [5/5][651/690] lr: 5.1e-07, eta: 3:34:31.179108, loss: 0.5590
2023-04-12 20:02:22 - training - INFO - Epoch [5/5][661/690] lr: 3.8e-07, eta: 3:31:03.426610, loss: 0.5990
2023-04-12 20:02:30 - training - INFO - Epoch [5/5][671/690] lr: 2.5e-07, eta: 3:27:41.814120, loss: 0.5634
2023-04-12 20:02:37 - training - INFO - Epoch [5/5][681/690] lr: 1.2e-07, eta: 3:24:25.628856, loss: 0.7230
2023-04-12 20:03:59 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.8501, Validation Metrics: {'exact_match': 22.11874272409779, 'f1': 25.61260373851794}, Test Metrics: {'exact_match': 25.319396051103368, 'f1': 28.32617037274567}
2023-04-12 20:04:36 - training - INFO - Final Test - Train Loss: 0.8501, Test Metrics: {'exact_match': 25.319396051103368, 'f1': 28.32617037274567}
