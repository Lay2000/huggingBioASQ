2023-04-11 15:46:16 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-44a167365c0b341b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepakvk/xlnet-base-cased-squad2'}, 'data': {'task_type': 'list', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_list_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 272.06it/s]
Map:   0%|          | 0/6878 [00:00<?, ? examples/s]Map:  15%|█▍        | 1000/6878 [00:00<00:04, 1426.91 examples/s]Map:  29%|██▉       | 2000/6878 [00:01<00:03, 1474.90 examples/s]Map:  44%|████▎     | 3000/6878 [00:02<00:02, 1478.07 examples/s]Map:  58%|█████▊    | 4000/6878 [00:02<00:01, 1486.62 examples/s]Map:  73%|███████▎  | 5000/6878 [00:03<00:01, 1476.18 examples/s]Map:  87%|████████▋ | 6000/6878 [00:04<00:00, 1488.75 examples/s]Map: 100%|██████████| 6878/6878 [00:04<00:00, 1358.31 examples/s]                                                                 Map:   0%|          | 0/859 [00:00<?, ? examples/s]Map: 100%|██████████| 859/859 [00:00<00:00, 1183.88 examples/s]                                                               Map:   0%|          | 0/861 [00:00<?, ? examples/s]Map: 100%|██████████| 861/861 [00:00<00:00, 1155.14 examples/s]                                                               2023-04-11 15:47:53 - training - INFO - First Test - Val Metrics:{'exact_match': 0.46565774155995343, 'f1': 2.111707080855453} Test Metrics: {'exact_match': 0.4645760743321719, 'f1': 2.558276426289279}
2023-04-11 15:47:53 - training - INFO - Epoch [1/5][1/690] lr: 4.5e-05, eta: 3 days, 7:45:31.719484, loss: 6.4936
2023-04-11 15:48:02 - training - INFO - Epoch [1/5][11/690] lr: 4.5e-05, eta: 7:59:07.419482, loss: 4.0011
2023-04-11 15:48:12 - training - INFO - Epoch [1/5][21/690] lr: 4.5e-05, eta: 4:36:20.967219, loss: 3.2693
2023-04-11 15:48:22 - training - INFO - Epoch [1/5][31/690] lr: 4.5e-05, eta: 3:25:04.013423, loss: 2.9011
2023-04-11 15:48:32 - training - INFO - Epoch [1/5][41/690] lr: 4.5e-05, eta: 2:48:41.978937, loss: 2.8526
2023-04-11 15:48:42 - training - INFO - Epoch [1/5][51/690] lr: 4.5e-05, eta: 2:26:00.212109, loss: 2.3130
2023-04-11 15:48:51 - training - INFO - Epoch [1/5][61/690] lr: 4.5e-05, eta: 2:10:30.525119, loss: 2.9935
2023-04-11 15:49:01 - training - INFO - Epoch [1/5][71/690] lr: 4.4e-05, eta: 1:59:39.013263, loss: 2.4459
2023-04-11 15:49:10 - training - INFO - Epoch [1/5][81/690] lr: 4.4e-05, eta: 1:50:48.553050, loss: 2.7920
2023-04-11 15:49:18 - training - INFO - Epoch [1/5][91/690] lr: 4.4e-05, eta: 1:43:22.917504, loss: 3.4146
2023-04-11 15:49:27 - training - INFO - Epoch [1/5][101/690] lr: 4.4e-05, eta: 1:37:27.206644, loss: 1.5230
2023-04-11 15:49:34 - training - INFO - Epoch [1/5][111/690] lr: 4.4e-05, eta: 1:32:19.324203, loss: 2.2313
2023-04-11 15:49:43 - training - INFO - Epoch [1/5][121/690] lr: 4.4e-05, eta: 1:28:28.376794, loss: 1.3684
2023-04-11 15:49:52 - training - INFO - Epoch [1/5][131/690] lr: 4.4e-05, eta: 1:25:11.552072, loss: 1.3415
2023-04-11 15:50:01 - training - INFO - Epoch [1/5][141/690] lr: 4.4e-05, eta: 1:22:18.781770, loss: 2.6203
2023-04-11 15:50:09 - training - INFO - Epoch [1/5][151/690] lr: 4.3e-05, eta: 1:19:36.800246, loss: 2.2467
2023-04-11 15:50:17 - training - INFO - Epoch [1/5][161/690] lr: 4.3e-05, eta: 1:17:10.944890, loss: 2.6056
2023-04-11 15:50:25 - training - INFO - Epoch [1/5][171/690] lr: 4.3e-05, eta: 1:15:01.161996, loss: 2.3721
2023-04-11 15:50:33 - training - INFO - Epoch [1/5][181/690] lr: 4.3e-05, eta: 1:12:59.557756, loss: 1.6165
2023-04-11 15:50:41 - training - INFO - Epoch [1/5][191/690] lr: 4.3e-05, eta: 1:11:15.446251, loss: 2.2743
2023-04-11 15:50:49 - training - INFO - Epoch [1/5][201/690] lr: 4.3e-05, eta: 1:09:45.693198, loss: 2.0800
2023-04-11 15:50:57 - training - INFO - Epoch [1/5][211/690] lr: 4.3e-05, eta: 1:08:19.401482, loss: 1.9708
2023-04-11 15:51:05 - training - INFO - Epoch [1/5][221/690] lr: 4.2e-05, eta: 1:07:01.606485, loss: 1.2350
2023-04-11 15:51:14 - training - INFO - Epoch [1/5][231/690] lr: 4.2e-05, eta: 1:05:51.203397, loss: 3.0145
2023-04-11 15:51:23 - training - INFO - Epoch [1/5][241/690] lr: 4.2e-05, eta: 1:04:53.158800, loss: 2.2639
2023-04-11 15:51:32 - training - INFO - Epoch [1/5][251/690] lr: 4.2e-05, eta: 1:04:02.005398, loss: 1.9200
2023-04-11 15:51:40 - training - INFO - Epoch [1/5][261/690] lr: 4.2e-05, eta: 1:03:10.729221, loss: 2.4670
2023-04-11 15:51:49 - training - INFO - Epoch [1/5][271/690] lr: 4.2e-05, eta: 1:02:17.985823, loss: 1.8390
2023-04-11 15:51:58 - training - INFO - Epoch [1/5][281/690] lr: 4.2e-05, eta: 1:01:32.800841, loss: 1.2171
2023-04-11 15:52:06 - training - INFO - Epoch [1/5][291/690] lr: 4.2e-05, eta: 1:00:44.645706, loss: 1.8236
2023-04-11 15:52:16 - training - INFO - Epoch [1/5][301/690] lr: 4.1e-05, eta: 1:00:17.168128, loss: 1.9941
2023-04-11 15:52:26 - training - INFO - Epoch [1/5][311/690] lr: 4.1e-05, eta: 0:59:51.687746, loss: 2.2086
2023-04-11 15:52:35 - training - INFO - Epoch [1/5][321/690] lr: 4.1e-05, eta: 0:59:20.342037, loss: 1.4936
2023-04-11 15:52:45 - training - INFO - Epoch [1/5][331/690] lr: 4.1e-05, eta: 0:58:54.064044, loss: 1.2391
2023-04-11 15:52:56 - training - INFO - Epoch [1/5][341/690] lr: 4.1e-05, eta: 0:58:33.325450, loss: 1.6059
2023-04-11 15:53:05 - training - INFO - Epoch [1/5][351/690] lr: 4.1e-05, eta: 0:58:08.789121, loss: 2.7394
2023-04-11 15:53:15 - training - INFO - Epoch [1/5][361/690] lr: 4.1e-05, eta: 0:57:45.079572, loss: 1.8827
2023-04-11 15:53:25 - training - INFO - Epoch [1/5][371/690] lr: 4.1e-05, eta: 0:57:22.060285, loss: 1.0725
2023-04-11 15:53:35 - training - INFO - Epoch [1/5][381/690] lr: 4.0e-05, eta: 0:57:00.636813, loss: 1.9753
2023-04-11 15:53:45 - training - INFO - Epoch [1/5][391/690] lr: 4.0e-05, eta: 0:56:39.757305, loss: 1.8844
2023-04-11 15:53:54 - training - INFO - Epoch [1/5][401/690] lr: 4.0e-05, eta: 0:56:16.358934, loss: 2.0851
2023-04-11 15:54:04 - training - INFO - Epoch [1/5][411/690] lr: 4.0e-05, eta: 0:55:55.876530, loss: 2.1737
2023-04-11 15:54:13 - training - INFO - Epoch [1/5][421/690] lr: 4.0e-05, eta: 0:55:33.041933, loss: 1.9440
2023-04-11 15:54:24 - training - INFO - Epoch [1/5][431/690] lr: 4.0e-05, eta: 0:55:16.389614, loss: 2.0019
2023-04-11 15:54:33 - training - INFO - Epoch [1/5][441/690] lr: 4.0e-05, eta: 0:54:54.602244, loss: 1.4635
2023-04-11 15:54:43 - training - INFO - Epoch [1/5][451/690] lr: 3.9e-05, eta: 0:54:36.578443, loss: 1.9173
2023-04-11 15:54:53 - training - INFO - Epoch [1/5][461/690] lr: 3.9e-05, eta: 0:54:19.737642, loss: 1.8737
2023-04-11 15:55:02 - training - INFO - Epoch [1/5][471/690] lr: 3.9e-05, eta: 0:53:58.664535, loss: 1.4323
2023-04-11 15:55:13 - training - INFO - Epoch [1/5][481/690] lr: 3.9e-05, eta: 0:53:44.301341, loss: 2.1488
2023-04-11 15:55:22 - training - INFO - Epoch [1/5][491/690] lr: 3.9e-05, eta: 0:53:27.641811, loss: 2.2617
2023-04-11 15:55:33 - training - INFO - Epoch [1/5][501/690] lr: 3.9e-05, eta: 0:53:12.357378, loss: 0.9290
2023-04-11 15:55:42 - training - INFO - Epoch [1/5][511/690] lr: 3.9e-05, eta: 0:52:55.113382, loss: 1.4533
2023-04-11 15:55:53 - training - INFO - Epoch [1/5][521/690] lr: 3.9e-05, eta: 0:52:41.454227, loss: 1.7027
2023-04-11 15:56:02 - training - INFO - Epoch [1/5][531/690] lr: 3.8e-05, eta: 0:52:21.421962, loss: 1.8209
2023-04-11 15:56:11 - training - INFO - Epoch [1/5][541/690] lr: 3.8e-05, eta: 0:52:05.415055, loss: 1.8037
2023-04-11 15:56:20 - training - INFO - Epoch [1/5][551/690] lr: 3.8e-05, eta: 0:51:42.312668, loss: 1.8061
2023-04-11 15:56:29 - training - INFO - Epoch [1/5][561/690] lr: 3.8e-05, eta: 0:51:22.389660, loss: 1.8703
2023-04-11 15:56:38 - training - INFO - Epoch [1/5][571/690] lr: 3.8e-05, eta: 0:51:02.271382, loss: 1.6821
2023-04-11 15:56:47 - training - INFO - Epoch [1/5][581/690] lr: 3.8e-05, eta: 0:50:47.050140, loss: 1.4651
2023-04-11 15:56:56 - training - INFO - Epoch [1/5][591/690] lr: 3.8e-05, eta: 0:50:27.106341, loss: 1.7986
2023-04-11 15:57:05 - training - INFO - Epoch [1/5][601/690] lr: 3.7e-05, eta: 0:50:09.418643, loss: 1.2244
2023-04-11 15:57:14 - training - INFO - Epoch [1/5][611/690] lr: 3.7e-05, eta: 0:49:52.848249, loss: 2.0286
2023-04-11 15:57:23 - training - INFO - Epoch [1/5][621/690] lr: 3.7e-05, eta: 0:49:32.735832, loss: 1.6116
2023-04-11 15:57:31 - training - INFO - Epoch [1/5][631/690] lr: 3.7e-05, eta: 0:49:13.246418, loss: 1.5457
2023-04-11 15:57:40 - training - INFO - Epoch [1/5][641/690] lr: 3.7e-05, eta: 0:48:56.708376, loss: 2.0778
2023-04-11 15:57:49 - training - INFO - Epoch [1/5][651/690] lr: 3.7e-05, eta: 0:48:39.594915, loss: 2.2932
2023-04-11 15:57:58 - training - INFO - Epoch [1/5][661/690] lr: 3.7e-05, eta: 0:48:21.419012, loss: 1.6228
2023-04-11 15:58:06 - training - INFO - Epoch [1/5][671/690] lr: 3.7e-05, eta: 0:48:03.206942, loss: 1.5353
2023-04-11 15:58:15 - training - INFO - Epoch [1/5][681/690] lr: 3.6e-05, eta: 0:47:44.320056, loss: 1.9254
2023-04-11 15:59:07 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 2.0229, Validation Metrics: {'exact_match': 20.60535506402794, 'f1': 24.5543122647087}
2023-04-11 15:59:08 - training - INFO - Epoch [2/5][1/690] lr: 3.6e-05, eta: 30 days, 5:58:03.961229, loss: 1.7785
2023-04-11 15:59:16 - training - INFO - Epoch [2/5][11/690] lr: 3.6e-05, eta: 2 days, 18:32:06.085197, loss: 0.4541
2023-04-11 15:59:25 - training - INFO - Epoch [2/5][21/690] lr: 3.6e-05, eta: 1 day, 11:07:53.617512, loss: 1.5212
2023-04-11 15:59:34 - training - INFO - Epoch [2/5][31/690] lr: 3.6e-05, eta: 1 day, 0:00:17.765317, loss: 0.8460
2023-04-11 15:59:43 - training - INFO - Epoch [2/5][41/690] lr: 3.6e-05, eta: 18:18:42.805648, loss: 1.7835
2023-04-11 15:59:52 - training - INFO - Epoch [2/5][51/690] lr: 3.6e-05, eta: 14:50:07.610058, loss: 1.0889
2023-04-11 16:00:00 - training - INFO - Epoch [2/5][61/690] lr: 3.6e-05, eta: 12:29:48.256532, loss: 0.9952
2023-04-11 16:00:08 - training - INFO - Epoch [2/5][71/690] lr: 3.5e-05, eta: 10:48:52.243296, loss: 1.3690
2023-04-11 16:00:18 - training - INFO - Epoch [2/5][81/690] lr: 3.5e-05, eta: 9:33:44.448738, loss: 1.2446
2023-04-11 16:00:27 - training - INFO - Epoch [2/5][91/690] lr: 3.5e-05, eta: 8:35:04.731425, loss: 1.5412
2023-04-11 16:00:37 - training - INFO - Epoch [2/5][101/690] lr: 3.5e-05, eta: 7:47:49.941561, loss: 1.2139
2023-04-11 16:00:45 - training - INFO - Epoch [2/5][111/690] lr: 3.5e-05, eta: 7:08:25.748943, loss: 1.4028
2023-04-11 16:00:54 - training - INFO - Epoch [2/5][121/690] lr: 3.5e-05, eta: 6:36:09.236437, loss: 1.7509
2023-04-11 16:01:03 - training - INFO - Epoch [2/5][131/690] lr: 3.5e-05, eta: 6:08:35.578994, loss: 1.3312
2023-04-11 16:01:12 - training - INFO - Epoch [2/5][141/690] lr: 3.4e-05, eta: 5:45:00.389256, loss: 2.1615
2023-04-11 16:01:20 - training - INFO - Epoch [2/5][151/690] lr: 3.4e-05, eta: 5:24:09.630586, loss: 0.7473
2023-04-11 16:01:29 - training - INFO - Epoch [2/5][161/690] lr: 3.4e-05, eta: 5:06:08.591384, loss: 1.0352
2023-04-11 16:01:38 - training - INFO - Epoch [2/5][171/690] lr: 3.4e-05, eta: 4:50:15.860907, loss: 1.4791
2023-04-11 16:01:48 - training - INFO - Epoch [2/5][181/690] lr: 3.4e-05, eta: 4:36:09.760095, loss: 1.2328
2023-04-11 16:01:56 - training - INFO - Epoch [2/5][191/690] lr: 3.4e-05, eta: 4:23:19.280028, loss: 1.6846
2023-04-11 16:02:05 - training - INFO - Epoch [2/5][201/690] lr: 3.4e-05, eta: 4:11:57.493032, loss: 1.5595
2023-04-11 16:02:14 - training - INFO - Epoch [2/5][211/690] lr: 3.4e-05, eta: 4:01:35.069152, loss: 1.4314
2023-04-11 16:02:25 - training - INFO - Epoch [2/5][221/690] lr: 3.3e-05, eta: 3:52:26.758151, loss: 1.3127
2023-04-11 16:02:34 - training - INFO - Epoch [2/5][231/690] lr: 3.3e-05, eta: 3:43:54.947160, loss: 1.4749
2023-04-11 16:02:44 - training - INFO - Epoch [2/5][241/690] lr: 3.3e-05, eta: 3:36:03.278567, loss: 1.4994
2023-04-11 16:02:53 - training - INFO - Epoch [2/5][251/690] lr: 3.3e-05, eta: 3:28:47.687074, loss: 1.3633
2023-04-11 16:03:03 - training - INFO - Epoch [2/5][261/690] lr: 3.3e-05, eta: 3:22:06.095964, loss: 1.0988
2023-04-11 16:03:11 - training - INFO - Epoch [2/5][271/690] lr: 3.3e-05, eta: 3:15:38.282655, loss: 1.6138
2023-04-11 16:03:20 - training - INFO - Epoch [2/5][281/690] lr: 3.3e-05, eta: 3:09:44.442360, loss: 1.0854
2023-04-11 16:03:28 - training - INFO - Epoch [2/5][291/690] lr: 3.2e-05, eta: 3:04:10.557921, loss: 1.9944
2023-04-11 16:03:37 - training - INFO - Epoch [2/5][301/690] lr: 3.2e-05, eta: 2:59:05.805050, loss: 1.6623
2023-04-11 16:03:47 - training - INFO - Epoch [2/5][311/690] lr: 3.2e-05, eta: 2:54:24.120176, loss: 1.1978
2023-04-11 16:03:56 - training - INFO - Epoch [2/5][321/690] lr: 3.2e-05, eta: 2:49:56.450397, loss: 0.9760
2023-04-11 16:04:05 - training - INFO - Epoch [2/5][331/690] lr: 3.2e-05, eta: 2:45:39.523154, loss: 1.6908
2023-04-11 16:04:15 - training - INFO - Epoch [2/5][341/690] lr: 3.2e-05, eta: 2:41:47.644197, loss: 1.3466
2023-04-11 16:04:24 - training - INFO - Epoch [2/5][351/690] lr: 3.2e-05, eta: 2:37:58.418559, loss: 1.0897
2023-04-11 16:04:33 - training - INFO - Epoch [2/5][361/690] lr: 3.2e-05, eta: 2:34:26.545917, loss: 1.8833
2023-04-11 16:04:41 - training - INFO - Epoch [2/5][371/690] lr: 3.1e-05, eta: 2:30:56.604469, loss: 0.8347
2023-04-11 16:04:50 - training - INFO - Epoch [2/5][381/690] lr: 3.1e-05, eta: 2:27:39.429612, loss: 2.5582
2023-04-11 16:04:59 - training - INFO - Epoch [2/5][391/690] lr: 3.1e-05, eta: 2:24:36.676078, loss: 1.3731
2023-04-11 16:05:08 - training - INFO - Epoch [2/5][401/690] lr: 3.1e-05, eta: 2:21:41.093742, loss: 1.3540
2023-04-11 16:05:17 - training - INFO - Epoch [2/5][411/690] lr: 3.1e-05, eta: 2:18:49.892922, loss: 0.9712
2023-04-11 16:05:25 - training - INFO - Epoch [2/5][421/690] lr: 3.1e-05, eta: 2:16:04.309049, loss: 1.0497
2023-04-11 16:05:33 - training - INFO - Epoch [2/5][431/690] lr: 3.1e-05, eta: 2:13:28.202419, loss: 0.8828
2023-04-11 16:05:42 - training - INFO - Epoch [2/5][441/690] lr: 3.1e-05, eta: 2:11:00.675492, loss: 1.5761
2023-04-11 16:05:51 - training - INFO - Epoch [2/5][451/690] lr: 3.0e-05, eta: 2:08:38.556290, loss: 1.4317
2023-04-11 16:06:00 - training - INFO - Epoch [2/5][461/690] lr: 3.0e-05, eta: 2:06:22.952517, loss: 1.3266
2023-04-11 16:06:08 - training - INFO - Epoch [2/5][471/690] lr: 3.0e-05, eta: 2:04:08.429448, loss: 1.5193
2023-04-11 16:06:16 - training - INFO - Epoch [2/5][481/690] lr: 3.0e-05, eta: 2:02:00.413904, loss: 0.8827
2023-04-11 16:06:24 - training - INFO - Epoch [2/5][491/690] lr: 3.0e-05, eta: 1:59:57.140192, loss: 1.6476
2023-04-11 16:06:33 - training - INFO - Epoch [2/5][501/690] lr: 3.0e-05, eta: 1:57:59.074500, loss: 1.0764
2023-04-11 16:06:42 - training - INFO - Epoch [2/5][511/690] lr: 3.0e-05, eta: 1:56:07.593104, loss: 1.1837
2023-04-11 16:06:50 - training - INFO - Epoch [2/5][521/690] lr: 2.9e-05, eta: 1:54:18.909596, loss: 1.1298
2023-04-11 16:06:59 - training - INFO - Epoch [2/5][531/690] lr: 2.9e-05, eta: 1:52:34.096041, loss: 1.4282
2023-04-11 16:07:08 - training - INFO - Epoch [2/5][541/690] lr: 2.9e-05, eta: 1:50:54.389862, loss: 1.4211
2023-04-11 16:07:16 - training - INFO - Epoch [2/5][551/690] lr: 2.9e-05, eta: 1:49:16.926311, loss: 1.1642
2023-04-11 16:07:25 - training - INFO - Epoch [2/5][561/690] lr: 2.9e-05, eta: 1:47:44.195280, loss: 1.6829
2023-04-11 16:07:34 - training - INFO - Epoch [2/5][571/690] lr: 2.9e-05, eta: 1:46:12.381479, loss: 1.2730
2023-04-11 16:07:43 - training - INFO - Epoch [2/5][581/690] lr: 2.9e-05, eta: 1:44:44.401050, loss: 1.0815
2023-04-11 16:07:52 - training - INFO - Epoch [2/5][591/690] lr: 2.9e-05, eta: 1:43:18.577887, loss: 1.5672
2023-04-11 16:08:00 - training - INFO - Epoch [2/5][601/690] lr: 2.8e-05, eta: 1:41:55.364255, loss: 1.2767
2023-04-11 16:08:10 - training - INFO - Epoch [2/5][611/690] lr: 2.8e-05, eta: 1:40:37.860284, loss: 1.3796
2023-04-11 16:08:19 - training - INFO - Epoch [2/5][621/690] lr: 2.8e-05, eta: 1:39:21.172614, loss: 0.8752
2023-04-11 16:08:27 - training - INFO - Epoch [2/5][631/690] lr: 2.8e-05, eta: 1:38:04.851373, loss: 0.6298
2023-04-11 16:08:36 - training - INFO - Epoch [2/5][641/690] lr: 2.8e-05, eta: 1:36:51.481111, loss: 1.1067
2023-04-11 16:08:46 - training - INFO - Epoch [2/5][651/690] lr: 2.8e-05, eta: 1:35:42.268857, loss: 0.9811
2023-04-11 16:08:55 - training - INFO - Epoch [2/5][661/690] lr: 2.8e-05, eta: 1:34:32.335136, loss: 1.3614
2023-04-11 16:09:04 - training - INFO - Epoch [2/5][671/690] lr: 2.7e-05, eta: 1:33:25.398624, loss: 0.9707
2023-04-11 16:09:13 - training - INFO - Epoch [2/5][681/690] lr: 2.7e-05, eta: 1:32:21.455712, loss: 1.4993
2023-04-11 16:10:06 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.3410, Validation Metrics: {'exact_match': 29.68568102444703, 'f1': 33.88429933570393}
2023-04-11 16:10:06 - training - INFO - Epoch [3/5][1/690] lr: 2.7e-05, eta: 56 days, 12:45:02.212250, loss: 1.2323
2023-04-11 16:10:15 - training - INFO - Epoch [3/5][11/690] lr: 2.7e-05, eta: 5 days, 3:43:35.517734, loss: 0.6269
2023-04-11 16:10:24 - training - INFO - Epoch [3/5][21/690] lr: 2.7e-05, eta: 2 days, 17:00:45.050832, loss: 0.6652
2023-04-11 16:10:32 - training - INFO - Epoch [3/5][31/690] lr: 2.7e-05, eta: 1 day, 20:10:44.334267, loss: 1.2898
2023-04-11 16:10:41 - training - INFO - Epoch [3/5][41/690] lr: 2.7e-05, eta: 1 day, 9:30:07.764389, loss: 0.9459
2023-04-11 16:10:49 - training - INFO - Epoch [3/5][51/690] lr: 2.7e-05, eta: 1 day, 3:00:21.267297, loss: 1.2148
2023-04-11 16:10:58 - training - INFO - Epoch [3/5][61/690] lr: 2.6e-05, eta: 22:38:47.593726, loss: 1.1750
2023-04-11 16:11:07 - training - INFO - Epoch [3/5][71/690] lr: 2.6e-05, eta: 19:31:06.696964, loss: 1.3196
2023-04-11 16:11:15 - training - INFO - Epoch [3/5][81/690] lr: 2.6e-05, eta: 17:09:27.114609, loss: 1.3652
2023-04-11 16:11:24 - training - INFO - Epoch [3/5][91/690] lr: 2.6e-05, eta: 15:18:50.138376, loss: 0.6594
2023-04-11 16:11:32 - training - INFO - Epoch [3/5][101/690] lr: 2.6e-05, eta: 13:50:12.316012, loss: 0.7356
2023-04-11 16:11:41 - training - INFO - Epoch [3/5][111/690] lr: 2.6e-05, eta: 12:37:27.806817, loss: 0.9668
2023-04-11 16:11:50 - training - INFO - Epoch [3/5][121/690] lr: 2.6e-05, eta: 11:36:46.514120, loss: 0.9537
2023-04-11 16:11:58 - training - INFO - Epoch [3/5][131/690] lr: 2.6e-05, eta: 10:45:06.974560, loss: 1.2412
2023-04-11 16:12:06 - training - INFO - Epoch [3/5][141/690] lr: 2.5e-05, eta: 10:00:48.216219, loss: 1.2756
2023-04-11 16:12:15 - training - INFO - Epoch [3/5][151/690] lr: 2.5e-05, eta: 9:22:37.594825, loss: 1.2851
2023-04-11 16:12:24 - training - INFO - Epoch [3/5][161/690] lr: 2.5e-05, eta: 8:49:09.022877, loss: 1.2731
2023-04-11 16:12:33 - training - INFO - Epoch [3/5][171/690] lr: 2.5e-05, eta: 8:19:34.162029, loss: 0.6210
2023-04-11 16:12:42 - training - INFO - Epoch [3/5][181/690] lr: 2.5e-05, eta: 7:53:03.396517, loss: 0.6634
2023-04-11 16:12:50 - training - INFO - Epoch [3/5][191/690] lr: 2.5e-05, eta: 7:29:18.363266, loss: 1.6167
2023-04-11 16:12:58 - training - INFO - Epoch [3/5][201/690] lr: 2.5e-05, eta: 7:07:52.613553, loss: 1.7764
2023-04-11 16:13:06 - training - INFO - Epoch [3/5][211/690] lr: 2.4e-05, eta: 6:48:18.921470, loss: 1.8553
2023-04-11 16:13:15 - training - INFO - Epoch [3/5][221/690] lr: 2.4e-05, eta: 6:30:42.368863, loss: 0.5678
2023-04-11 16:13:23 - training - INFO - Epoch [3/5][231/690] lr: 2.4e-05, eta: 6:14:32.878737, loss: 1.5530
2023-04-11 16:13:31 - training - INFO - Epoch [3/5][241/690] lr: 2.4e-05, eta: 5:59:36.096580, loss: 0.9647
2023-04-11 16:13:39 - training - INFO - Epoch [3/5][251/690] lr: 2.4e-05, eta: 5:45:59.718560, loss: 0.6801
2023-04-11 16:13:48 - training - INFO - Epoch [3/5][261/690] lr: 2.4e-05, eta: 5:33:26.972805, loss: 1.0979
2023-04-11 16:13:56 - training - INFO - Epoch [3/5][271/690] lr: 2.4e-05, eta: 5:21:45.606045, loss: 1.0462
2023-04-11 16:14:04 - training - INFO - Epoch [3/5][281/690] lr: 2.4e-05, eta: 5:10:50.794572, loss: 0.7016
2023-04-11 16:14:12 - training - INFO - Epoch [3/5][291/690] lr: 2.3e-05, eta: 5:00:43.658334, loss: 1.1957
2023-04-11 16:14:20 - training - INFO - Epoch [3/5][301/690] lr: 2.3e-05, eta: 4:51:12.790171, loss: 0.8224
2023-04-11 16:14:28 - training - INFO - Epoch [3/5][311/690] lr: 2.3e-05, eta: 4:42:14.380787, loss: 0.9118
2023-04-11 16:14:37 - training - INFO - Epoch [3/5][321/690] lr: 2.3e-05, eta: 4:33:58.120146, loss: 1.2562
2023-04-11 16:14:44 - training - INFO - Epoch [3/5][331/690] lr: 2.3e-05, eta: 4:26:03.781203, loss: 1.4592
2023-04-11 16:14:52 - training - INFO - Epoch [3/5][341/690] lr: 2.3e-05, eta: 4:18:38.004553, loss: 0.9324
2023-04-11 16:15:01 - training - INFO - Epoch [3/5][351/690] lr: 2.3e-05, eta: 4:11:40.890873, loss: 1.4332
2023-04-11 16:15:09 - training - INFO - Epoch [3/5][361/690] lr: 2.2e-05, eta: 4:05:07.868841, loss: 0.5502
2023-04-11 16:15:18 - training - INFO - Epoch [3/5][371/690] lr: 2.2e-05, eta: 3:58:56.381299, loss: 1.4647
2023-04-11 16:15:27 - training - INFO - Epoch [3/5][381/690] lr: 2.2e-05, eta: 3:53:07.295883, loss: 0.5409
2023-04-11 16:15:35 - training - INFO - Epoch [3/5][391/690] lr: 2.2e-05, eta: 3:47:30.047222, loss: 1.1222
2023-04-11 16:15:43 - training - INFO - Epoch [3/5][401/690] lr: 2.2e-05, eta: 3:42:10.484116, loss: 1.3198
2023-04-11 16:15:52 - training - INFO - Epoch [3/5][411/690] lr: 2.2e-05, eta: 3:37:06.609681, loss: 1.1191
2023-04-11 16:16:00 - training - INFO - Epoch [3/5][421/690] lr: 2.2e-05, eta: 3:32:14.379437, loss: 0.9029
2023-04-11 16:16:09 - training - INFO - Epoch [3/5][431/690] lr: 2.2e-05, eta: 3:27:38.084640, loss: 1.2097
2023-04-11 16:16:18 - training - INFO - Epoch [3/5][441/690] lr: 2.1e-05, eta: 3:23:18.058722, loss: 0.8759
2023-04-11 16:16:26 - training - INFO - Epoch [3/5][451/690] lr: 2.1e-05, eta: 3:19:04.495174, loss: 0.8497
2023-04-11 16:16:35 - training - INFO - Epoch [3/5][461/690] lr: 2.1e-05, eta: 3:15:00.852982, loss: 1.3347
2023-04-11 16:16:43 - training - INFO - Epoch [3/5][471/690] lr: 2.1e-05, eta: 3:11:05.050896, loss: 1.7893
2023-04-11 16:16:51 - training - INFO - Epoch [3/5][481/690] lr: 2.1e-05, eta: 3:07:19.336547, loss: 1.0942
2023-04-11 16:16:59 - training - INFO - Epoch [3/5][491/690] lr: 2.1e-05, eta: 3:03:43.958671, loss: 0.9430
2023-04-11 16:17:08 - training - INFO - Epoch [3/5][501/690] lr: 2.1e-05, eta: 3:00:16.268475, loss: 0.8369
2023-04-11 16:17:16 - training - INFO - Epoch [3/5][511/690] lr: 2.1e-05, eta: 2:56:58.618756, loss: 0.8820
2023-04-11 16:17:25 - training - INFO - Epoch [3/5][521/690] lr: 2.0e-05, eta: 2:53:47.735001, loss: 0.9674
2023-04-11 16:17:33 - training - INFO - Epoch [3/5][531/690] lr: 2.0e-05, eta: 2:50:41.460369, loss: 1.4246
2023-04-11 16:17:42 - training - INFO - Epoch [3/5][541/690] lr: 2.0e-05, eta: 2:47:46.716678, loss: 1.1251
2023-04-11 16:17:51 - training - INFO - Epoch [3/5][551/690] lr: 2.0e-05, eta: 2:44:56.324997, loss: 0.8609
2023-04-11 16:18:00 - training - INFO - Epoch [3/5][561/690] lr: 2.0e-05, eta: 2:42:10.125999, loss: 0.8106
2023-04-11 16:18:09 - training - INFO - Epoch [3/5][571/690] lr: 2.0e-05, eta: 2:39:31.555069, loss: 0.7871
2023-04-11 16:18:17 - training - INFO - Epoch [3/5][581/690] lr: 2.0e-05, eta: 2:36:55.590353, loss: 0.7044
2023-04-11 16:18:26 - training - INFO - Epoch [3/5][591/690] lr: 1.9e-05, eta: 2:34:26.104770, loss: 1.0143
2023-04-11 16:18:35 - training - INFO - Epoch [3/5][601/690] lr: 1.9e-05, eta: 2:32:02.703128, loss: 1.3907
2023-04-11 16:18:44 - training - INFO - Epoch [3/5][611/690] lr: 1.9e-05, eta: 2:29:43.280199, loss: 1.0581
2023-04-11 16:18:52 - training - INFO - Epoch [3/5][621/690] lr: 1.9e-05, eta: 2:27:27.558879, loss: 1.1602
2023-04-11 16:19:01 - training - INFO - Epoch [3/5][631/690] lr: 1.9e-05, eta: 2:25:15.073812, loss: 1.2095
2023-04-11 16:19:10 - training - INFO - Epoch [3/5][641/690] lr: 1.9e-05, eta: 2:23:07.576485, loss: 0.9262
2023-04-11 16:19:18 - training - INFO - Epoch [3/5][651/690] lr: 1.9e-05, eta: 2:21:02.563776, loss: 1.1300
2023-04-11 16:19:27 - training - INFO - Epoch [3/5][661/690] lr: 1.9e-05, eta: 2:19:00.616060, loss: 1.2261
2023-04-11 16:19:36 - training - INFO - Epoch [3/5][671/690] lr: 1.8e-05, eta: 2:17:03.689054, loss: 1.5176
2023-04-11 16:19:45 - training - INFO - Epoch [3/5][681/690] lr: 1.8e-05, eta: 2:15:09.597990, loss: 1.2121
2023-04-11 16:20:38 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.1062, Validation Metrics: {'exact_match': 23.166472642607683, 'f1': 26.33743913888249}
2023-04-11 16:20:39 - training - INFO - Epoch [4/5][1/690] lr: 1.8e-05, eta: 81 days, 18:38:50.649912, loss: 0.4013
2023-04-11 16:20:48 - training - INFO - Epoch [4/5][11/690] lr: 1.8e-05, eta: 7 days, 10:40:02.872611, loss: 1.0305
2023-04-11 16:20:56 - training - INFO - Epoch [4/5][21/690] lr: 1.8e-05, eta: 3 days, 21:41:31.215561, loss: 0.5757
2023-04-11 16:21:05 - training - INFO - Epoch [4/5][31/690] lr: 1.8e-05, eta: 2 days, 15:33:12.556525, loss: 0.3928
2023-04-11 16:21:13 - training - INFO - Epoch [4/5][41/690] lr: 1.8e-05, eta: 2 days, 0:06:30.703049, loss: 0.7925
2023-04-11 16:21:22 - training - INFO - Epoch [4/5][51/690] lr: 1.7e-05, eta: 1 day, 14:43:28.350081, loss: 1.1731
2023-04-11 16:21:31 - training - INFO - Epoch [4/5][61/690] lr: 1.7e-05, eta: 1 day, 8:25:04.546142, loss: 1.2267
2023-04-11 16:21:39 - training - INFO - Epoch [4/5][71/690] lr: 1.7e-05, eta: 1 day, 3:52:55.844136, loss: 0.9599
2023-04-11 16:21:48 - training - INFO - Epoch [4/5][81/690] lr: 1.7e-05, eta: 1 day, 0:28:02.686926, loss: 1.2425
2023-04-11 16:21:57 - training - INFO - Epoch [4/5][91/690] lr: 1.7e-05, eta: 21:48:19.077584, loss: 0.7018
2023-04-11 16:22:05 - training - INFO - Epoch [4/5][101/690] lr: 1.7e-05, eta: 19:40:01.500363, loss: 0.6167
2023-04-11 16:22:14 - training - INFO - Epoch [4/5][111/690] lr: 1.7e-05, eta: 17:54:58.491351, loss: 0.9867
2023-04-11 16:22:23 - training - INFO - Epoch [4/5][121/690] lr: 1.7e-05, eta: 16:27:10.017415, loss: 1.6200
2023-04-11 16:22:31 - training - INFO - Epoch [4/5][131/690] lr: 1.6e-05, eta: 15:12:34.840729, loss: 1.0442
2023-04-11 16:22:40 - training - INFO - Epoch [4/5][141/690] lr: 1.6e-05, eta: 14:08:51.807027, loss: 0.8694
2023-04-11 16:22:49 - training - INFO - Epoch [4/5][151/690] lr: 1.6e-05, eta: 13:13:11.720395, loss: 0.9073
2023-04-11 16:22:56 - training - INFO - Epoch [4/5][161/690] lr: 1.6e-05, eta: 12:24:20.696223, loss: 1.1280
2023-04-11 16:23:05 - training - INFO - Epoch [4/5][171/690] lr: 1.6e-05, eta: 11:41:19.564392, loss: 1.0417
2023-04-11 16:23:13 - training - INFO - Epoch [4/5][181/690] lr: 1.6e-05, eta: 11:03:05.884271, loss: 0.6231
2023-04-11 16:23:21 - training - INFO - Epoch [4/5][191/690] lr: 1.6e-05, eta: 10:28:50.000289, loss: 1.2420
2023-04-11 16:23:30 - training - INFO - Epoch [4/5][201/690] lr: 1.6e-05, eta: 9:57:55.587960, loss: 0.8952
2023-04-11 16:23:38 - training - INFO - Epoch [4/5][211/690] lr: 1.5e-05, eta: 9:29:55.872060, loss: 1.3182
2023-04-11 16:23:46 - training - INFO - Epoch [4/5][221/690] lr: 1.5e-05, eta: 9:04:27.676756, loss: 1.2177
2023-04-11 16:23:54 - training - INFO - Epoch [4/5][231/690] lr: 1.5e-05, eta: 8:41:11.027004, loss: 1.2071
2023-04-11 16:24:02 - training - INFO - Epoch [4/5][241/690] lr: 1.5e-05, eta: 8:19:48.027984, loss: 1.2843
2023-04-11 16:24:11 - training - INFO - Epoch [4/5][251/690] lr: 1.5e-05, eta: 8:00:13.226652, loss: 1.1240
2023-04-11 16:24:19 - training - INFO - Epoch [4/5][261/690] lr: 1.5e-05, eta: 7:41:58.306461, loss: 0.8215
2023-04-11 16:24:27 - training - INFO - Epoch [4/5][271/690] lr: 1.5e-05, eta: 7:25:08.867603, loss: 0.7144
2023-04-11 16:24:35 - training - INFO - Epoch [4/5][281/690] lr: 1.4e-05, eta: 7:09:30.970321, loss: 1.0410
2023-04-11 16:24:44 - training - INFO - Epoch [4/5][291/690] lr: 1.4e-05, eta: 6:55:00.150951, loss: 0.9731
2023-04-11 16:24:52 - training - INFO - Epoch [4/5][301/690] lr: 1.4e-05, eta: 6:41:25.271354, loss: 0.9433
2023-04-11 16:25:01 - training - INFO - Epoch [4/5][311/690] lr: 1.4e-05, eta: 6:28:40.921129, loss: 0.5168
2023-04-11 16:25:09 - training - INFO - Epoch [4/5][321/690] lr: 1.4e-05, eta: 6:16:45.350985, loss: 1.0160
2023-04-11 16:25:17 - training - INFO - Epoch [4/5][331/690] lr: 1.4e-05, eta: 6:05:28.634778, loss: 1.4342
2023-04-11 16:25:25 - training - INFO - Epoch [4/5][341/690] lr: 1.4e-05, eta: 5:54:45.690775, loss: 1.3093
2023-04-11 16:25:33 - training - INFO - Epoch [4/5][351/690] lr: 1.4e-05, eta: 5:44:45.087438, loss: 0.8673
2023-04-11 16:25:41 - training - INFO - Epoch [4/5][361/690] lr: 1.3e-05, eta: 5:35:14.786483, loss: 0.8455
2023-04-11 16:25:49 - training - INFO - Epoch [4/5][371/690] lr: 1.3e-05, eta: 5:26:18.455774, loss: 0.7534
2023-04-11 16:25:57 - training - INFO - Epoch [4/5][381/690] lr: 1.3e-05, eta: 5:17:46.883715, loss: 1.0143
2023-04-11 16:26:06 - training - INFO - Epoch [4/5][391/690] lr: 1.3e-05, eta: 5:09:45.116627, loss: 0.5677
2023-04-11 16:26:14 - training - INFO - Epoch [4/5][401/690] lr: 1.3e-05, eta: 5:02:07.088593, loss: 0.4699
2023-04-11 16:26:23 - training - INFO - Epoch [4/5][411/690] lr: 1.3e-05, eta: 4:54:50.122326, loss: 0.7217
2023-04-11 16:26:31 - training - INFO - Epoch [4/5][421/690] lr: 1.3e-05, eta: 4:47:53.563112, loss: 0.9270
2023-04-11 16:26:39 - training - INFO - Epoch [4/5][431/690] lr: 1.2e-05, eta: 4:41:13.873294, loss: 0.3796
2023-04-11 16:26:47 - training - INFO - Epoch [4/5][441/690] lr: 1.2e-05, eta: 4:34:51.107346, loss: 1.1384
2023-04-11 16:26:56 - training - INFO - Epoch [4/5][451/690] lr: 1.2e-05, eta: 4:28:47.506372, loss: 1.1885
2023-04-11 16:27:04 - training - INFO - Epoch [4/5][461/690] lr: 1.2e-05, eta: 4:22:58.488628, loss: 0.5991
2023-04-11 16:27:12 - training - INFO - Epoch [4/5][471/690] lr: 1.2e-05, eta: 4:17:21.792471, loss: 1.2735
2023-04-11 16:27:19 - training - INFO - Epoch [4/5][481/690] lr: 1.2e-05, eta: 4:11:58.112372, loss: 0.8738
2023-04-11 16:27:28 - training - INFO - Epoch [4/5][491/690] lr: 1.2e-05, eta: 4:06:50.883912, loss: 0.6724
2023-04-11 16:27:37 - training - INFO - Epoch [4/5][501/690] lr: 1.2e-05, eta: 4:01:58.065603, loss: 0.8028
2023-04-11 16:27:45 - training - INFO - Epoch [4/5][511/690] lr: 1.1e-05, eta: 3:57:12.880457, loss: 1.2939
2023-04-11 16:27:53 - training - INFO - Epoch [4/5][521/690] lr: 1.1e-05, eta: 3:52:38.295950, loss: 1.5550
2023-04-11 16:28:02 - training - INFO - Epoch [4/5][531/690] lr: 1.1e-05, eta: 3:48:15.367119, loss: 1.0767
2023-04-11 16:28:10 - training - INFO - Epoch [4/5][541/690] lr: 1.1e-05, eta: 3:44:00.251979, loss: 0.9727
2023-04-11 16:28:18 - training - INFO - Epoch [4/5][551/690] lr: 1.1e-05, eta: 3:39:54.134629, loss: 0.8037
2023-04-11 16:28:26 - training - INFO - Epoch [4/5][561/690] lr: 1.1e-05, eta: 3:35:57.982587, loss: 0.7022
2023-04-11 16:28:35 - training - INFO - Epoch [4/5][571/690] lr: 1.1e-05, eta: 3:32:08.369932, loss: 0.7257
2023-04-11 16:28:43 - training - INFO - Epoch [4/5][581/690] lr: 1.1e-05, eta: 3:28:28.636301, loss: 1.5024
2023-04-11 16:28:52 - training - INFO - Epoch [4/5][591/690] lr: 1.0e-05, eta: 3:24:54.429045, loss: 0.8449
2023-04-11 16:29:00 - training - INFO - Epoch [4/5][601/690] lr: 1.0e-05, eta: 3:21:25.523527, loss: 1.3972
2023-04-11 16:29:08 - training - INFO - Epoch [4/5][611/690] lr: 1.0e-05, eta: 3:18:04.062517, loss: 0.7921
2023-04-11 16:29:16 - training - INFO - Epoch [4/5][621/690] lr: 1.0e-05, eta: 3:14:50.658615, loss: 0.5916
2023-04-11 16:29:25 - training - INFO - Epoch [4/5][631/690] lr: 9.9e-06, eta: 3:11:43.197305, loss: 0.9226
2023-04-11 16:29:34 - training - INFO - Epoch [4/5][641/690] lr: 9.7e-06, eta: 3:08:42.090232, loss: 0.7956
2023-04-11 16:29:43 - training - INFO - Epoch [4/5][651/690] lr: 9.6e-06, eta: 3:05:47.658471, loss: 0.5673
2023-04-11 16:29:51 - training - INFO - Epoch [4/5][661/690] lr: 9.5e-06, eta: 3:02:55.242121, loss: 1.2654
2023-04-11 16:30:00 - training - INFO - Epoch [4/5][671/690] lr: 9.3e-06, eta: 3:00:08.923279, loss: 0.8134
2023-04-11 16:30:09 - training - INFO - Epoch [4/5][681/690] lr: 9.2e-06, eta: 2:57:27.225888, loss: 1.1192
2023-04-11 16:31:02 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.9664, Validation Metrics: {'exact_match': 23.39930151338766, 'f1': 27.02516575734643}
2023-04-11 16:31:03 - training - INFO - Epoch [5/5][1/690] lr: 9.1e-06, eta: 106 days, 16:50:17.487199, loss: 0.6874
2023-04-11 16:31:12 - training - INFO - Epoch [5/5][11/690] lr: 8.9e-06, eta: 9 days, 16:52:57.471311, loss: 0.7124
2023-04-11 16:31:20 - training - INFO - Epoch [5/5][21/690] lr: 8.8e-06, eta: 5 days, 1:59:24.124083, loss: 0.8423
2023-04-11 16:31:29 - training - INFO - Epoch [5/5][31/690] lr: 8.7e-06, eta: 3 days, 10:40:34.880543, loss: 0.7329
2023-04-11 16:31:37 - training - INFO - Epoch [5/5][41/690] lr: 8.5e-06, eta: 2 days, 14:31:29.404274, loss: 0.4646
2023-04-11 16:31:46 - training - INFO - Epoch [5/5][51/690] lr: 8.4e-06, eta: 2 days, 2:16:50.193045, loss: 0.6450
2023-04-11 16:31:55 - training - INFO - Epoch [5/5][61/690] lr: 8.3e-06, eta: 1 day, 18:03:10.361289, loss: 0.8439
2023-04-11 16:32:04 - training - INFO - Epoch [5/5][71/690] lr: 8.1e-06, eta: 1 day, 12:08:27.905045, loss: 0.7485
2023-04-11 16:32:13 - training - INFO - Epoch [5/5][81/690] lr: 8.0e-06, eta: 1 day, 7:41:26.650326, loss: 1.0892
2023-04-11 16:32:22 - training - INFO - Epoch [5/5][91/690] lr: 7.9e-06, eta: 1 day, 4:12:52.918565, loss: 0.9722
2023-04-11 16:32:31 - training - INFO - Epoch [5/5][101/690] lr: 7.8e-06, eta: 1 day, 1:25:32.466767, loss: 0.8962
2023-04-11 16:32:39 - training - INFO - Epoch [5/5][111/690] lr: 7.6e-06, eta: 23:07:59.367990, loss: 0.8308
2023-04-11 16:32:47 - training - INFO - Epoch [5/5][121/690] lr: 7.5e-06, eta: 21:13:14.680973, loss: 1.2217
2023-04-11 16:32:55 - training - INFO - Epoch [5/5][131/690] lr: 7.4e-06, eta: 19:35:55.278767, loss: 0.7218
2023-04-11 16:33:03 - training - INFO - Epoch [5/5][141/690] lr: 7.2e-06, eta: 18:12:29.913456, loss: 0.7742
2023-04-11 16:33:12 - training - INFO - Epoch [5/5][151/690] lr: 7.1e-06, eta: 17:00:09.533834, loss: 0.7142
2023-04-11 16:33:21 - training - INFO - Epoch [5/5][161/690] lr: 7.0e-06, eta: 15:56:53.695053, loss: 0.8143
2023-04-11 16:33:29 - training - INFO - Epoch [5/5][171/690] lr: 6.8e-06, eta: 15:00:53.373927, loss: 0.4739
2023-04-11 16:33:38 - training - INFO - Epoch [5/5][181/690] lr: 6.7e-06, eta: 14:11:04.235019, loss: 1.2307
2023-04-11 16:33:46 - training - INFO - Epoch [5/5][191/690] lr: 6.6e-06, eta: 13:26:26.024287, loss: 0.6540
2023-04-11 16:33:55 - training - INFO - Epoch [5/5][201/690] lr: 6.4e-06, eta: 12:46:19.825257, loss: 1.1881
2023-04-11 16:34:03 - training - INFO - Epoch [5/5][211/690] lr: 6.3e-06, eta: 12:09:59.455236, loss: 0.8010
2023-04-11 16:34:12 - training - INFO - Epoch [5/5][221/690] lr: 6.2e-06, eta: 11:36:54.161530, loss: 0.7687
2023-04-11 16:34:21 - training - INFO - Epoch [5/5][231/690] lr: 6.0e-06, eta: 11:06:42.764082, loss: 0.8734
2023-04-11 16:34:29 - training - INFO - Epoch [5/5][241/690] lr: 5.9e-06, eta: 10:38:58.356215, loss: 0.7450
2023-04-11 16:34:39 - training - INFO - Epoch [5/5][251/690] lr: 5.8e-06, eta: 10:13:40.947457, loss: 1.2175
2023-04-11 16:34:48 - training - INFO - Epoch [5/5][261/690] lr: 5.6e-06, eta: 9:50:08.251494, loss: 0.7722
2023-04-11 16:34:57 - training - INFO - Epoch [5/5][271/690] lr: 5.5e-06, eta: 9:28:16.812739, loss: 0.5209
2023-04-11 16:35:06 - training - INFO - Epoch [5/5][281/690] lr: 5.4e-06, eta: 9:07:59.217954, loss: 0.7783
2023-04-11 16:35:15 - training - INFO - Epoch [5/5][291/690] lr: 5.3e-06, eta: 8:49:09.090399, loss: 0.2317
2023-04-11 16:35:24 - training - INFO - Epoch [5/5][301/690] lr: 5.1e-06, eta: 8:31:29.070744, loss: 1.1168
2023-04-11 16:35:32 - training - INFO - Epoch [5/5][311/690] lr: 5.0e-06, eta: 8:14:56.879902, loss: 1.2096
2023-04-11 16:35:41 - training - INFO - Epoch [5/5][321/690] lr: 4.9e-06, eta: 7:59:27.747519, loss: 1.1363
2023-04-11 16:35:51 - training - INFO - Epoch [5/5][331/690] lr: 4.7e-06, eta: 7:44:55.266183, loss: 0.6727
2023-04-11 16:35:59 - training - INFO - Epoch [5/5][341/690] lr: 4.6e-06, eta: 7:31:08.312633, loss: 0.5311
2023-04-11 16:36:08 - training - INFO - Epoch [5/5][351/690] lr: 4.5e-06, eta: 7:18:14.265042, loss: 1.3808
2023-04-11 16:36:17 - training - INFO - Epoch [5/5][361/690] lr: 4.3e-06, eta: 7:05:58.756680, loss: 0.7199
2023-04-11 16:36:26 - training - INFO - Epoch [5/5][371/690] lr: 4.2e-06, eta: 6:54:20.661935, loss: 0.5905
2023-04-11 16:36:34 - training - INFO - Epoch [5/5][381/690] lr: 4.1e-06, eta: 6:43:17.103909, loss: 0.7745
2023-04-11 16:36:43 - training - INFO - Epoch [5/5][391/690] lr: 3.9e-06, eta: 6:32:51.100028, loss: 1.0299
2023-04-11 16:36:52 - training - INFO - Epoch [5/5][401/690] lr: 3.8e-06, eta: 6:22:54.394891, loss: 1.3691
2023-04-11 16:37:00 - training - INFO - Epoch [5/5][411/690] lr: 3.7e-06, eta: 6:13:24.684093, loss: 0.8435
2023-04-11 16:37:09 - training - INFO - Epoch [5/5][421/690] lr: 3.5e-06, eta: 6:04:20.977554, loss: 0.7852
2023-04-11 16:37:17 - training - INFO - Epoch [5/5][431/690] lr: 3.4e-06, eta: 5:55:42.098959, loss: 1.2461
2023-04-11 16:37:26 - training - INFO - Epoch [5/5][441/690] lr: 3.3e-06, eta: 5:47:32.379027, loss: 0.5303
2023-04-11 16:37:35 - training - INFO - Epoch [5/5][451/690] lr: 3.1e-06, eta: 5:39:40.886106, loss: 1.1022
2023-04-11 16:37:44 - training - INFO - Epoch [5/5][461/690] lr: 3.0e-06, eta: 5:32:10.693846, loss: 0.5794
2023-04-11 16:37:53 - training - INFO - Epoch [5/5][471/690] lr: 2.9e-06, eta: 5:24:58.445721, loss: 0.9714
2023-04-11 16:38:02 - training - INFO - Epoch [5/5][481/690] lr: 2.8e-06, eta: 5:18:02.799181, loss: 1.4077
2023-04-11 16:38:11 - training - INFO - Epoch [5/5][491/690] lr: 2.6e-06, eta: 5:11:26.022861, loss: 1.1211
2023-04-11 16:38:20 - training - INFO - Epoch [5/5][501/690] lr: 2.5e-06, eta: 5:05:02.349210, loss: 0.8800
2023-04-11 16:38:28 - training - INFO - Epoch [5/5][511/690] lr: 2.4e-06, eta: 4:58:51.047669, loss: 0.8126
2023-04-11 16:38:37 - training - INFO - Epoch [5/5][521/690] lr: 2.2e-06, eta: 4:52:59.362999, loss: 0.8359
2023-04-11 16:38:46 - training - INFO - Epoch [5/5][531/690] lr: 2.1e-06, eta: 4:47:18.312126, loss: 0.7541
2023-04-11 16:38:54 - training - INFO - Epoch [5/5][541/690] lr: 2.0e-06, eta: 4:41:46.860735, loss: 0.7825
2023-04-11 16:39:03 - training - INFO - Epoch [5/5][551/690] lr: 1.8e-06, eta: 4:36:29.260792, loss: 1.3610
2023-04-11 16:39:12 - training - INFO - Epoch [5/5][561/690] lr: 1.7e-06, eta: 4:31:23.184030, loss: 0.9394
2023-04-11 16:39:20 - training - INFO - Epoch [5/5][571/690] lr: 1.6e-06, eta: 4:26:24.487263, loss: 1.0849
2023-04-11 16:39:29 - training - INFO - Epoch [5/5][581/690] lr: 1.4e-06, eta: 4:21:34.520220, loss: 1.2129
2023-04-11 16:39:37 - training - INFO - Epoch [5/5][591/690] lr: 1.3e-06, eta: 4:16:56.108247, loss: 0.6602
2023-04-11 16:39:45 - training - INFO - Epoch [5/5][601/690] lr: 1.2e-06, eta: 4:12:24.434998, loss: 0.7399
2023-04-11 16:39:53 - training - INFO - Epoch [5/5][611/690] lr: 1.0e-06, eta: 4:08:00.811552, loss: 0.6465
2023-04-11 16:40:01 - training - INFO - Epoch [5/5][621/690] lr: 9.1e-07, eta: 4:03:47.166273, loss: 0.2655
2023-04-11 16:40:09 - training - INFO - Epoch [5/5][631/690] lr: 7.8e-07, eta: 3:59:41.762775, loss: 0.7096
2023-04-11 16:40:17 - training - INFO - Epoch [5/5][641/690] lr: 6.4e-07, eta: 3:55:40.991957, loss: 1.2992
2023-04-11 16:40:25 - training - INFO - Epoch [5/5][651/690] lr: 5.1e-07, eta: 3:51:50.067144, loss: 1.3867
2023-04-11 16:40:34 - training - INFO - Epoch [5/5][661/690] lr: 3.8e-07, eta: 3:48:05.299476, loss: 1.1093
2023-04-11 16:40:42 - training - INFO - Epoch [5/5][671/690] lr: 2.5e-07, eta: 3:44:26.417062, loss: 0.9667
2023-04-11 16:40:50 - training - INFO - Epoch [5/5][681/690] lr: 1.2e-07, eta: 3:40:53.691126, loss: 1.1697
2023-04-11 16:41:40 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.8555, Validation Metrics: {'exact_match': 22.235157159487777, 'f1': 26.12828943769132}
2023-04-11 16:42:23 - training - INFO - Final Test - Train Loss: 0.8555, Test Metrics: {'exact_match': 25.43554006968641, 'f1': 29.261593400118233}
