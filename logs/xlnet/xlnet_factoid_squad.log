2023-04-12 12:16:51 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'srikanthkb/xlnet-base-cased-finetuned-squad'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_factoid_squad'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 592.33it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1266.53 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1474.13 examples/s]Map:  68%|██████▊   | 3000/4429 [00:02<00:00, 1530.77 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1542.95 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1527.69 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1247.91 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1190.17 examples/s]                                                               2023-04-12 12:17:50 - training - INFO - First Test - Val Metrics:{'exact_match': 10.126582278481013, 'f1': 18.748142397257652} Test Metrics: {'exact_match': 12.072072072072071, 'f1': 19.175582248527128}
2023-04-12 12:17:51 - training - INFO - Epoch [1/5][1/438] lr: 4.5e-05, eta: 1 day, 6:06:40.330720, loss: 9.3821
2023-04-12 12:17:59 - training - INFO - Epoch [1/5][11/438] lr: 4.5e-05, eta: 3:09:37.907801, loss: 4.6448
2023-04-12 12:18:06 - training - INFO - Epoch [1/5][21/438] lr: 4.5e-05, eta: 1:52:02.360010, loss: 3.8999
2023-04-12 12:18:14 - training - INFO - Epoch [1/5][31/438] lr: 4.5e-05, eta: 1:24:28.684300, loss: 3.2042
2023-04-12 12:18:22 - training - INFO - Epoch [1/5][41/438] lr: 4.5e-05, eta: 1:10:05.700450, loss: 2.8644
2023-04-12 12:18:29 - training - INFO - Epoch [1/5][51/438] lr: 4.4e-05, eta: 1:01:25.225347, loss: 3.6026
2023-04-12 12:18:37 - training - INFO - Epoch [1/5][61/438] lr: 4.4e-05, eta: 0:55:34.539863, loss: 2.4614
2023-04-12 12:18:44 - training - INFO - Epoch [1/5][71/438] lr: 4.4e-05, eta: 0:51:14.988969, loss: 2.1998
2023-04-12 12:18:52 - training - INFO - Epoch [1/5][81/438] lr: 4.4e-05, eta: 0:48:04.907427, loss: 2.7096
2023-04-12 12:19:00 - training - INFO - Epoch [1/5][91/438] lr: 4.4e-05, eta: 0:45:35.160722, loss: 2.2918
2023-04-12 12:19:08 - training - INFO - Epoch [1/5][101/438] lr: 4.3e-05, eta: 0:43:30.861446, loss: 2.0412
2023-04-12 12:19:15 - training - INFO - Epoch [1/5][111/438] lr: 4.3e-05, eta: 0:41:48.009966, loss: 1.4884
2023-04-12 12:19:23 - training - INFO - Epoch [1/5][121/438] lr: 4.3e-05, eta: 0:40:16.836142, loss: 2.5210
2023-04-12 12:19:30 - training - INFO - Epoch [1/5][131/438] lr: 4.3e-05, eta: 0:39:02.411055, loss: 2.1677
2023-04-12 12:19:38 - training - INFO - Epoch [1/5][141/438] lr: 4.2e-05, eta: 0:37:57.490137, loss: 2.1041
2023-04-12 12:19:46 - training - INFO - Epoch [1/5][151/438] lr: 4.2e-05, eta: 0:36:59.241483, loss: 1.1826
2023-04-12 12:19:54 - training - INFO - Epoch [1/5][161/438] lr: 4.2e-05, eta: 0:36:10.715505, loss: 2.0652
2023-04-12 12:20:01 - training - INFO - Epoch [1/5][171/438] lr: 4.2e-05, eta: 0:35:23.321730, loss: 1.3595
2023-04-12 12:20:09 - training - INFO - Epoch [1/5][181/438] lr: 4.2e-05, eta: 0:34:41.609278, loss: 1.7841
2023-04-12 12:20:17 - training - INFO - Epoch [1/5][191/438] lr: 4.1e-05, eta: 0:34:03.659659, loss: 1.5375
2023-04-12 12:20:24 - training - INFO - Epoch [1/5][201/438] lr: 4.1e-05, eta: 0:33:28.118268, loss: 1.4084
2023-04-12 12:20:32 - training - INFO - Epoch [1/5][211/438] lr: 4.1e-05, eta: 0:32:54.507670, loss: 1.2887
2023-04-12 12:20:39 - training - INFO - Epoch [1/5][221/438] lr: 4.1e-05, eta: 0:32:23.351806, loss: 2.0593
2023-04-12 12:20:47 - training - INFO - Epoch [1/5][231/438] lr: 4.1e-05, eta: 0:31:53.588421, loss: 1.5282
2023-04-12 12:20:55 - training - INFO - Epoch [1/5][241/438] lr: 4.0e-05, eta: 0:31:26.314313, loss: 1.7669
2023-04-12 12:21:02 - training - INFO - Epoch [1/5][251/438] lr: 4.0e-05, eta: 0:31:00.059432, loss: 1.3588
2023-04-12 12:21:10 - training - INFO - Epoch [1/5][261/438] lr: 4.0e-05, eta: 0:30:36.537243, loss: 1.3854
2023-04-12 12:21:17 - training - INFO - Epoch [1/5][271/438] lr: 4.0e-05, eta: 0:30:13.781230, loss: 1.5623
2023-04-12 12:21:25 - training - INFO - Epoch [1/5][281/438] lr: 4.0e-05, eta: 0:29:50.991347, loss: 0.9424
2023-04-12 12:21:33 - training - INFO - Epoch [1/5][291/438] lr: 3.9e-05, eta: 0:29:30.625701, loss: 1.2901
2023-04-12 12:21:40 - training - INFO - Epoch [1/5][301/438] lr: 3.9e-05, eta: 0:29:11.478911, loss: 1.4704
2023-04-12 12:21:48 - training - INFO - Epoch [1/5][311/438] lr: 3.9e-05, eta: 0:28:51.765318, loss: 2.1570
2023-04-12 12:21:55 - training - INFO - Epoch [1/5][321/438] lr: 3.9e-05, eta: 0:28:32.815146, loss: 1.4176
2023-04-12 12:22:03 - training - INFO - Epoch [1/5][331/438] lr: 3.9e-05, eta: 0:28:14.402281, loss: 1.2714
2023-04-12 12:22:11 - training - INFO - Epoch [1/5][341/438] lr: 3.8e-05, eta: 0:27:57.919426, loss: 2.1783
2023-04-12 12:22:18 - training - INFO - Epoch [1/5][351/438] lr: 3.8e-05, eta: 0:27:41.341566, loss: 1.7134
2023-04-12 12:22:26 - training - INFO - Epoch [1/5][361/438] lr: 3.8e-05, eta: 0:27:25.280608, loss: 1.8724
2023-04-12 12:22:34 - training - INFO - Epoch [1/5][371/438] lr: 3.8e-05, eta: 0:27:08.956337, loss: 1.1126
2023-04-12 12:22:42 - training - INFO - Epoch [1/5][381/438] lr: 3.8e-05, eta: 0:26:55.230774, loss: 1.6980
2023-04-12 12:22:49 - training - INFO - Epoch [1/5][391/438] lr: 3.7e-05, eta: 0:26:39.872288, loss: 1.0272
2023-04-12 12:22:57 - training - INFO - Epoch [1/5][401/438] lr: 3.7e-05, eta: 0:26:25.070101, loss: 1.3747
2023-04-12 12:23:04 - training - INFO - Epoch [1/5][411/438] lr: 3.7e-05, eta: 0:26:10.538559, loss: 0.7641
2023-04-12 12:23:12 - training - INFO - Epoch [1/5][421/438] lr: 3.7e-05, eta: 0:25:57.181709, loss: 1.3087
2023-04-12 12:23:20 - training - INFO - Epoch [1/5][431/438] lr: 3.6e-05, eta: 0:25:43.638594, loss: 1.3413
2023-04-12 12:24:13 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 1.9554, Validation Metrics: {'exact_match': 42.13381555153707, 'f1': 46.13285027677242}, Test Metrics: {'exact_match': 42.88288288288288, 'f1': 46.197788807423535}
2023-04-12 12:24:13 - training - INFO - Epoch [2/5][1/438] lr: 3.6e-05, eta: 10 days, 22:42:48.057894, loss: 1.1937
2023-04-12 12:24:21 - training - INFO - Epoch [2/5][11/438] lr: 3.6e-05, eta: 1 day, 0:11:00.278065, loss: 1.1056
2023-04-12 12:24:28 - training - INFO - Epoch [2/5][21/438] lr: 3.6e-05, eta: 12:49:25.818051, loss: 1.2926
2023-04-12 12:24:36 - training - INFO - Epoch [2/5][31/438] lr: 3.6e-05, eta: 8:47:32.010864, loss: 0.9913
2023-04-12 12:24:43 - training - INFO - Epoch [2/5][41/438] lr: 3.5e-05, eta: 6:43:33.275121, loss: 1.2969
2023-04-12 12:24:51 - training - INFO - Epoch [2/5][51/438] lr: 3.5e-05, eta: 5:28:20.632773, loss: 1.3620
2023-04-12 12:24:59 - training - INFO - Epoch [2/5][61/438] lr: 3.5e-05, eta: 4:37:37.004327, loss: 1.2055
2023-04-12 12:25:06 - training - INFO - Epoch [2/5][71/438] lr: 3.5e-05, eta: 4:01:08.290434, loss: 0.6933
2023-04-12 12:25:14 - training - INFO - Epoch [2/5][81/438] lr: 3.5e-05, eta: 3:33:36.686151, loss: 1.4645
2023-04-12 12:25:21 - training - INFO - Epoch [2/5][91/438] lr: 3.4e-05, eta: 3:12:08.062731, loss: 1.2408
2023-04-12 12:25:29 - training - INFO - Epoch [2/5][101/438] lr: 3.4e-05, eta: 2:54:52.668891, loss: 0.9388
2023-04-12 12:25:37 - training - INFO - Epoch [2/5][111/438] lr: 3.4e-05, eta: 2:40:50.453967, loss: 0.9676
2023-04-12 12:25:44 - training - INFO - Epoch [2/5][121/438] lr: 3.4e-05, eta: 2:28:59.224157, loss: 0.9962
2023-04-12 12:25:52 - training - INFO - Epoch [2/5][131/438] lr: 3.4e-05, eta: 2:18:55.591771, loss: 0.5847
2023-04-12 12:25:59 - training - INFO - Epoch [2/5][141/438] lr: 3.3e-05, eta: 2:10:16.521102, loss: 1.4820
2023-04-12 12:26:07 - training - INFO - Epoch [2/5][151/438] lr: 3.3e-05, eta: 2:02:44.182896, loss: 1.1440
2023-04-12 12:26:15 - training - INFO - Epoch [2/5][161/438] lr: 3.3e-05, eta: 1:56:12.518499, loss: 1.4025
2023-04-12 12:26:22 - training - INFO - Epoch [2/5][171/438] lr: 3.3e-05, eta: 1:50:21.173208, loss: 0.9892
2023-04-12 12:26:30 - training - INFO - Epoch [2/5][181/438] lr: 3.3e-05, eta: 1:45:07.924497, loss: 1.2801
2023-04-12 12:26:37 - training - INFO - Epoch [2/5][191/438] lr: 3.2e-05, eta: 1:40:26.459263, loss: 0.6048
2023-04-12 12:26:45 - training - INFO - Epoch [2/5][201/438] lr: 3.2e-05, eta: 1:36:12.905424, loss: 0.8203
2023-04-12 12:26:52 - training - INFO - Epoch [2/5][211/438] lr: 3.2e-05, eta: 1:32:22.943499, loss: 1.3160
2023-04-12 12:27:00 - training - INFO - Epoch [2/5][221/438] lr: 3.2e-05, eta: 1:28:53.150702, loss: 1.3413
2023-04-12 12:27:07 - training - INFO - Epoch [2/5][231/438] lr: 3.2e-05, eta: 1:25:40.165248, loss: 0.7896
2023-04-12 12:27:15 - training - INFO - Epoch [2/5][241/438] lr: 3.1e-05, eta: 1:22:42.044856, loss: 1.4832
2023-04-12 12:27:23 - training - INFO - Epoch [2/5][251/438] lr: 3.1e-05, eta: 1:19:59.963476, loss: 1.5543
2023-04-12 12:27:30 - training - INFO - Epoch [2/5][261/438] lr: 3.1e-05, eta: 1:17:28.010376, loss: 0.9980
2023-04-12 12:27:38 - training - INFO - Epoch [2/5][271/438] lr: 3.1e-05, eta: 1:15:06.040361, loss: 0.5734
2023-04-12 12:27:45 - training - INFO - Epoch [2/5][281/438] lr: 3.0e-05, eta: 1:12:55.584538, loss: 1.1418
2023-04-12 12:27:53 - training - INFO - Epoch [2/5][291/438] lr: 3.0e-05, eta: 1:10:52.086981, loss: 1.0354
2023-04-12 12:28:01 - training - INFO - Epoch [2/5][301/438] lr: 3.0e-05, eta: 1:08:57.873390, loss: 0.5827
2023-04-12 12:28:08 - training - INFO - Epoch [2/5][311/438] lr: 3.0e-05, eta: 1:07:09.831172, loss: 1.3487
2023-04-12 12:28:16 - training - INFO - Epoch [2/5][321/438] lr: 3.0e-05, eta: 1:05:30.353742, loss: 1.0463
2023-04-12 12:28:24 - training - INFO - Epoch [2/5][331/438] lr: 2.9e-05, eta: 1:03:53.600056, loss: 0.8250
2023-04-12 12:28:31 - training - INFO - Epoch [2/5][341/438] lr: 2.9e-05, eta: 1:02:22.144875, loss: 1.1072
2023-04-12 12:28:39 - training - INFO - Epoch [2/5][351/438] lr: 2.9e-05, eta: 1:00:55.233180, loss: 1.3160
2023-04-12 12:28:47 - training - INFO - Epoch [2/5][361/438] lr: 2.9e-05, eta: 0:59:34.328737, loss: 1.1395
2023-04-12 12:28:54 - training - INFO - Epoch [2/5][371/438] lr: 2.9e-05, eta: 0:58:15.925186, loss: 1.5288
2023-04-12 12:29:02 - training - INFO - Epoch [2/5][381/438] lr: 2.8e-05, eta: 0:57:01.542600, loss: 0.5720
2023-04-12 12:29:10 - training - INFO - Epoch [2/5][391/438] lr: 2.8e-05, eta: 0:55:50.612314, loss: 0.7657
2023-04-12 12:29:17 - training - INFO - Epoch [2/5][401/438] lr: 2.8e-05, eta: 0:54:43.777482, loss: 0.9002
2023-04-12 12:29:25 - training - INFO - Epoch [2/5][411/438] lr: 2.8e-05, eta: 0:53:39.045351, loss: 0.8576
2023-04-12 12:29:33 - training - INFO - Epoch [2/5][421/438] lr: 2.8e-05, eta: 0:52:37.479255, loss: 1.4140
2023-04-12 12:29:40 - training - INFO - Epoch [2/5][431/438] lr: 2.7e-05, eta: 0:51:37.409028, loss: 1.2496
2023-04-12 12:30:33 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.1041, Validation Metrics: {'exact_match': 44.48462929475588, 'f1': 47.70549446432384}, Test Metrics: {'exact_match': 48.828828828828826, 'f1': 51.645851456645666}
2023-04-12 12:30:34 - training - INFO - Epoch [3/5][1/438] lr: 2.7e-05, eta: 20 days, 14:11:53.088225, loss: 0.7006
2023-04-12 12:30:42 - training - INFO - Epoch [3/5][11/438] lr: 2.7e-05, eta: 1 day, 21:08:29.338441, loss: 0.5860
2023-04-12 12:30:49 - training - INFO - Epoch [3/5][21/438] lr: 2.7e-05, eta: 23:45:24.524586, loss: 0.8754
2023-04-12 12:30:57 - training - INFO - Epoch [3/5][31/438] lr: 2.7e-05, eta: 16:10:01.255454, loss: 1.3041
2023-04-12 12:31:05 - training - INFO - Epoch [3/5][41/438] lr: 2.6e-05, eta: 12:16:36.241593, loss: 0.7161
2023-04-12 12:31:12 - training - INFO - Epoch [3/5][51/438] lr: 2.6e-05, eta: 9:54:41.484654, loss: 0.6802
2023-04-12 12:31:20 - training - INFO - Epoch [3/5][61/438] lr: 2.6e-05, eta: 8:19:12.866936, loss: 0.9984
2023-04-12 12:31:27 - training - INFO - Epoch [3/5][71/438] lr: 2.6e-05, eta: 7:10:37.888765, loss: 0.7828
2023-04-12 12:31:35 - training - INFO - Epoch [3/5][81/438] lr: 2.6e-05, eta: 6:18:58.938522, loss: 0.4640
2023-04-12 12:31:42 - training - INFO - Epoch [3/5][91/438] lr: 2.5e-05, eta: 5:38:39.419876, loss: 0.8683
2023-04-12 12:31:50 - training - INFO - Epoch [3/5][101/438] lr: 2.5e-05, eta: 5:06:16.394038, loss: 0.9038
2023-04-12 12:31:58 - training - INFO - Epoch [3/5][111/438] lr: 2.5e-05, eta: 4:39:46.315854, loss: 1.0987
2023-04-12 12:32:05 - training - INFO - Epoch [3/5][121/438] lr: 2.5e-05, eta: 4:17:38.326600, loss: 0.7213
2023-04-12 12:32:13 - training - INFO - Epoch [3/5][131/438] lr: 2.5e-05, eta: 3:58:52.633112, loss: 0.7356
2023-04-12 12:32:21 - training - INFO - Epoch [3/5][141/438] lr: 2.4e-05, eta: 3:42:41.186817, loss: 0.3138
2023-04-12 12:32:28 - training - INFO - Epoch [3/5][151/438] lr: 2.4e-05, eta: 3:28:38.195820, loss: 0.7335
2023-04-12 12:32:36 - training - INFO - Epoch [3/5][161/438] lr: 2.4e-05, eta: 3:16:17.101223, loss: 0.9117
2023-04-12 12:32:44 - training - INFO - Epoch [3/5][171/438] lr: 2.4e-05, eta: 3:05:25.455201, loss: 0.8894
2023-04-12 12:32:51 - training - INFO - Epoch [3/5][181/438] lr: 2.3e-05, eta: 2:55:42.565012, loss: 0.7559
2023-04-12 12:32:59 - training - INFO - Epoch [3/5][191/438] lr: 2.3e-05, eta: 2:47:00.563212, loss: 0.9265
2023-04-12 12:33:06 - training - INFO - Epoch [3/5][201/438] lr: 2.3e-05, eta: 2:39:10.575333, loss: 0.7405
2023-04-12 12:33:14 - training - INFO - Epoch [3/5][211/438] lr: 2.3e-05, eta: 2:32:04.830591, loss: 1.0457
2023-04-12 12:33:22 - training - INFO - Epoch [3/5][221/438] lr: 2.3e-05, eta: 2:25:35.175119, loss: 1.0608
2023-04-12 12:33:29 - training - INFO - Epoch [3/5][231/438] lr: 2.2e-05, eta: 2:19:39.459903, loss: 0.7303
2023-04-12 12:33:37 - training - INFO - Epoch [3/5][241/438] lr: 2.2e-05, eta: 2:14:12.689147, loss: 0.7999
2023-04-12 12:33:45 - training - INFO - Epoch [3/5][251/438] lr: 2.2e-05, eta: 2:09:12.436118, loss: 1.2875
2023-04-12 12:33:52 - training - INFO - Epoch [3/5][261/438] lr: 2.2e-05, eta: 2:04:33.133113, loss: 0.6758
2023-04-12 12:34:00 - training - INFO - Epoch [3/5][271/438] lr: 2.2e-05, eta: 2:00:13.762794, loss: 0.5369
2023-04-12 12:34:08 - training - INFO - Epoch [3/5][281/438] lr: 2.1e-05, eta: 1:56:13.233380, loss: 0.8757
2023-04-12 12:34:15 - training - INFO - Epoch [3/5][291/438] lr: 2.1e-05, eta: 1:52:27.902802, loss: 0.6067
2023-04-12 12:34:23 - training - INFO - Epoch [3/5][301/438] lr: 2.1e-05, eta: 1:48:56.978950, loss: 1.5746
2023-04-12 12:34:30 - training - INFO - Epoch [3/5][311/438] lr: 2.1e-05, eta: 1:45:38.590415, loss: 0.8865
2023-04-12 12:34:38 - training - INFO - Epoch [3/5][321/438] lr: 2.1e-05, eta: 1:42:32.770428, loss: 1.1804
2023-04-12 12:34:46 - training - INFO - Epoch [3/5][331/438] lr: 2.0e-05, eta: 1:39:37.865465, loss: 0.7900
2023-04-12 12:34:53 - training - INFO - Epoch [3/5][341/438] lr: 2.0e-05, eta: 1:36:52.349990, loss: 1.0070
2023-04-12 12:35:01 - training - INFO - Epoch [3/5][351/438] lr: 2.0e-05, eta: 1:34:15.530031, loss: 0.6175
2023-04-12 12:35:08 - training - INFO - Epoch [3/5][361/438] lr: 2.0e-05, eta: 1:31:47.462852, loss: 0.8223
2023-04-12 12:35:16 - training - INFO - Epoch [3/5][371/438] lr: 2.0e-05, eta: 1:29:28.964038, loss: 1.1392
2023-04-12 12:35:24 - training - INFO - Epoch [3/5][381/438] lr: 1.9e-05, eta: 1:27:15.150123, loss: 1.3943
2023-04-12 12:35:32 - training - INFO - Epoch [3/5][391/438] lr: 1.9e-05, eta: 1:25:08.271294, loss: 0.6571
2023-04-12 12:35:39 - training - INFO - Epoch [3/5][401/438] lr: 1.9e-05, eta: 1:23:07.969937, loss: 1.2907
2023-04-12 12:35:47 - training - INFO - Epoch [3/5][411/438] lr: 1.9e-05, eta: 1:21:14.027703, loss: 0.7016
2023-04-12 12:35:55 - training - INFO - Epoch [3/5][421/438] lr: 1.9e-05, eta: 1:19:23.609194, loss: 0.6626
2023-04-12 12:36:03 - training - INFO - Epoch [3/5][431/438] lr: 1.8e-05, eta: 1:17:38.243606, loss: 0.6445
2023-04-12 12:36:56 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 0.8650, Validation Metrics: {'exact_match': 58.047016274864376, 'f1': 60.225977386651856}, Test Metrics: {'exact_match': 60.54054054054054, 'f1': 63.08998041717538}
2023-04-12 12:36:57 - training - INFO - Epoch [4/5][1/438] lr: 1.8e-05, eta: 30 days, 7:03:24.045850, loss: 0.5669
2023-04-12 12:37:05 - training - INFO - Epoch [4/5][11/438] lr: 1.8e-05, eta: 2 days, 18:12:59.845744, loss: 0.7959
2023-04-12 12:37:13 - training - INFO - Epoch [4/5][21/438] lr: 1.8e-05, eta: 1 day, 10:45:18.962379, loss: 0.9289
2023-04-12 12:37:20 - training - INFO - Epoch [4/5][31/438] lr: 1.8e-05, eta: 23:35:02.288539, loss: 0.6502
2023-04-12 12:37:28 - training - INFO - Epoch [4/5][41/438] lr: 1.7e-05, eta: 17:51:39.231864, loss: 0.5246
2023-04-12 12:37:36 - training - INFO - Epoch [4/5][51/438] lr: 1.7e-05, eta: 14:23:10.135368, loss: 0.4904
2023-04-12 12:37:44 - training - INFO - Epoch [4/5][61/438] lr: 1.7e-05, eta: 12:02:44.278891, loss: 0.6699
2023-04-12 12:37:51 - training - INFO - Epoch [4/5][71/438] lr: 1.7e-05, eta: 10:21:50.472615, loss: 0.2907
2023-04-12 12:37:59 - training - INFO - Epoch [4/5][81/438] lr: 1.6e-05, eta: 9:05:53.054715, loss: 0.6173
2023-04-12 12:38:07 - training - INFO - Epoch [4/5][91/438] lr: 1.6e-05, eta: 8:06:34.212271, loss: 0.6659
2023-04-12 12:38:15 - training - INFO - Epoch [4/5][101/438] lr: 1.6e-05, eta: 7:18:58.548601, loss: 0.5320
2023-04-12 12:38:22 - training - INFO - Epoch [4/5][111/438] lr: 1.6e-05, eta: 6:39:53.813844, loss: 0.6997
2023-04-12 12:38:30 - training - INFO - Epoch [4/5][121/438] lr: 1.6e-05, eta: 6:07:12.592721, loss: 0.4570
2023-04-12 12:38:37 - training - INFO - Epoch [4/5][131/438] lr: 1.5e-05, eta: 5:39:30.158511, loss: 0.5394
2023-04-12 12:38:45 - training - INFO - Epoch [4/5][141/438] lr: 1.5e-05, eta: 5:15:42.910746, loss: 1.0068
2023-04-12 12:38:52 - training - INFO - Epoch [4/5][151/438] lr: 1.5e-05, eta: 4:55:04.779730, loss: 0.3184
2023-04-12 12:39:00 - training - INFO - Epoch [4/5][161/438] lr: 1.5e-05, eta: 4:36:58.169425, loss: 0.8731
2023-04-12 12:39:08 - training - INFO - Epoch [4/5][171/438] lr: 1.5e-05, eta: 4:21:00.569343, loss: 0.5718
2023-04-12 12:39:16 - training - INFO - Epoch [4/5][181/438] lr: 1.4e-05, eta: 4:06:48.801070, loss: 0.8100
2023-04-12 12:39:23 - training - INFO - Epoch [4/5][191/438] lr: 1.4e-05, eta: 3:54:02.978998, loss: 1.0214
2023-04-12 12:39:31 - training - INFO - Epoch [4/5][201/438] lr: 1.4e-05, eta: 3:42:33.227082, loss: 0.6883
2023-04-12 12:39:38 - training - INFO - Epoch [4/5][211/438] lr: 1.4e-05, eta: 3:32:07.811844, loss: 1.3531
2023-04-12 12:39:46 - training - INFO - Epoch [4/5][221/438] lr: 1.4e-05, eta: 3:22:38.301309, loss: 0.6341
2023-04-12 12:39:54 - training - INFO - Epoch [4/5][231/438] lr: 1.3e-05, eta: 3:13:57.721596, loss: 0.5008
2023-04-12 12:40:01 - training - INFO - Epoch [4/5][241/438] lr: 1.3e-05, eta: 3:05:58.896203, loss: 0.6054
2023-04-12 12:40:09 - training - INFO - Epoch [4/5][251/438] lr: 1.3e-05, eta: 2:58:38.072631, loss: 0.4160
2023-04-12 12:40:17 - training - INFO - Epoch [4/5][261/438] lr: 1.3e-05, eta: 2:51:52.264248, loss: 0.4302
2023-04-12 12:40:24 - training - INFO - Epoch [4/5][271/438] lr: 1.3e-05, eta: 2:45:34.413530, loss: 0.5585
2023-04-12 12:40:32 - training - INFO - Epoch [4/5][281/438] lr: 1.2e-05, eta: 2:39:45.697971, loss: 1.0414
2023-04-12 12:40:40 - training - INFO - Epoch [4/5][291/438] lr: 1.2e-05, eta: 2:34:17.930739, loss: 0.4364
2023-04-12 12:40:48 - training - INFO - Epoch [4/5][301/438] lr: 1.2e-05, eta: 2:29:11.183287, loss: 0.8319
2023-04-12 12:40:55 - training - INFO - Epoch [4/5][311/438] lr: 1.2e-05, eta: 2:24:22.907778, loss: 0.8590
2023-04-12 12:41:03 - training - INFO - Epoch [4/5][321/438] lr: 1.2e-05, eta: 2:19:53.555646, loss: 0.7528
2023-04-12 12:41:10 - training - INFO - Epoch [4/5][331/438] lr: 1.1e-05, eta: 2:15:38.532831, loss: 0.6486
2023-04-12 12:41:18 - training - INFO - Epoch [4/5][341/438] lr: 1.1e-05, eta: 2:11:37.955426, loss: 0.9054
2023-04-12 12:41:26 - training - INFO - Epoch [4/5][351/438] lr: 1.1e-05, eta: 2:07:51.633087, loss: 0.5809
2023-04-12 12:41:33 - training - INFO - Epoch [4/5][361/438] lr: 1.1e-05, eta: 2:04:17.070770, loss: 0.4924
2023-04-12 12:41:41 - training - INFO - Epoch [4/5][371/438] lr: 1.0e-05, eta: 2:00:53.688146, loss: 0.4968
2023-04-12 12:41:48 - training - INFO - Epoch [4/5][381/438] lr: 1.0e-05, eta: 1:57:40.007817, loss: 0.4690
2023-04-12 12:41:56 - training - INFO - Epoch [4/5][391/438] lr: 1.0e-05, eta: 1:54:37.062486, loss: 1.1032
2023-04-12 12:42:04 - training - INFO - Epoch [4/5][401/438] lr: 9.8e-06, eta: 1:51:42.459876, loss: 0.5694
2023-04-12 12:42:11 - training - INFO - Epoch [4/5][411/438] lr: 9.6e-06, eta: 1:48:55.551438, loss: 0.6909
2023-04-12 12:42:19 - training - INFO - Epoch [4/5][421/438] lr: 9.4e-06, eta: 1:46:16.326889, loss: 0.9242
2023-04-12 12:42:26 - training - INFO - Epoch [4/5][431/438] lr: 9.2e-06, eta: 1:43:44.080780, loss: 0.6568
2023-04-12 12:43:19 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.7297, Validation Metrics: {'exact_match': 61.66365280289331, 'f1': 63.83351195618044}, Test Metrics: {'exact_match': 62.7027027027027, 'f1': 64.77378517535485}
2023-04-12 12:43:20 - training - INFO - Epoch [5/5][1/438] lr: 9.1e-06, eta: 39 days, 23:45:40.890960, loss: 0.5523
2023-04-12 12:43:27 - training - INFO - Epoch [5/5][11/438] lr: 8.9e-06, eta: 3 days, 15:16:20.108624, loss: 0.4789
2023-04-12 12:43:35 - training - INFO - Epoch [5/5][21/438] lr: 8.6e-06, eta: 1 day, 21:43:20.683749, loss: 0.6424
2023-04-12 12:43:43 - training - INFO - Epoch [5/5][31/438] lr: 8.4e-06, eta: 1 day, 6:58:38.967335, loss: 0.5529
2023-04-12 12:43:50 - training - INFO - Epoch [5/5][41/438] lr: 8.2e-06, eta: 23:25:34.088090, loss: 0.3159
2023-04-12 12:43:58 - training - INFO - Epoch [5/5][51/438] lr: 8.0e-06, eta: 18:49:57.018879, loss: 0.5354
2023-04-12 12:44:05 - training - INFO - Epoch [5/5][61/438] lr: 7.8e-06, eta: 15:44:39.202437, loss: 0.3513
2023-04-12 12:44:13 - training - INFO - Epoch [5/5][71/438] lr: 7.6e-06, eta: 13:31:34.706879, loss: 0.9310
2023-04-12 12:44:20 - training - INFO - Epoch [5/5][81/438] lr: 7.4e-06, eta: 11:51:17.751417, loss: 0.5561
2023-04-12 12:44:28 - training - INFO - Epoch [5/5][91/438] lr: 7.2e-06, eta: 10:33:03.308793, loss: 0.7699
2023-04-12 12:44:36 - training - INFO - Epoch [5/5][101/438] lr: 7.0e-06, eta: 9:30:16.905018, loss: 0.6321
2023-04-12 12:44:43 - training - INFO - Epoch [5/5][111/438] lr: 6.8e-06, eta: 8:38:49.430409, loss: 0.8437
2023-04-12 12:44:51 - training - INFO - Epoch [5/5][121/438] lr: 6.6e-06, eta: 7:55:50.379280, loss: 0.3586
2023-04-12 12:44:59 - training - INFO - Epoch [5/5][131/438] lr: 6.4e-06, eta: 7:19:22.618577, loss: 0.5001
2023-04-12 12:45:06 - training - INFO - Epoch [5/5][141/438] lr: 6.2e-06, eta: 6:48:04.648440, loss: 0.4421
2023-04-12 12:45:14 - training - INFO - Epoch [5/5][151/438] lr: 5.9e-06, eta: 6:20:53.489215, loss: 0.8344
2023-04-12 12:45:21 - training - INFO - Epoch [5/5][161/438] lr: 5.7e-06, eta: 5:57:05.083470, loss: 0.7409
2023-04-12 12:45:29 - training - INFO - Epoch [5/5][171/438] lr: 5.5e-06, eta: 5:36:02.583999, loss: 0.4564
2023-04-12 12:45:36 - training - INFO - Epoch [5/5][181/438] lr: 5.3e-06, eta: 5:17:17.324180, loss: 0.6762
2023-04-12 12:45:44 - training - INFO - Epoch [5/5][191/438] lr: 5.1e-06, eta: 5:00:28.861060, loss: 0.5615
2023-04-12 12:45:52 - training - INFO - Epoch [5/5][201/438] lr: 4.9e-06, eta: 4:45:22.125501, loss: 0.6786
2023-04-12 12:45:59 - training - INFO - Epoch [5/5][211/438] lr: 4.7e-06, eta: 4:31:40.941861, loss: 0.6032
2023-04-12 12:46:07 - training - INFO - Epoch [5/5][221/438] lr: 4.5e-06, eta: 4:19:11.886592, loss: 0.9902
2023-04-12 12:46:14 - training - INFO - Epoch [5/5][231/438] lr: 4.3e-06, eta: 4:07:46.467036, loss: 0.3445
2023-04-12 12:46:22 - training - INFO - Epoch [5/5][241/438] lr: 4.1e-06, eta: 3:57:17.632104, loss: 0.7113
2023-04-12 12:46:29 - training - INFO - Epoch [5/5][251/438] lr: 3.9e-06, eta: 3:47:38.996589, loss: 0.5370
2023-04-12 12:46:37 - training - INFO - Epoch [5/5][261/438] lr: 3.7e-06, eta: 3:38:43.735452, loss: 0.3876
2023-04-12 12:46:45 - training - INFO - Epoch [5/5][271/438] lr: 3.5e-06, eta: 3:30:27.050704, loss: 0.6176
2023-04-12 12:46:52 - training - INFO - Epoch [5/5][281/438] lr: 3.3e-06, eta: 3:22:45.545388, loss: 0.6496
2023-04-12 12:47:00 - training - INFO - Epoch [5/5][291/438] lr: 3.0e-06, eta: 3:15:34.925571, loss: 0.3983
2023-04-12 12:47:07 - training - INFO - Epoch [5/5][301/438] lr: 2.8e-06, eta: 3:08:52.622919, loss: 0.5478
2023-04-12 12:47:15 - training - INFO - Epoch [5/5][311/438] lr: 2.6e-06, eta: 3:02:36.704544, loss: 0.8956
2023-04-12 12:47:22 - training - INFO - Epoch [5/5][321/438] lr: 2.4e-06, eta: 2:56:42.784668, loss: 0.6235
2023-04-12 12:47:30 - training - INFO - Epoch [5/5][331/438] lr: 2.2e-06, eta: 2:51:10.460057, loss: 0.5626
2023-04-12 12:47:38 - training - INFO - Epoch [5/5][341/438] lr: 2.0e-06, eta: 2:45:57.194122, loss: 0.6774
2023-04-12 12:47:45 - training - INFO - Epoch [5/5][351/438] lr: 1.8e-06, eta: 2:41:01.085355, loss: 0.8533
2023-04-12 12:47:53 - training - INFO - Epoch [5/5][361/438] lr: 1.6e-06, eta: 2:36:21.815262, loss: 1.4753
2023-04-12 12:48:01 - training - INFO - Epoch [5/5][371/438] lr: 1.4e-06, eta: 2:31:57.226361, loss: 0.3659
2023-04-12 12:48:08 - training - INFO - Epoch [5/5][381/438] lr: 1.2e-06, eta: 2:27:45.241479, loss: 0.4778
2023-04-12 12:48:16 - training - INFO - Epoch [5/5][391/438] lr: 9.7e-07, eta: 2:23:45.748054, loss: 0.5890
2023-04-12 12:48:24 - training - INFO - Epoch [5/5][401/438] lr: 7.7e-07, eta: 2:19:57.324485, loss: 0.7650
2023-04-12 12:48:31 - training - INFO - Epoch [5/5][411/438] lr: 5.6e-07, eta: 2:16:19.907823, loss: 0.7068
2023-04-12 12:48:39 - training - INFO - Epoch [5/5][421/438] lr: 3.5e-07, eta: 2:12:54.135452, loss: 0.4440
2023-04-12 12:48:47 - training - INFO - Epoch [5/5][431/438] lr: 1.5e-07, eta: 2:09:35.647187, loss: 0.6967
2023-04-12 12:49:40 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.6218, Validation Metrics: {'exact_match': 53.52622061482821, 'f1': 56.1850759559773}, Test Metrics: {'exact_match': 55.4954954954955, 'f1': 58.05705001177112}
2023-04-12 12:50:04 - training - INFO - Final Test - Train Loss: 0.6218, Test Metrics: {'exact_match': 55.4954954954955, 'f1': 58.05705001177112}
