2023-04-12 20:04:58 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-44a167365c0b341b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepakvk/xlnet-base-cased-squad2'}, 'data': {'task_type': 'list', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 1e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_list_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 581.33it/s]
Map:   0%|          | 0/6878 [00:00<?, ? examples/s]Map:  15%|█▍        | 1000/6878 [00:00<00:03, 1520.51 examples/s]Map:  29%|██▉       | 2000/6878 [00:01<00:03, 1576.85 examples/s]Map:  44%|████▎     | 3000/6878 [00:01<00:02, 1586.36 examples/s]Map:  58%|█████▊    | 4000/6878 [00:02<00:01, 1583.84 examples/s]Map:  73%|███████▎  | 5000/6878 [00:03<00:01, 1585.57 examples/s]Map:  87%|████████▋ | 6000/6878 [00:03<00:00, 1585.76 examples/s]Map: 100%|██████████| 6878/6878 [00:04<00:00, 1458.29 examples/s]                                                                 Map:   0%|          | 0/859 [00:00<?, ? examples/s]Map: 100%|██████████| 859/859 [00:00<00:00, 1247.74 examples/s]                                                               Map:   0%|          | 0/861 [00:00<?, ? examples/s]Map: 100%|██████████| 861/861 [00:00<00:00, 1239.24 examples/s]                                                               2023-04-12 20:06:26 - training - INFO - First Test - Val Metrics:{'exact_match': 0.46565774155995343, 'f1': 2.111707080855453} Test Metrics: {'exact_match': 0.4645760743321719, 'f1': 2.558276426289279}
2023-04-12 20:06:26 - training - INFO - Epoch [1/5][1/690] lr: 1.0e-05, eta: 3 days, 0:41:24.066254, loss: 6.8472
2023-04-12 20:06:34 - training - INFO - Epoch [1/5][11/690] lr: 1.0e-05, eta: 7:14:51.758341, loss: 5.4359
2023-04-12 20:06:42 - training - INFO - Epoch [1/5][21/690] lr: 9.9e-06, eta: 4:08:08.447109, loss: 4.3420
2023-04-12 20:06:49 - training - INFO - Epoch [1/5][31/690] lr: 9.9e-06, eta: 3:01:44.603047, loss: 4.4557
2023-04-12 20:06:57 - training - INFO - Epoch [1/5][41/690] lr: 9.9e-06, eta: 2:27:40.376217, loss: 4.2202
2023-04-12 20:07:05 - training - INFO - Epoch [1/5][51/690] lr: 9.9e-06, eta: 2:06:54.324234, loss: 3.6592
2023-04-12 20:07:12 - training - INFO - Epoch [1/5][61/690] lr: 9.8e-06, eta: 1:52:51.215222, loss: 4.9124
2023-04-12 20:07:20 - training - INFO - Epoch [1/5][71/690] lr: 9.8e-06, eta: 1:42:36.598822, loss: 3.6832
2023-04-12 20:07:27 - training - INFO - Epoch [1/5][81/690] lr: 9.8e-06, eta: 1:34:52.949676, loss: 3.4318
2023-04-12 20:07:35 - training - INFO - Epoch [1/5][91/690] lr: 9.7e-06, eta: 1:28:52.086677, loss: 4.1439
2023-04-12 20:07:43 - training - INFO - Epoch [1/5][101/690] lr: 9.7e-06, eta: 1:24:02.244353, loss: 3.5295
2023-04-12 20:07:50 - training - INFO - Epoch [1/5][111/690] lr: 9.7e-06, eta: 1:20:02.871024, loss: 3.8174
2023-04-12 20:07:58 - training - INFO - Epoch [1/5][121/690] lr: 9.6e-06, eta: 1:16:40.964294, loss: 2.6724
2023-04-12 20:08:05 - training - INFO - Epoch [1/5][131/690] lr: 9.6e-06, eta: 1:13:48.067083, loss: 2.9304
2023-04-12 20:08:13 - training - INFO - Epoch [1/5][141/690] lr: 9.6e-06, eta: 1:11:27.113928, loss: 2.9375
2023-04-12 20:08:21 - training - INFO - Epoch [1/5][151/690] lr: 9.6e-06, eta: 1:09:18.132178, loss: 2.6199
2023-04-12 20:08:28 - training - INFO - Epoch [1/5][161/690] lr: 9.5e-06, eta: 1:07:24.476722, loss: 2.9570
2023-04-12 20:08:36 - training - INFO - Epoch [1/5][171/690] lr: 9.5e-06, eta: 1:05:45.827277, loss: 3.1492
2023-04-12 20:08:44 - training - INFO - Epoch [1/5][181/690] lr: 9.5e-06, eta: 1:04:14.517128, loss: 2.8031
2023-04-12 20:08:51 - training - INFO - Epoch [1/5][191/690] lr: 9.4e-06, eta: 1:02:50.291474, loss: 3.1593
2023-04-12 20:08:59 - training - INFO - Epoch [1/5][201/690] lr: 9.4e-06, eta: 1:01:37.098831, loss: 2.8749
2023-04-12 20:09:07 - training - INFO - Epoch [1/5][211/690] lr: 9.4e-06, eta: 1:00:25.626474, loss: 1.8872
2023-04-12 20:09:15 - training - INFO - Epoch [1/5][221/690] lr: 9.4e-06, eta: 0:59:26.953598, loss: 2.6234
2023-04-12 20:09:22 - training - INFO - Epoch [1/5][231/690] lr: 9.3e-06, eta: 0:58:29.913906, loss: 2.4756
2023-04-12 20:09:30 - training - INFO - Epoch [1/5][241/690] lr: 9.3e-06, eta: 0:57:36.959430, loss: 1.5074
2023-04-12 20:09:38 - training - INFO - Epoch [1/5][251/690] lr: 9.3e-06, eta: 0:56:47.011776, loss: 2.3384
2023-04-12 20:09:45 - training - INFO - Epoch [1/5][261/690] lr: 9.2e-06, eta: 0:55:58.597398, loss: 2.2916
2023-04-12 20:09:53 - training - INFO - Epoch [1/5][271/690] lr: 9.2e-06, eta: 0:55:14.765553, loss: 2.2229
2023-04-12 20:10:01 - training - INFO - Epoch [1/5][281/690] lr: 9.2e-06, eta: 0:54:31.732642, loss: 1.9129
2023-04-12 20:10:08 - training - INFO - Epoch [1/5][291/690] lr: 9.2e-06, eta: 0:53:51.202104, loss: 2.1529
2023-04-12 20:10:16 - training - INFO - Epoch [1/5][301/690] lr: 9.1e-06, eta: 0:53:12.339687, loss: 2.6072
2023-04-12 20:10:23 - training - INFO - Epoch [1/5][311/690] lr: 9.1e-06, eta: 0:52:37.862251, loss: 2.2267
2023-04-12 20:10:31 - training - INFO - Epoch [1/5][321/690] lr: 9.1e-06, eta: 0:52:02.995449, loss: 2.0113
2023-04-12 20:10:39 - training - INFO - Epoch [1/5][331/690] lr: 9.0e-06, eta: 0:51:31.371898, loss: 2.3925
2023-04-12 20:10:46 - training - INFO - Epoch [1/5][341/690] lr: 9.0e-06, eta: 0:51:00.847808, loss: 2.1023
2023-04-12 20:10:54 - training - INFO - Epoch [1/5][351/690] lr: 9.0e-06, eta: 0:50:31.113306, loss: 2.6325
2023-04-12 20:11:01 - training - INFO - Epoch [1/5][361/690] lr: 9.0e-06, eta: 0:50:02.276325, loss: 3.1113
2023-04-12 20:11:09 - training - INFO - Epoch [1/5][371/690] lr: 8.9e-06, eta: 0:49:33.984547, loss: 1.4376
2023-04-12 20:11:17 - training - INFO - Epoch [1/5][381/690] lr: 8.9e-06, eta: 0:49:08.759649, loss: 2.6541
2023-04-12 20:11:24 - training - INFO - Epoch [1/5][391/690] lr: 8.9e-06, eta: 0:48:42.690960, loss: 1.4211
2023-04-12 20:11:32 - training - INFO - Epoch [1/5][401/690] lr: 8.8e-06, eta: 0:48:18.318420, loss: 2.3582
2023-04-12 20:11:39 - training - INFO - Epoch [1/5][411/690] lr: 8.8e-06, eta: 0:47:53.918481, loss: 1.6297
2023-04-12 20:11:47 - training - INFO - Epoch [1/5][421/690] lr: 8.8e-06, eta: 0:47:31.115917, loss: 3.2801
2023-04-12 20:11:55 - training - INFO - Epoch [1/5][431/690] lr: 8.8e-06, eta: 0:47:11.112535, loss: 1.6948
2023-04-12 20:12:02 - training - INFO - Epoch [1/5][441/690] lr: 8.7e-06, eta: 0:46:49.560471, loss: 2.3843
2023-04-12 20:12:10 - training - INFO - Epoch [1/5][451/690] lr: 8.7e-06, eta: 0:46:29.375898, loss: 2.0961
2023-04-12 20:12:18 - training - INFO - Epoch [1/5][461/690] lr: 8.7e-06, eta: 0:46:09.305511, loss: 1.6506
2023-04-12 20:12:25 - training - INFO - Epoch [1/5][471/690] lr: 8.6e-06, eta: 0:45:48.613077, loss: 1.9145
2023-04-12 20:12:33 - training - INFO - Epoch [1/5][481/690] lr: 8.6e-06, eta: 0:45:33.104043, loss: 2.7607
2023-04-12 20:12:41 - training - INFO - Epoch [1/5][491/690] lr: 8.6e-06, eta: 0:45:13.459221, loss: 2.7396
2023-04-12 20:12:48 - training - INFO - Epoch [1/5][501/690] lr: 8.5e-06, eta: 0:44:55.170723, loss: 2.7183
2023-04-12 20:12:56 - training - INFO - Epoch [1/5][511/690] lr: 8.5e-06, eta: 0:44:37.161551, loss: 2.4502
2023-04-12 20:13:04 - training - INFO - Epoch [1/5][521/690] lr: 8.5e-06, eta: 0:44:20.144161, loss: 1.6671
2023-04-12 20:13:11 - training - INFO - Epoch [1/5][531/690] lr: 8.5e-06, eta: 0:44:03.437643, loss: 1.4718
2023-04-12 20:13:19 - training - INFO - Epoch [1/5][541/690] lr: 8.4e-06, eta: 0:43:47.158626, loss: 2.0791
2023-04-12 20:13:28 - training - INFO - Epoch [1/5][551/690] lr: 8.4e-06, eta: 0:43:36.396783, loss: 1.7449
2023-04-12 20:13:35 - training - INFO - Epoch [1/5][561/690] lr: 8.4e-06, eta: 0:43:20.206893, loss: 2.4132
2023-04-12 20:13:43 - training - INFO - Epoch [1/5][571/690] lr: 8.3e-06, eta: 0:43:04.990762, loss: 2.4102
2023-04-12 20:13:51 - training - INFO - Epoch [1/5][581/690] lr: 8.3e-06, eta: 0:42:51.651102, loss: 1.9605
2023-04-12 20:13:59 - training - INFO - Epoch [1/5][591/690] lr: 8.3e-06, eta: 0:42:36.497787, loss: 1.4704
2023-04-12 20:14:07 - training - INFO - Epoch [1/5][601/690] lr: 8.3e-06, eta: 0:42:22.185492, loss: 1.4470
2023-04-12 20:14:15 - training - INFO - Epoch [1/5][611/690] lr: 8.2e-06, eta: 0:42:08.237382, loss: 2.2272
2023-04-12 20:14:22 - training - INFO - Epoch [1/5][621/690] lr: 8.2e-06, eta: 0:41:53.057280, loss: 2.2345
2023-04-12 20:14:30 - training - INFO - Epoch [1/5][631/690] lr: 8.2e-06, eta: 0:41:38.584003, loss: 0.8738
2023-04-12 20:14:38 - training - INFO - Epoch [1/5][641/690] lr: 8.1e-06, eta: 0:41:26.231855, loss: 2.0163
2023-04-12 20:14:46 - training - INFO - Epoch [1/5][651/690] lr: 8.1e-06, eta: 0:41:12.591816, loss: 2.2197
2023-04-12 20:14:53 - training - INFO - Epoch [1/5][661/690] lr: 8.1e-06, eta: 0:40:58.311059, loss: 1.8136
2023-04-12 20:15:01 - training - INFO - Epoch [1/5][671/690] lr: 8.1e-06, eta: 0:40:45.506105, loss: 2.5768
2023-04-12 20:15:09 - training - INFO - Epoch [1/5][681/690] lr: 8.0e-06, eta: 0:40:32.644032, loss: 1.1253
2023-04-12 20:16:32 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 2.5045, Validation Metrics: {'exact_match': 25.145518044237484, 'f1': 30.66654018921855}, Test Metrics: {'exact_match': 26.13240418118467, 'f1': 31.74785328224402}
2023-04-12 20:16:33 - training - INFO - Epoch [2/5][1/690] lr: 8.0e-06, eta: 27 days, 5:42:42.247138, loss: 1.6510
2023-04-12 20:16:40 - training - INFO - Epoch [2/5][11/690] lr: 8.0e-06, eta: 2 days, 11:54:31.062773, loss: 1.6712
2023-04-12 20:16:48 - training - INFO - Epoch [2/5][21/690] lr: 7.9e-06, eta: 1 day, 7:37:49.367892, loss: 1.8130
2023-04-12 20:16:55 - training - INFO - Epoch [2/5][31/690] lr: 7.9e-06, eta: 21:35:40.264680, loss: 1.9268
2023-04-12 20:17:03 - training - INFO - Epoch [2/5][41/690] lr: 7.9e-06, eta: 16:27:20.016815, loss: 1.3909
2023-04-12 20:17:11 - training - INFO - Epoch [2/5][51/690] lr: 7.9e-06, eta: 13:19:58.570620, loss: 2.2151
2023-04-12 20:17:18 - training - INFO - Epoch [2/5][61/690] lr: 7.8e-06, eta: 11:13:52.803400, loss: 1.6701
2023-04-12 20:17:26 - training - INFO - Epoch [2/5][71/690] lr: 7.8e-06, eta: 9:43:17.093686, loss: 1.8726
2023-04-12 20:17:33 - training - INFO - Epoch [2/5][81/690] lr: 7.8e-06, eta: 8:34:57.688575, loss: 1.8835
2023-04-12 20:17:41 - training - INFO - Epoch [2/5][91/690] lr: 7.7e-06, eta: 7:41:42.949420, loss: 1.5727
2023-04-12 20:17:49 - training - INFO - Epoch [2/5][101/690] lr: 7.7e-06, eta: 6:59:02.362976, loss: 1.2062
2023-04-12 20:17:56 - training - INFO - Epoch [2/5][111/690] lr: 7.7e-06, eta: 6:23:55.216743, loss: 1.4625
2023-04-12 20:18:04 - training - INFO - Epoch [2/5][121/690] lr: 7.6e-06, eta: 5:54:38.222304, loss: 1.7319
2023-04-12 20:18:12 - training - INFO - Epoch [2/5][131/690] lr: 7.6e-06, eta: 5:29:53.470515, loss: 2.3989
2023-04-12 20:18:19 - training - INFO - Epoch [2/5][141/690] lr: 7.6e-06, eta: 5:08:30.926535, loss: 1.8604
2023-04-12 20:18:27 - training - INFO - Epoch [2/5][151/690] lr: 7.6e-06, eta: 4:49:55.524731, loss: 1.3454
2023-04-12 20:18:34 - training - INFO - Epoch [2/5][161/690] lr: 7.5e-06, eta: 4:33:41.033057, loss: 2.3382
2023-04-12 20:18:42 - training - INFO - Epoch [2/5][171/690] lr: 7.5e-06, eta: 4:19:20.464989, loss: 1.6210
2023-04-12 20:18:49 - training - INFO - Epoch [2/5][181/690] lr: 7.5e-06, eta: 4:06:30.881441, loss: 1.8405
2023-04-12 20:18:57 - training - INFO - Epoch [2/5][191/690] lr: 7.4e-06, eta: 3:55:02.823873, loss: 2.3075
2023-04-12 20:19:04 - training - INFO - Epoch [2/5][201/690] lr: 7.4e-06, eta: 3:44:40.523370, loss: 1.2595
2023-04-12 20:19:12 - training - INFO - Epoch [2/5][211/690] lr: 7.4e-06, eta: 3:35:22.411570, loss: 1.2649
2023-04-12 20:19:20 - training - INFO - Epoch [2/5][221/690] lr: 7.4e-06, eta: 3:26:51.423544, loss: 1.3269
2023-04-12 20:19:28 - training - INFO - Epoch [2/5][231/690] lr: 7.3e-06, eta: 3:19:03.813009, loss: 1.3281
2023-04-12 20:19:35 - training - INFO - Epoch [2/5][241/690] lr: 7.3e-06, eta: 3:11:53.436322, loss: 1.4527
2023-04-12 20:19:43 - training - INFO - Epoch [2/5][251/690] lr: 7.3e-06, eta: 3:05:18.997827, loss: 0.9848
2023-04-12 20:19:51 - training - INFO - Epoch [2/5][261/690] lr: 7.2e-06, eta: 2:59:13.690680, loss: 1.9695
2023-04-12 20:19:58 - training - INFO - Epoch [2/5][271/690] lr: 7.2e-06, eta: 2:53:33.269097, loss: 1.8428
2023-04-12 20:20:06 - training - INFO - Epoch [2/5][281/690] lr: 7.2e-06, eta: 2:48:15.781186, loss: 1.6458
2023-04-12 20:20:13 - training - INFO - Epoch [2/5][291/690] lr: 7.2e-06, eta: 2:43:21.280827, loss: 1.4037
2023-04-12 20:20:21 - training - INFO - Epoch [2/5][301/690] lr: 7.1e-06, eta: 2:38:46.247734, loss: 2.0968
2023-04-12 20:20:29 - training - INFO - Epoch [2/5][311/690] lr: 7.1e-06, eta: 2:34:28.252207, loss: 1.3087
2023-04-12 20:20:36 - training - INFO - Epoch [2/5][321/690] lr: 7.1e-06, eta: 2:30:25.099860, loss: 1.8639
2023-04-12 20:20:44 - training - INFO - Epoch [2/5][331/690] lr: 7.0e-06, eta: 2:26:37.420210, loss: 1.1159
2023-04-12 20:20:52 - training - INFO - Epoch [2/5][341/690] lr: 7.0e-06, eta: 2:23:00.112494, loss: 1.8501
2023-04-12 20:20:59 - training - INFO - Epoch [2/5][351/690] lr: 7.0e-06, eta: 2:19:35.447271, loss: 2.2198
2023-04-12 20:21:07 - training - INFO - Epoch [2/5][361/690] lr: 7.0e-06, eta: 2:16:22.699220, loss: 1.7672
2023-04-12 20:21:14 - training - INFO - Epoch [2/5][371/690] lr: 6.9e-06, eta: 2:13:20.261149, loss: 2.2576
2023-04-12 20:21:22 - training - INFO - Epoch [2/5][381/690] lr: 6.9e-06, eta: 2:10:26.962770, loss: 1.3135
2023-04-12 20:21:30 - training - INFO - Epoch [2/5][391/690] lr: 6.9e-06, eta: 2:07:41.678465, loss: 1.6704
2023-04-12 20:21:37 - training - INFO - Epoch [2/5][401/690] lr: 6.8e-06, eta: 2:05:03.253610, loss: 1.9811
2023-04-12 20:21:45 - training - INFO - Epoch [2/5][411/690] lr: 6.8e-06, eta: 2:02:33.298116, loss: 1.0856
2023-04-12 20:21:53 - training - INFO - Epoch [2/5][421/690] lr: 6.8e-06, eta: 2:00:11.173619, loss: 1.6113
2023-04-12 20:22:00 - training - INFO - Epoch [2/5][431/690] lr: 6.8e-06, eta: 1:57:54.537422, loss: 0.8128
2023-04-12 20:22:08 - training - INFO - Epoch [2/5][441/690] lr: 6.7e-06, eta: 1:55:43.035807, loss: 1.6593
2023-04-12 20:22:16 - training - INFO - Epoch [2/5][451/690] lr: 6.7e-06, eta: 1:53:37.359789, loss: 1.5049
2023-04-12 20:22:23 - training - INFO - Epoch [2/5][461/690] lr: 6.7e-06, eta: 1:51:35.536351, loss: 1.3681
2023-04-12 20:22:31 - training - INFO - Epoch [2/5][471/690] lr: 6.6e-06, eta: 1:49:41.111472, loss: 1.3691
2023-04-12 20:22:39 - training - INFO - Epoch [2/5][481/690] lr: 6.6e-06, eta: 1:47:49.934947, loss: 1.6676
2023-04-12 20:22:46 - training - INFO - Epoch [2/5][491/690] lr: 6.6e-06, eta: 1:46:02.817593, loss: 2.5179
2023-04-12 20:22:54 - training - INFO - Epoch [2/5][501/690] lr: 6.5e-06, eta: 1:44:19.290837, loss: 1.3317
2023-04-12 20:23:01 - training - INFO - Epoch [2/5][511/690] lr: 6.5e-06, eta: 1:42:39.368104, loss: 1.6124
2023-04-12 20:23:09 - training - INFO - Epoch [2/5][521/690] lr: 6.5e-06, eta: 1:41:04.178168, loss: 1.6325
2023-04-12 20:23:17 - training - INFO - Epoch [2/5][531/690] lr: 6.5e-06, eta: 1:39:33.371544, loss: 1.6447
2023-04-12 20:23:25 - training - INFO - Epoch [2/5][541/690] lr: 6.4e-06, eta: 1:38:04.758641, loss: 1.9414
2023-04-12 20:23:32 - training - INFO - Epoch [2/5][551/690] lr: 6.4e-06, eta: 1:36:37.562251, loss: 1.1179
2023-04-12 20:23:40 - training - INFO - Epoch [2/5][561/690] lr: 6.4e-06, eta: 1:35:14.395776, loss: 1.2791
2023-04-12 20:23:48 - training - INFO - Epoch [2/5][571/690] lr: 6.3e-06, eta: 1:33:52.849870, loss: 1.2792
2023-04-12 20:23:55 - training - INFO - Epoch [2/5][581/690] lr: 6.3e-06, eta: 1:32:34.412690, loss: 1.1506
2023-04-12 20:24:03 - training - INFO - Epoch [2/5][591/690] lr: 6.3e-06, eta: 1:31:17.620998, loss: 1.6853
2023-04-12 20:24:11 - training - INFO - Epoch [2/5][601/690] lr: 6.3e-06, eta: 1:30:04.458983, loss: 1.5575
2023-04-12 20:24:18 - training - INFO - Epoch [2/5][611/690] lr: 6.2e-06, eta: 1:28:52.516412, loss: 1.1729
2023-04-12 20:24:26 - training - INFO - Epoch [2/5][621/690] lr: 6.2e-06, eta: 1:27:42.681198, loss: 1.2328
2023-04-12 20:24:33 - training - INFO - Epoch [2/5][631/690] lr: 6.2e-06, eta: 1:26:34.190735, loss: 1.5075
2023-04-12 20:24:41 - training - INFO - Epoch [2/5][641/690] lr: 6.1e-06, eta: 1:25:28.385682, loss: 1.0282
2023-04-12 20:24:48 - training - INFO - Epoch [2/5][651/690] lr: 6.1e-06, eta: 1:24:24.516198, loss: 1.3274
2023-04-12 20:24:56 - training - INFO - Epoch [2/5][661/690] lr: 6.1e-06, eta: 1:23:21.505333, loss: 1.4501
2023-04-12 20:25:04 - training - INFO - Epoch [2/5][671/690] lr: 6.1e-06, eta: 1:22:20.967514, loss: 2.3589
2023-04-12 20:25:11 - training - INFO - Epoch [2/5][681/690] lr: 6.0e-06, eta: 1:21:21.827301, loss: 1.7471
2023-04-12 20:26:34 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.6302, Validation Metrics: {'exact_match': 23.748544819557626, 'f1': 29.340694260830134}, Test Metrics: {'exact_match': 24.041811846689896, 'f1': 29.37934914892048}
2023-04-12 20:26:35 - training - INFO - Epoch [3/5][1/690] lr: 6.0e-06, eta: 51 days, 6:18:57.578780, loss: 1.7637
2023-04-12 20:26:42 - training - INFO - Epoch [3/5][11/690] lr: 6.0e-06, eta: 4 days, 16:11:59.639277, loss: 1.2393
2023-04-12 20:26:50 - training - INFO - Epoch [3/5][21/690] lr: 5.9e-06, eta: 2 days, 10:56:42.999774, loss: 1.5353
2023-04-12 20:26:58 - training - INFO - Epoch [3/5][31/690] lr: 5.9e-06, eta: 1 day, 16:02:59.777040, loss: 1.5252
2023-04-12 20:27:05 - training - INFO - Epoch [3/5][41/690] lr: 5.9e-06, eta: 1 day, 6:22:10.959430, loss: 1.7532
2023-04-12 20:27:13 - training - INFO - Epoch [3/5][51/690] lr: 5.9e-06, eta: 1 day, 0:29:15.648240, loss: 1.2261
2023-04-12 20:27:21 - training - INFO - Epoch [3/5][61/690] lr: 5.8e-06, eta: 20:32:03.453807, loss: 1.1761
2023-04-12 20:27:29 - training - INFO - Epoch [3/5][71/690] lr: 5.8e-06, eta: 17:41:22.823592, loss: 1.8155
2023-04-12 20:27:36 - training - INFO - Epoch [3/5][81/690] lr: 5.8e-06, eta: 15:32:46.090782, loss: 1.5716
2023-04-12 20:27:44 - training - INFO - Epoch [3/5][91/690] lr: 5.7e-06, eta: 13:52:36.831629, loss: 1.2054
2023-04-12 20:27:52 - training - INFO - Epoch [3/5][101/690] lr: 5.7e-06, eta: 12:32:11.020181, loss: 2.0068
2023-04-12 20:27:59 - training - INFO - Epoch [3/5][111/690] lr: 5.7e-06, eta: 11:26:13.990326, loss: 1.3651
2023-04-12 20:28:07 - training - INFO - Epoch [3/5][121/690] lr: 5.6e-06, eta: 10:31:06.645949, loss: 0.9055
2023-04-12 20:28:14 - training - INFO - Epoch [3/5][131/690] lr: 5.6e-06, eta: 9:44:24.866591, loss: 0.8705
2023-04-12 20:28:22 - training - INFO - Epoch [3/5][141/690] lr: 5.6e-06, eta: 9:04:18.460074, loss: 0.9900
2023-04-12 20:28:30 - training - INFO - Epoch [3/5][151/690] lr: 5.6e-06, eta: 8:29:35.894069, loss: 1.0544
2023-04-12 20:28:38 - training - INFO - Epoch [3/5][161/690] lr: 5.5e-06, eta: 7:59:11.638773, loss: 0.9630
2023-04-12 20:28:45 - training - INFO - Epoch [3/5][171/690] lr: 5.5e-06, eta: 7:32:10.547649, loss: 1.5208
2023-04-12 20:28:53 - training - INFO - Epoch [3/5][181/690] lr: 5.5e-06, eta: 7:08:09.982423, loss: 1.5511
2023-04-12 20:29:01 - training - INFO - Epoch [3/5][191/690] lr: 5.4e-06, eta: 6:46:41.938486, loss: 2.2105
2023-04-12 20:29:08 - training - INFO - Epoch [3/5][201/690] lr: 5.4e-06, eta: 6:27:17.527041, loss: 1.6317
2023-04-12 20:29:16 - training - INFO - Epoch [3/5][211/690] lr: 5.4e-06, eta: 6:09:45.948331, loss: 1.4225
2023-04-12 20:29:23 - training - INFO - Epoch [3/5][221/690] lr: 5.4e-06, eta: 5:53:45.741088, loss: 1.3906
2023-04-12 20:29:31 - training - INFO - Epoch [3/5][231/690] lr: 5.3e-06, eta: 5:39:09.085545, loss: 1.4025
2023-04-12 20:29:39 - training - INFO - Epoch [3/5][241/690] lr: 5.3e-06, eta: 5:25:47.921937, loss: 1.2649
2023-04-12 20:29:46 - training - INFO - Epoch [3/5][251/690] lr: 5.3e-06, eta: 5:13:26.578707, loss: 0.8053
2023-04-12 20:29:54 - training - INFO - Epoch [3/5][261/690] lr: 5.2e-06, eta: 5:02:05.660523, loss: 1.2948
2023-04-12 20:30:02 - training - INFO - Epoch [3/5][271/690] lr: 5.2e-06, eta: 4:51:32.371204, loss: 0.7781
2023-04-12 20:30:09 - training - INFO - Epoch [3/5][281/690] lr: 5.2e-06, eta: 4:41:42.590370, loss: 0.8665
2023-04-12 20:30:17 - training - INFO - Epoch [3/5][291/690] lr: 5.2e-06, eta: 4:32:33.024714, loss: 1.6729
2023-04-12 20:30:25 - training - INFO - Epoch [3/5][301/690] lr: 5.1e-06, eta: 4:24:02.105713, loss: 0.9148
2023-04-12 20:30:32 - training - INFO - Epoch [3/5][311/690] lr: 5.1e-06, eta: 4:16:00.517577, loss: 1.5725
2023-04-12 20:30:40 - training - INFO - Epoch [3/5][321/690] lr: 5.1e-06, eta: 4:08:30.795795, loss: 0.9423
2023-04-12 20:30:48 - training - INFO - Epoch [3/5][331/690] lr: 5.0e-06, eta: 4:01:26.613446, loss: 1.2115
2023-04-12 20:30:56 - training - INFO - Epoch [3/5][341/690] lr: 5.0e-06, eta: 3:54:46.984706, loss: 0.8920
2023-04-12 20:31:03 - training - INFO - Epoch [3/5][351/690] lr: 5.0e-06, eta: 3:48:27.871779, loss: 1.8306
2023-04-12 20:31:11 - training - INFO - Epoch [3/5][361/690] lr: 5.0e-06, eta: 3:42:31.732972, loss: 1.6923
2023-04-12 20:31:19 - training - INFO - Epoch [3/5][371/690] lr: 4.9e-06, eta: 3:36:54.933000, loss: 1.2193
2023-04-12 20:31:26 - training - INFO - Epoch [3/5][381/690] lr: 4.9e-06, eta: 3:31:32.490921, loss: 1.6398
2023-04-12 20:31:34 - training - INFO - Epoch [3/5][391/690] lr: 4.9e-06, eta: 3:26:27.542860, loss: 1.2713
2023-04-12 20:31:42 - training - INFO - Epoch [3/5][401/690] lr: 4.8e-06, eta: 3:21:37.657554, loss: 1.3657
2023-04-12 20:31:49 - training - INFO - Epoch [3/5][411/690] lr: 4.8e-06, eta: 3:17:01.579323, loss: 1.1716
2023-04-12 20:31:57 - training - INFO - Epoch [3/5][421/690] lr: 4.8e-06, eta: 3:12:37.131326, loss: 1.1059
2023-04-12 20:32:04 - training - INFO - Epoch [3/5][431/690] lr: 4.8e-06, eta: 3:08:24.920229, loss: 1.3720
2023-04-12 20:32:12 - training - INFO - Epoch [3/5][441/690] lr: 4.7e-06, eta: 3:04:23.259507, loss: 1.2403
2023-04-12 20:32:20 - training - INFO - Epoch [3/5][451/690] lr: 4.7e-06, eta: 3:00:33.536617, loss: 2.0622
2023-04-12 20:32:27 - training - INFO - Epoch [3/5][461/690] lr: 4.7e-06, eta: 2:56:53.063223, loss: 1.7183
2023-04-12 20:32:35 - training - INFO - Epoch [3/5][471/690] lr: 4.6e-06, eta: 2:53:21.667056, loss: 1.1534
2023-04-12 20:32:43 - training - INFO - Epoch [3/5][481/690] lr: 4.6e-06, eta: 2:49:58.440775, loss: 1.4646
2023-04-12 20:32:50 - training - INFO - Epoch [3/5][491/690] lr: 4.6e-06, eta: 2:46:42.497076, loss: 1.1976
2023-04-12 20:32:58 - training - INFO - Epoch [3/5][501/690] lr: 4.5e-06, eta: 2:43:33.826701, loss: 1.4643
2023-04-12 20:33:05 - training - INFO - Epoch [3/5][511/690] lr: 4.5e-06, eta: 2:40:33.548248, loss: 1.8782
2023-04-12 20:33:13 - training - INFO - Epoch [3/5][521/690] lr: 4.5e-06, eta: 2:37:40.028549, loss: 1.6827
2023-04-12 20:33:21 - training - INFO - Epoch [3/5][531/690] lr: 4.5e-06, eta: 2:34:51.781233, loss: 1.9582
2023-04-12 20:33:28 - training - INFO - Epoch [3/5][541/690] lr: 4.4e-06, eta: 2:32:10.001224, loss: 1.6604
2023-04-12 20:33:36 - training - INFO - Epoch [3/5][551/690] lr: 4.4e-06, eta: 2:29:33.025386, loss: 1.0994
2023-04-12 20:33:44 - training - INFO - Epoch [3/5][561/690] lr: 4.4e-06, eta: 2:27:03.162006, loss: 1.2956
2023-04-12 20:33:52 - training - INFO - Epoch [3/5][571/690] lr: 4.3e-06, eta: 2:24:38.166821, loss: 1.7766
2023-04-12 20:33:59 - training - INFO - Epoch [3/5][581/690] lr: 4.3e-06, eta: 2:22:16.474242, loss: 1.3056
2023-04-12 20:34:07 - training - INFO - Epoch [3/5][591/690] lr: 4.3e-06, eta: 2:19:59.267406, loss: 1.0827
2023-04-12 20:34:15 - training - INFO - Epoch [3/5][601/690] lr: 4.3e-06, eta: 2:17:48.601418, loss: 1.3150
2023-04-12 20:34:23 - training - INFO - Epoch [3/5][611/690] lr: 4.2e-06, eta: 2:15:40.946060, loss: 1.4937
2023-04-12 20:34:30 - training - INFO - Epoch [3/5][621/690] lr: 4.2e-06, eta: 2:13:36.774936, loss: 1.3177
2023-04-12 20:34:38 - training - INFO - Epoch [3/5][631/690] lr: 4.2e-06, eta: 2:11:36.675827, loss: 1.8926
2023-04-12 20:34:46 - training - INFO - Epoch [3/5][641/690] lr: 4.1e-06, eta: 2:09:39.213701, loss: 1.6290
2023-04-12 20:34:53 - training - INFO - Epoch [3/5][651/690] lr: 4.1e-06, eta: 2:07:44.689233, loss: 1.2034
2023-04-12 20:35:01 - training - INFO - Epoch [3/5][661/690] lr: 4.1e-06, eta: 2:05:54.009289, loss: 0.9493
2023-04-12 20:35:08 - training - INFO - Epoch [3/5][671/690] lr: 4.1e-06, eta: 2:04:06.055379, loss: 1.3954
2023-04-12 20:35:16 - training - INFO - Epoch [3/5][681/690] lr: 4.0e-06, eta: 2:02:22.820355, loss: 2.0233
2023-04-12 20:36:40 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.4183, Validation Metrics: {'exact_match': 23.28288707799767, 'f1': 29.511226041195275}, Test Metrics: {'exact_match': 24.274099883855982, 'f1': 29.547522814731128}
2023-04-12 20:36:41 - training - INFO - Epoch [4/5][1/690] lr: 4.0e-06, eta: 75 days, 11:28:27.635350, loss: 1.5096
2023-04-12 20:36:49 - training - INFO - Epoch [4/5][11/690] lr: 4.0e-06, eta: 6 days, 20:51:42.207320, loss: 1.2754
2023-04-12 20:36:57 - training - INFO - Epoch [4/5][21/690] lr: 3.9e-06, eta: 3 days, 14:27:15.647022, loss: 0.8510
2023-04-12 20:37:04 - training - INFO - Epoch [4/5][31/690] lr: 3.9e-06, eta: 2 days, 10:37:30.856094, loss: 1.6790
2023-04-12 20:37:12 - training - INFO - Epoch [4/5][41/690] lr: 3.9e-06, eta: 1 day, 20:22:14.272124, loss: 1.1440
2023-04-12 20:37:19 - training - INFO - Epoch [4/5][51/690] lr: 3.9e-06, eta: 1 day, 11:42:20.040783, loss: 1.0528
2023-04-12 20:37:27 - training - INFO - Epoch [4/5][61/690] lr: 3.8e-06, eta: 1 day, 5:53:02.317229, loss: 1.4574
2023-04-12 20:37:34 - training - INFO - Epoch [4/5][71/690] lr: 3.8e-06, eta: 1 day, 1:41:57.901919, loss: 1.5696
2023-04-12 20:37:42 - training - INFO - Epoch [4/5][81/690] lr: 3.8e-06, eta: 22:33:00.899622, loss: 1.5850
2023-04-12 20:37:50 - training - INFO - Epoch [4/5][91/690] lr: 3.7e-06, eta: 20:05:28.379608, loss: 1.5184
2023-04-12 20:37:58 - training - INFO - Epoch [4/5][101/690] lr: 3.7e-06, eta: 18:07:04.892919, loss: 1.4164
2023-04-12 20:38:05 - training - INFO - Epoch [4/5][111/690] lr: 3.7e-06, eta: 16:29:57.711408, loss: 1.1578
2023-04-12 20:38:13 - training - INFO - Epoch [4/5][121/690] lr: 3.6e-06, eta: 15:09:00.068951, loss: 1.2590
2023-04-12 20:38:20 - training - INFO - Epoch [4/5][131/690] lr: 3.6e-06, eta: 14:00:14.932924, loss: 0.7652
2023-04-12 20:38:28 - training - INFO - Epoch [4/5][141/690] lr: 3.6e-06, eta: 13:01:16.415751, loss: 1.4205
2023-04-12 20:38:36 - training - INFO - Epoch [4/5][151/690] lr: 3.6e-06, eta: 12:10:06.424702, loss: 0.8439
2023-04-12 20:38:43 - training - INFO - Epoch [4/5][161/690] lr: 3.5e-06, eta: 11:25:20.275196, loss: 1.6118
2023-04-12 20:38:51 - training - INFO - Epoch [4/5][171/690] lr: 3.5e-06, eta: 10:45:49.211973, loss: 1.1947
2023-04-12 20:38:59 - training - INFO - Epoch [4/5][181/690] lr: 3.5e-06, eta: 10:10:42.185041, loss: 1.4593
2023-04-12 20:39:07 - training - INFO - Epoch [4/5][191/690] lr: 3.4e-06, eta: 9:39:06.294537, loss: 1.4845
2023-04-12 20:39:15 - training - INFO - Epoch [4/5][201/690] lr: 3.4e-06, eta: 9:10:39.906246, loss: 1.5079
2023-04-12 20:39:22 - training - INFO - Epoch [4/5][211/690] lr: 3.4e-06, eta: 8:44:51.682784, loss: 1.0209
2023-04-12 20:39:30 - training - INFO - Epoch [4/5][221/690] lr: 3.4e-06, eta: 8:21:25.655341, loss: 1.0211
2023-04-12 20:39:37 - training - INFO - Epoch [4/5][231/690] lr: 3.3e-06, eta: 8:00:02.086194, loss: 1.4090
2023-04-12 20:39:45 - training - INFO - Epoch [4/5][241/690] lr: 3.3e-06, eta: 7:40:25.019863, loss: 0.8546
2023-04-12 20:39:53 - training - INFO - Epoch [4/5][251/690] lr: 3.3e-06, eta: 7:22:17.630798, loss: 1.0131
2023-04-12 20:40:00 - training - INFO - Epoch [4/5][261/690] lr: 3.2e-06, eta: 7:05:33.736224, loss: 1.0728
2023-04-12 20:40:08 - training - INFO - Epoch [4/5][271/690] lr: 3.2e-06, eta: 6:50:03.514452, loss: 1.4468
2023-04-12 20:40:15 - training - INFO - Epoch [4/5][281/690] lr: 3.2e-06, eta: 6:35:38.342031, loss: 0.7827
2023-04-12 20:40:23 - training - INFO - Epoch [4/5][291/690] lr: 3.2e-06, eta: 6:22:14.488473, loss: 1.1882
2023-04-12 20:40:31 - training - INFO - Epoch [4/5][301/690] lr: 3.1e-06, eta: 6:09:43.398165, loss: 1.3053
2023-04-12 20:40:39 - training - INFO - Epoch [4/5][311/690] lr: 3.1e-06, eta: 5:58:01.212870, loss: 1.0030
2023-04-12 20:40:46 - training - INFO - Epoch [4/5][321/690] lr: 3.1e-06, eta: 5:46:59.314656, loss: 0.8788
2023-04-12 20:40:54 - training - INFO - Epoch [4/5][331/690] lr: 3.0e-06, eta: 5:36:36.420153, loss: 1.4015
2023-04-12 20:41:01 - training - INFO - Epoch [4/5][341/690] lr: 3.0e-06, eta: 5:26:50.486959, loss: 1.3076
2023-04-12 20:41:09 - training - INFO - Epoch [4/5][351/690] lr: 3.0e-06, eta: 5:17:37.622796, loss: 1.6186
2023-04-12 20:41:17 - training - INFO - Epoch [4/5][361/690] lr: 3.0e-06, eta: 5:08:55.040993, loss: 1.2824
2023-04-12 20:41:24 - training - INFO - Epoch [4/5][371/690] lr: 2.9e-06, eta: 5:00:40.569170, loss: 1.0553
2023-04-12 20:41:32 - training - INFO - Epoch [4/5][381/690] lr: 2.9e-06, eta: 4:52:51.565638, loss: 1.0158
2023-04-12 20:41:40 - training - INFO - Epoch [4/5][391/690] lr: 2.9e-06, eta: 4:45:28.738963, loss: 0.6247
2023-04-12 20:41:48 - training - INFO - Epoch [4/5][401/690] lr: 2.8e-06, eta: 4:38:28.520000, loss: 1.2772
2023-04-12 20:41:56 - training - INFO - Epoch [4/5][411/690] lr: 2.8e-06, eta: 4:31:44.891424, loss: 0.9385
2023-04-12 20:42:03 - training - INFO - Epoch [4/5][421/690] lr: 2.8e-06, eta: 4:25:20.030230, loss: 1.8072
2023-04-12 20:42:11 - training - INFO - Epoch [4/5][431/690] lr: 2.8e-06, eta: 4:19:13.664594, loss: 0.6152
2023-04-12 20:42:19 - training - INFO - Epoch [4/5][441/690] lr: 2.7e-06, eta: 4:13:22.448934, loss: 1.6140
2023-04-12 20:42:26 - training - INFO - Epoch [4/5][451/690] lr: 2.7e-06, eta: 4:07:47.158628, loss: 1.1172
2023-04-12 20:42:34 - training - INFO - Epoch [4/5][461/690] lr: 2.7e-06, eta: 4:02:25.687534, loss: 0.6746
2023-04-12 20:42:42 - training - INFO - Epoch [4/5][471/690] lr: 2.6e-06, eta: 3:57:17.570448, loss: 1.2758
2023-04-12 20:42:49 - training - INFO - Epoch [4/5][481/690] lr: 2.6e-06, eta: 3:52:22.483380, loss: 1.0903
2023-04-12 20:42:57 - training - INFO - Epoch [4/5][491/690] lr: 2.6e-06, eta: 3:47:37.826710, loss: 1.2826
2023-04-12 20:43:04 - training - INFO - Epoch [4/5][501/690] lr: 2.5e-06, eta: 3:43:04.523085, loss: 1.5721
2023-04-12 20:43:12 - training - INFO - Epoch [4/5][511/690] lr: 2.5e-06, eta: 3:38:41.832653, loss: 1.0596
2023-04-12 20:43:20 - training - INFO - Epoch [4/5][521/690] lr: 2.5e-06, eta: 3:34:28.910051, loss: 1.4357
2023-04-12 20:43:27 - training - INFO - Epoch [4/5][531/690] lr: 2.5e-06, eta: 3:30:24.908520, loss: 1.2197
2023-04-12 20:43:35 - training - INFO - Epoch [4/5][541/690] lr: 2.4e-06, eta: 3:26:29.919712, loss: 0.9859
2023-04-12 20:43:42 - training - INFO - Epoch [4/5][551/690] lr: 2.4e-06, eta: 3:22:44.079343, loss: 1.0644
2023-04-12 20:43:50 - training - INFO - Epoch [4/5][561/690] lr: 2.4e-06, eta: 3:19:05.070297, loss: 1.3616
2023-04-12 20:43:58 - training - INFO - Epoch [4/5][571/690] lr: 2.3e-06, eta: 3:15:33.911510, loss: 1.3899
2023-04-12 20:44:06 - training - INFO - Epoch [4/5][581/690] lr: 2.3e-06, eta: 3:12:10.723306, loss: 0.8848
2023-04-12 20:44:14 - training - INFO - Epoch [4/5][591/690] lr: 2.3e-06, eta: 3:08:54.765669, loss: 1.1728
2023-04-12 20:44:21 - training - INFO - Epoch [4/5][601/690] lr: 2.3e-06, eta: 3:05:44.191135, loss: 1.1149
2023-04-12 20:44:29 - training - INFO - Epoch [4/5][611/690] lr: 2.2e-06, eta: 3:02:38.775637, loss: 0.5944
2023-04-12 20:44:37 - training - INFO - Epoch [4/5][621/690] lr: 2.2e-06, eta: 2:59:40.611750, loss: 1.6751
2023-04-12 20:44:45 - training - INFO - Epoch [4/5][631/690] lr: 2.2e-06, eta: 2:56:46.693287, loss: 1.7179
2023-04-12 20:44:52 - training - INFO - Epoch [4/5][641/690] lr: 2.1e-06, eta: 2:53:56.974332, loss: 0.8642
2023-04-12 20:45:00 - training - INFO - Epoch [4/5][651/690] lr: 2.1e-06, eta: 2:51:12.791835, loss: 1.9325
2023-04-12 20:45:08 - training - INFO - Epoch [4/5][661/690] lr: 2.1e-06, eta: 2:48:34.584611, loss: 1.9302
2023-04-12 20:45:15 - training - INFO - Epoch [4/5][671/690] lr: 2.1e-06, eta: 2:45:59.324620, loss: 1.6670
2023-04-12 20:45:23 - training - INFO - Epoch [4/5][681/690] lr: 2.0e-06, eta: 2:43:29.088354, loss: 1.5620
2023-04-12 20:46:46 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 1.3021, Validation Metrics: {'exact_match': 24.679860302677533, 'f1': 29.642880189895763}, Test Metrics: {'exact_match': 27.06155632984901, 'f1': 31.233294324997907}
2023-04-12 20:46:47 - training - INFO - Epoch [5/5][1/690] lr: 2.0e-06, eta: 99 days, 16:03:07.597920, loss: 0.5988
2023-04-12 20:46:55 - training - INFO - Epoch [5/5][11/690] lr: 2.0e-06, eta: 9 days, 1:29:18.137627, loss: 1.9104
2023-04-12 20:47:02 - training - INFO - Epoch [5/5][21/690] lr: 1.9e-06, eta: 4 days, 17:55:56.426574, loss: 1.2211
2023-04-12 20:47:10 - training - INFO - Epoch [5/5][31/690] lr: 1.9e-06, eta: 3 days, 5:11:11.463870, loss: 1.3831
2023-04-12 20:47:17 - training - INFO - Epoch [5/5][41/690] lr: 1.9e-06, eta: 2 days, 10:21:51.038935, loss: 1.1878
2023-04-12 20:47:25 - training - INFO - Epoch [5/5][51/690] lr: 1.9e-06, eta: 1 day, 22:55:28.005675, loss: 1.2196
2023-04-12 20:47:33 - training - INFO - Epoch [5/5][61/690] lr: 1.8e-06, eta: 1 day, 15:14:01.272154, loss: 1.3000
2023-04-12 20:47:40 - training - INFO - Epoch [5/5][71/690] lr: 1.8e-06, eta: 1 day, 9:42:34.325088, loss: 1.2448
2023-04-12 20:47:48 - training - INFO - Epoch [5/5][81/690] lr: 1.8e-06, eta: 1 day, 5:32:49.696413, loss: 0.9898
2023-04-12 20:47:56 - training - INFO - Epoch [5/5][91/690] lr: 1.7e-06, eta: 1 day, 2:18:03.135946, loss: 1.4670
2023-04-12 20:48:03 - training - INFO - Epoch [5/5][101/690] lr: 1.7e-06, eta: 23:41:54.010077, loss: 1.0833
2023-04-12 20:48:11 - training - INFO - Epoch [5/5][111/690] lr: 1.7e-06, eta: 21:33:40.955013, loss: 1.5066
2023-04-12 20:48:18 - training - INFO - Epoch [5/5][121/690] lr: 1.6e-06, eta: 19:46:40.898346, loss: 1.1938
2023-04-12 20:48:26 - training - INFO - Epoch [5/5][131/690] lr: 1.6e-06, eta: 18:15:58.806003, loss: 1.1522
2023-04-12 20:48:34 - training - INFO - Epoch [5/5][141/690] lr: 1.6e-06, eta: 16:58:09.060483, loss: 1.1435
2023-04-12 20:48:41 - training - INFO - Epoch [5/5][151/690] lr: 1.6e-06, eta: 15:50:39.528555, loss: 1.2893
2023-04-12 20:48:49 - training - INFO - Epoch [5/5][161/690] lr: 1.5e-06, eta: 14:51:31.809228, loss: 1.4375
2023-04-12 20:48:57 - training - INFO - Epoch [5/5][171/690] lr: 1.5e-06, eta: 13:59:17.094945, loss: 1.1639
2023-04-12 20:49:04 - training - INFO - Epoch [5/5][181/690] lr: 1.5e-06, eta: 13:12:47.104585, loss: 1.1574
2023-04-12 20:49:12 - training - INFO - Epoch [5/5][191/690] lr: 1.4e-06, eta: 12:31:12.846671, loss: 1.0543
2023-04-12 20:49:20 - training - INFO - Epoch [5/5][201/690] lr: 1.4e-06, eta: 11:53:39.987564, loss: 1.1002
2023-04-12 20:49:27 - training - INFO - Epoch [5/5][211/690] lr: 1.4e-06, eta: 11:19:43.321109, loss: 1.1243
2023-04-12 20:49:35 - training - INFO - Epoch [5/5][221/690] lr: 1.4e-06, eta: 10:48:48.949931, loss: 1.0676
2023-04-12 20:49:42 - training - INFO - Epoch [5/5][231/690] lr: 1.3e-06, eta: 10:20:33.419754, loss: 1.2125
2023-04-12 20:49:50 - training - INFO - Epoch [5/5][241/690] lr: 1.3e-06, eta: 9:54:41.939597, loss: 1.8170
2023-04-12 20:49:58 - training - INFO - Epoch [5/5][251/690] lr: 1.3e-06, eta: 9:30:49.863172, loss: 2.2187
2023-04-12 20:50:06 - training - INFO - Epoch [5/5][261/690] lr: 1.2e-06, eta: 9:08:49.553409, loss: 1.5552
2023-04-12 20:50:13 - training - INFO - Epoch [5/5][271/690] lr: 1.2e-06, eta: 8:48:24.548480, loss: 1.3915
2023-04-12 20:50:21 - training - INFO - Epoch [5/5][281/690] lr: 1.2e-06, eta: 8:29:25.892320, loss: 1.2914
2023-04-12 20:50:29 - training - INFO - Epoch [5/5][291/690] lr: 1.2e-06, eta: 8:11:47.650380, loss: 1.1009
2023-04-12 20:50:36 - training - INFO - Epoch [5/5][301/690] lr: 1.1e-06, eta: 7:55:16.421343, loss: 1.4039
2023-04-12 20:50:44 - training - INFO - Epoch [5/5][311/690] lr: 1.1e-06, eta: 7:39:49.214047, loss: 1.1092
2023-04-12 20:50:51 - training - INFO - Epoch [5/5][321/690] lr: 1.1e-06, eta: 7:25:18.240003, loss: 1.3833
2023-04-12 20:50:59 - training - INFO - Epoch [5/5][331/690] lr: 1.0e-06, eta: 7:11:40.609541, loss: 1.3256
2023-04-12 20:51:07 - training - INFO - Epoch [5/5][341/690] lr: 1.0e-06, eta: 6:58:50.799378, loss: 0.8038
2023-04-12 20:51:15 - training - INFO - Epoch [5/5][351/690] lr: 9.8e-07, eta: 6:46:44.392575, loss: 1.3496
2023-04-12 20:51:22 - training - INFO - Epoch [5/5][361/690] lr: 9.5e-07, eta: 6:35:16.288651, loss: 1.0039
2023-04-12 20:51:30 - training - INFO - Epoch [5/5][371/690] lr: 9.2e-07, eta: 6:24:24.859817, loss: 0.4871
2023-04-12 20:51:37 - training - INFO - Epoch [5/5][381/690] lr: 9.0e-07, eta: 6:14:06.929934, loss: 1.2373
2023-04-12 20:51:45 - training - INFO - Epoch [5/5][391/690] lr: 8.7e-07, eta: 6:04:21.834834, loss: 0.9477
2023-04-12 20:51:52 - training - INFO - Epoch [5/5][401/690] lr: 8.4e-07, eta: 5:55:04.780785, loss: 1.0131
2023-04-12 20:52:00 - training - INFO - Epoch [5/5][411/690] lr: 8.1e-07, eta: 5:46:14.819769, loss: 1.4051
2023-04-12 20:52:08 - training - INFO - Epoch [5/5][421/690] lr: 7.8e-07, eta: 5:37:49.004821, loss: 1.1647
2023-04-12 20:52:16 - training - INFO - Epoch [5/5][431/690] lr: 7.5e-07, eta: 5:29:49.397069, loss: 1.0878
2023-04-12 20:52:23 - training - INFO - Epoch [5/5][441/690] lr: 7.2e-07, eta: 5:22:08.714706, loss: 1.3460
2023-04-12 20:52:31 - training - INFO - Epoch [5/5][451/690] lr: 6.9e-07, eta: 5:14:48.517728, loss: 1.1033
2023-04-12 20:52:39 - training - INFO - Epoch [5/5][461/690] lr: 6.6e-07, eta: 5:07:47.396017, loss: 1.1939
2023-04-12 20:52:47 - training - INFO - Epoch [5/5][471/690] lr: 6.3e-07, eta: 5:01:06.771090, loss: 1.0517
2023-04-12 20:52:55 - training - INFO - Epoch [5/5][481/690] lr: 6.1e-07, eta: 4:54:40.210922, loss: 2.2409
2023-04-12 20:53:03 - training - INFO - Epoch [5/5][491/690] lr: 5.8e-07, eta: 4:48:29.132104, loss: 1.5320
2023-04-12 20:53:10 - training - INFO - Epoch [5/5][501/690] lr: 5.5e-07, eta: 4:42:31.258962, loss: 1.4355
2023-04-12 20:53:18 - training - INFO - Epoch [5/5][511/690] lr: 5.2e-07, eta: 4:36:46.907670, loss: 1.1314
2023-04-12 20:53:26 - training - INFO - Epoch [5/5][521/690] lr: 4.9e-07, eta: 4:31:15.793975, loss: 0.8741
2023-04-12 20:53:33 - training - INFO - Epoch [5/5][531/690] lr: 4.6e-07, eta: 4:25:57.052104, loss: 1.8348
2023-04-12 20:53:41 - training - INFO - Epoch [5/5][541/690] lr: 4.3e-07, eta: 4:20:49.820746, loss: 1.5325
2023-04-12 20:53:48 - training - INFO - Epoch [5/5][551/690] lr: 4.0e-07, eta: 4:15:52.535796, loss: 1.2712
2023-04-12 20:53:56 - training - INFO - Epoch [5/5][561/690] lr: 3.7e-07, eta: 4:11:06.681021, loss: 0.9253
2023-04-12 20:54:04 - training - INFO - Epoch [5/5][571/690] lr: 3.4e-07, eta: 4:06:30.735824, loss: 0.8561
2023-04-12 20:54:12 - training - INFO - Epoch [5/5][581/690] lr: 3.2e-07, eta: 4:02:03.701403, loss: 1.3849
2023-04-12 20:54:19 - training - INFO - Epoch [5/5][591/690] lr: 2.9e-07, eta: 3:57:45.858213, loss: 1.2955
2023-04-12 20:54:27 - training - INFO - Epoch [5/5][601/690] lr: 2.6e-07, eta: 3:53:35.205358, loss: 1.3612
2023-04-12 20:54:35 - training - INFO - Epoch [5/5][611/690] lr: 2.3e-07, eta: 3:49:32.553961, loss: 1.0530
2023-04-12 20:54:42 - training - INFO - Epoch [5/5][621/690] lr: 2.0e-07, eta: 3:45:37.695741, loss: 1.0567
2023-04-12 20:54:50 - training - INFO - Epoch [5/5][631/690] lr: 1.7e-07, eta: 3:41:51.033281, loss: 1.1439
2023-04-12 20:54:58 - training - INFO - Epoch [5/5][641/690] lr: 1.4e-07, eta: 3:38:13.566419, loss: 1.0900
2023-04-12 20:55:07 - training - INFO - Epoch [5/5][651/690] lr: 1.1e-07, eta: 3:34:41.563398, loss: 1.1484
2023-04-12 20:55:14 - training - INFO - Epoch [5/5][661/690] lr: 8.4e-08, eta: 3:31:14.423637, loss: 0.8550
2023-04-12 20:55:22 - training - INFO - Epoch [5/5][671/690] lr: 5.5e-08, eta: 3:27:52.502154, loss: 0.8492
2023-04-12 20:55:30 - training - INFO - Epoch [5/5][681/690] lr: 2.6e-08, eta: 3:24:35.835390, loss: 1.1055
2023-04-12 20:56:54 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 1.2292, Validation Metrics: {'exact_match': 25.029103608847496, 'f1': 29.94554624636117}, Test Metrics: {'exact_match': 26.13240418118467, 'f1': 30.990448756054693}
2023-04-12 20:57:33 - training - INFO - Final Test - Train Loss: 1.2292, Test Metrics: {'exact_match': 26.13240418118467, 'f1': 30.990448756054693}
