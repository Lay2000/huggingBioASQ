2023-04-12 13:58:43 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepakvk/xlnet-base-cased-squad2'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-06, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_factoid_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 586.34it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1230.16 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1444.88 examples/s]Map:  68%|██████▊   | 3000/4429 [00:02<00:00, 1507.20 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1533.45 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1527.32 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1204.59 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1205.73 examples/s]                                                               2023-04-12 13:59:43 - training - INFO - First Test - Val Metrics:{'exact_match': 0.3616636528028933, 'f1': 4.288024128918328} Test Metrics: {'exact_match': 0.18018018018018017, 'f1': 3.8611520082108313}
2023-04-12 13:59:44 - training - INFO - Epoch [1/5][1/438] lr: 4.5e-06, eta: 1 day, 6:10:48.252482, loss: 6.4757
2023-04-12 13:59:52 - training - INFO - Epoch [1/5][11/438] lr: 4.5e-06, eta: 3:09:15.132893, loss: 5.6416
2023-04-12 13:59:59 - training - INFO - Epoch [1/5][21/438] lr: 4.5e-06, eta: 1:51:33.319269, loss: 5.0684
2023-04-12 14:00:07 - training - INFO - Epoch [1/5][31/438] lr: 4.5e-06, eta: 1:23:58.894418, loss: 5.2906
2023-04-12 14:00:14 - training - INFO - Epoch [1/5][41/438] lr: 4.5e-06, eta: 1:09:56.693991, loss: 4.4234
2023-04-12 14:00:22 - training - INFO - Epoch [1/5][51/438] lr: 4.4e-06, eta: 1:01:27.832788, loss: 5.1691
2023-04-12 14:00:30 - training - INFO - Epoch [1/5][61/438] lr: 4.4e-06, eta: 0:55:30.467086, loss: 3.9019
2023-04-12 14:00:37 - training - INFO - Epoch [1/5][71/438] lr: 4.4e-06, eta: 0:51:13.111535, loss: 3.8443
2023-04-12 14:00:45 - training - INFO - Epoch [1/5][81/438] lr: 4.4e-06, eta: 0:48:00.472200, loss: 4.4045
2023-04-12 14:00:52 - training - INFO - Epoch [1/5][91/438] lr: 4.4e-06, eta: 0:45:25.179977, loss: 3.6551
2023-04-12 14:01:00 - training - INFO - Epoch [1/5][101/438] lr: 4.3e-06, eta: 0:43:20.115630, loss: 3.9439
2023-04-12 14:01:08 - training - INFO - Epoch [1/5][111/438] lr: 4.3e-06, eta: 0:41:39.170058, loss: 3.9199
2023-04-12 14:01:15 - training - INFO - Epoch [1/5][121/438] lr: 4.3e-06, eta: 0:40:11.957440, loss: 3.5961
2023-04-12 14:01:23 - training - INFO - Epoch [1/5][131/438] lr: 4.3e-06, eta: 0:38:57.576523, loss: 3.5082
2023-04-12 14:01:30 - training - INFO - Epoch [1/5][141/438] lr: 4.2e-06, eta: 0:37:50.537880, loss: 3.4467
2023-04-12 14:01:38 - training - INFO - Epoch [1/5][151/438] lr: 4.2e-06, eta: 0:36:51.370943, loss: 3.6830
2023-04-12 14:01:45 - training - INFO - Epoch [1/5][161/438] lr: 4.2e-06, eta: 0:35:57.825268, loss: 3.8951
2023-04-12 14:01:53 - training - INFO - Epoch [1/5][171/438] lr: 4.2e-06, eta: 0:35:09.612720, loss: 3.4328
2023-04-12 14:02:01 - training - INFO - Epoch [1/5][181/438] lr: 4.2e-06, eta: 0:34:27.552305, loss: 3.6362
2023-04-12 14:02:09 - training - INFO - Epoch [1/5][191/438] lr: 4.1e-06, eta: 0:33:55.113934, loss: 3.5807
2023-04-12 14:02:18 - training - INFO - Epoch [1/5][201/438] lr: 4.1e-06, eta: 0:33:35.020098, loss: 3.2643
2023-04-12 14:02:26 - training - INFO - Epoch [1/5][211/438] lr: 4.1e-06, eta: 0:33:02.045681, loss: 2.4657
2023-04-12 14:02:33 - training - INFO - Epoch [1/5][221/438] lr: 4.1e-06, eta: 0:32:30.085786, loss: 2.9564
2023-04-12 14:02:41 - training - INFO - Epoch [1/5][231/438] lr: 4.1e-06, eta: 0:32:00.217677, loss: 2.5686
2023-04-12 14:02:48 - training - INFO - Epoch [1/5][241/438] lr: 4.0e-06, eta: 0:31:31.950821, loss: 3.1461
2023-04-12 14:02:56 - training - INFO - Epoch [1/5][251/438] lr: 4.0e-06, eta: 0:31:08.845041, loss: 3.1514
2023-04-12 14:03:04 - training - INFO - Epoch [1/5][261/438] lr: 4.0e-06, eta: 0:30:47.065725, loss: 2.6711
2023-04-12 14:03:12 - training - INFO - Epoch [1/5][271/438] lr: 4.0e-06, eta: 0:30:23.882846, loss: 2.9443
2023-04-12 14:03:19 - training - INFO - Epoch [1/5][281/438] lr: 4.0e-06, eta: 0:30:01.368671, loss: 1.8500
2023-04-12 14:03:27 - training - INFO - Epoch [1/5][291/438] lr: 3.9e-06, eta: 0:29:39.573789, loss: 2.2252
2023-04-12 14:03:35 - training - INFO - Epoch [1/5][301/438] lr: 3.9e-06, eta: 0:29:19.229478, loss: 3.2673
2023-04-12 14:03:42 - training - INFO - Epoch [1/5][311/438] lr: 3.9e-06, eta: 0:28:59.860050, loss: 2.4986
2023-04-12 14:03:50 - training - INFO - Epoch [1/5][321/438] lr: 3.9e-06, eta: 0:28:40.263111, loss: 2.3153
2023-04-12 14:03:57 - training - INFO - Epoch [1/5][331/438] lr: 3.9e-06, eta: 0:28:22.697139, loss: 2.7915
2023-04-12 14:04:05 - training - INFO - Epoch [1/5][341/438] lr: 3.8e-06, eta: 0:28:04.843931, loss: 3.2132
2023-04-12 14:04:13 - training - INFO - Epoch [1/5][351/438] lr: 3.8e-06, eta: 0:27:47.562903, loss: 2.3703
2023-04-12 14:04:21 - training - INFO - Epoch [1/5][361/438] lr: 3.8e-06, eta: 0:27:34.334158, loss: 2.3743
2023-04-12 14:04:28 - training - INFO - Epoch [1/5][371/438] lr: 3.8e-06, eta: 0:27:18.442422, loss: 2.4184
2023-04-12 14:04:36 - training - INFO - Epoch [1/5][381/438] lr: 3.8e-06, eta: 0:27:02.246076, loss: 2.2969
2023-04-12 14:04:44 - training - INFO - Epoch [1/5][391/438] lr: 3.7e-06, eta: 0:26:48.948243, loss: 2.7529
2023-04-12 14:04:52 - training - INFO - Epoch [1/5][401/438] lr: 3.7e-06, eta: 0:26:36.172635, loss: 2.1260
2023-04-12 14:05:00 - training - INFO - Epoch [1/5][411/438] lr: 3.7e-06, eta: 0:26:21.427818, loss: 1.5818
2023-04-12 14:05:07 - training - INFO - Epoch [1/5][421/438] lr: 3.7e-06, eta: 0:26:06.994352, loss: 2.2276
2023-04-12 14:05:15 - training - INFO - Epoch [1/5][431/438] lr: 3.6e-06, eta: 0:25:53.219867, loss: 1.7187
2023-04-12 14:06:09 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 3.2972, Validation Metrics: {'exact_match': 48.10126582278481, 'f1': 56.53875410678765}, Test Metrics: {'exact_match': 49.369369369369366, 'f1': 59.32961910040577}
2023-04-12 14:06:09 - training - INFO - Epoch [2/5][1/438] lr: 3.6e-06, eta: 11 days, 0:38:12.742683, loss: 1.6299
2023-04-12 14:06:17 - training - INFO - Epoch [2/5][11/438] lr: 3.6e-06, eta: 1 day, 0:22:08.466236, loss: 2.2916
2023-04-12 14:06:25 - training - INFO - Epoch [2/5][21/438] lr: 3.6e-06, eta: 12:55:14.389365, loss: 1.6283
2023-04-12 14:06:32 - training - INFO - Epoch [2/5][31/438] lr: 3.6e-06, eta: 8:51:24.254494, loss: 1.4866
2023-04-12 14:06:40 - training - INFO - Epoch [2/5][41/438] lr: 3.5e-06, eta: 6:46:31.652866, loss: 2.0241
2023-04-12 14:06:47 - training - INFO - Epoch [2/5][51/438] lr: 3.5e-06, eta: 5:30:43.539363, loss: 2.1729
2023-04-12 14:06:56 - training - INFO - Epoch [2/5][61/438] lr: 3.5e-06, eta: 4:40:02.877020, loss: 1.9214
2023-04-12 14:07:03 - training - INFO - Epoch [2/5][71/438] lr: 3.5e-06, eta: 4:03:13.271173, loss: 1.8106
2023-04-12 14:07:11 - training - INFO - Epoch [2/5][81/438] lr: 3.5e-06, eta: 3:35:33.096624, loss: 1.7079
2023-04-12 14:07:19 - training - INFO - Epoch [2/5][91/438] lr: 3.4e-06, eta: 3:14:01.933481, loss: 2.1102
2023-04-12 14:07:27 - training - INFO - Epoch [2/5][101/438] lr: 3.4e-06, eta: 2:56:39.677916, loss: 1.7502
2023-04-12 14:07:34 - training - INFO - Epoch [2/5][111/438] lr: 3.4e-06, eta: 2:42:20.067183, loss: 1.9353
2023-04-12 14:07:42 - training - INFO - Epoch [2/5][121/438] lr: 3.4e-06, eta: 2:30:21.785533, loss: 1.9905
2023-04-12 14:07:49 - training - INFO - Epoch [2/5][131/438] lr: 3.4e-06, eta: 2:20:12.365704, loss: 1.0941
2023-04-12 14:07:57 - training - INFO - Epoch [2/5][141/438] lr: 3.3e-06, eta: 2:11:27.293562, loss: 2.6061
2023-04-12 14:08:05 - training - INFO - Epoch [2/5][151/438] lr: 3.3e-06, eta: 2:03:52.540371, loss: 1.7632
2023-04-12 14:08:12 - training - INFO - Epoch [2/5][161/438] lr: 3.3e-06, eta: 1:57:13.826763, loss: 2.2165
2023-04-12 14:08:20 - training - INFO - Epoch [2/5][171/438] lr: 3.3e-06, eta: 1:51:24.113514, loss: 1.4387
2023-04-12 14:08:28 - training - INFO - Epoch [2/5][181/438] lr: 3.3e-06, eta: 1:46:08.515937, loss: 2.5791
2023-04-12 14:08:36 - training - INFO - Epoch [2/5][191/438] lr: 3.2e-06, eta: 1:41:26.827064, loss: 1.5906
2023-04-12 14:08:44 - training - INFO - Epoch [2/5][201/438] lr: 3.2e-06, eta: 1:37:12.732555, loss: 1.5424
2023-04-12 14:08:51 - training - INFO - Epoch [2/5][211/438] lr: 3.2e-06, eta: 1:33:20.007964, loss: 2.1601
2023-04-12 14:08:59 - training - INFO - Epoch [2/5][221/438] lr: 3.2e-06, eta: 1:29:49.558614, loss: 1.8877
2023-04-12 14:09:07 - training - INFO - Epoch [2/5][231/438] lr: 3.2e-06, eta: 1:26:34.552965, loss: 1.4895
2023-04-12 14:09:15 - training - INFO - Epoch [2/5][241/438] lr: 3.1e-06, eta: 1:23:36.708459, loss: 1.7822
2023-04-12 14:09:22 - training - INFO - Epoch [2/5][251/438] lr: 3.1e-06, eta: 1:20:50.325123, loss: 2.4118
2023-04-12 14:09:30 - training - INFO - Epoch [2/5][261/438] lr: 3.1e-06, eta: 1:18:18.015843, loss: 1.6129
2023-04-12 14:09:38 - training - INFO - Epoch [2/5][271/438] lr: 3.1e-06, eta: 1:15:59.133334, loss: 1.4577
2023-04-12 14:09:46 - training - INFO - Epoch [2/5][281/438] lr: 3.0e-06, eta: 1:13:49.941404, loss: 2.0885
2023-04-12 14:09:54 - training - INFO - Epoch [2/5][291/438] lr: 3.0e-06, eta: 1:11:47.868207, loss: 1.9934
2023-04-12 14:10:02 - training - INFO - Epoch [2/5][301/438] lr: 3.0e-06, eta: 1:09:51.124300, loss: 1.7685
2023-04-12 14:10:10 - training - INFO - Epoch [2/5][311/438] lr: 3.0e-06, eta: 1:08:01.065865, loss: 1.9016
2023-04-12 14:10:18 - training - INFO - Epoch [2/5][321/438] lr: 3.0e-06, eta: 1:06:18.719724, loss: 2.2807
2023-04-12 14:10:26 - training - INFO - Epoch [2/5][331/438] lr: 2.9e-06, eta: 1:04:42.703682, loss: 2.5201
2023-04-12 14:10:33 - training - INFO - Epoch [2/5][341/438] lr: 2.9e-06, eta: 1:03:09.695608, loss: 1.7036
2023-04-12 14:10:41 - training - INFO - Epoch [2/5][351/438] lr: 2.9e-06, eta: 1:01:41.710227, loss: 1.7863
2023-04-12 14:10:48 - training - INFO - Epoch [2/5][361/438] lr: 2.9e-06, eta: 1:00:17.676037, loss: 1.7732
2023-04-12 14:10:56 - training - INFO - Epoch [2/5][371/438] lr: 2.9e-06, eta: 0:58:57.838584, loss: 2.4297
2023-04-12 14:11:04 - training - INFO - Epoch [2/5][381/438] lr: 2.8e-06, eta: 0:57:43.066386, loss: 1.2723
2023-04-12 14:11:11 - training - INFO - Epoch [2/5][391/438] lr: 2.8e-06, eta: 0:56:30.828959, loss: 1.7746
2023-04-12 14:11:19 - training - INFO - Epoch [2/5][401/438] lr: 2.8e-06, eta: 0:55:21.176527, loss: 1.4206
2023-04-12 14:11:26 - training - INFO - Epoch [2/5][411/438] lr: 2.8e-06, eta: 0:54:15.093228, loss: 1.6315
2023-04-12 14:11:34 - training - INFO - Epoch [2/5][421/438] lr: 2.8e-06, eta: 0:53:11.875691, loss: 1.9274
2023-04-12 14:11:42 - training - INFO - Epoch [2/5][431/438] lr: 2.7e-06, eta: 0:52:11.797478, loss: 2.2123
2023-04-12 14:12:35 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.8920, Validation Metrics: {'exact_match': 46.292947558770344, 'f1': 53.27398005183453}, Test Metrics: {'exact_match': 49.549549549549546, 'f1': 56.92482397323641}
2023-04-12 14:12:36 - training - INFO - Epoch [3/5][1/438] lr: 2.7e-06, eta: 20 days, 19:50:49.712533, loss: 1.2399
2023-04-12 14:12:44 - training - INFO - Epoch [3/5][11/438] lr: 2.7e-06, eta: 1 day, 21:40:29.728184, loss: 1.4871
2023-04-12 14:12:52 - training - INFO - Epoch [3/5][21/438] lr: 2.7e-06, eta: 1 day, 0:02:25.531449, loss: 1.8352
2023-04-12 14:13:00 - training - INFO - Epoch [3/5][31/438] lr: 2.7e-06, eta: 16:21:33.474034, loss: 1.5464
2023-04-12 14:13:08 - training - INFO - Epoch [3/5][41/438] lr: 2.6e-06, eta: 12:25:48.100495, loss: 0.9370
2023-04-12 14:13:16 - training - INFO - Epoch [3/5][51/438] lr: 2.6e-06, eta: 10:02:17.510898, loss: 1.7470
2023-04-12 14:13:23 - training - INFO - Epoch [3/5][61/438] lr: 2.6e-06, eta: 8:25:34.226190, loss: 1.7669
2023-04-12 14:13:31 - training - INFO - Epoch [3/5][71/438] lr: 2.6e-06, eta: 7:16:04.206289, loss: 1.8370
2023-04-12 14:13:39 - training - INFO - Epoch [3/5][81/438] lr: 2.6e-06, eta: 6:23:45.098187, loss: 1.0506
2023-04-12 14:13:46 - training - INFO - Epoch [3/5][91/438] lr: 2.5e-06, eta: 5:42:55.747657, loss: 1.9348
2023-04-12 14:13:54 - training - INFO - Epoch [3/5][101/438] lr: 2.5e-06, eta: 5:10:07.030083, loss: 1.9479
2023-04-12 14:14:02 - training - INFO - Epoch [3/5][111/438] lr: 2.5e-06, eta: 4:43:21.563040, loss: 1.7981
2023-04-12 14:14:10 - training - INFO - Epoch [3/5][121/438] lr: 2.5e-06, eta: 4:20:59.758233, loss: 1.8516
2023-04-12 14:14:18 - training - INFO - Epoch [3/5][131/438] lr: 2.5e-06, eta: 4:01:52.593830, loss: 1.9740
2023-04-12 14:14:25 - training - INFO - Epoch [3/5][141/438] lr: 2.4e-06, eta: 3:45:27.991809, loss: 1.1661
2023-04-12 14:14:33 - training - INFO - Epoch [3/5][151/438] lr: 2.4e-06, eta: 3:31:12.401312, loss: 1.3695
2023-04-12 14:14:40 - training - INFO - Epoch [3/5][161/438] lr: 2.4e-06, eta: 3:18:42.229506, loss: 1.4185
2023-04-12 14:14:48 - training - INFO - Epoch [3/5][171/438] lr: 2.4e-06, eta: 3:07:38.592099, loss: 1.4505
2023-04-12 14:14:55 - training - INFO - Epoch [3/5][181/438] lr: 2.3e-06, eta: 2:57:47.261633, loss: 1.4956
2023-04-12 14:15:03 - training - INFO - Epoch [3/5][191/438] lr: 2.3e-06, eta: 2:48:57.586671, loss: 1.8574
2023-04-12 14:15:10 - training - INFO - Epoch [3/5][201/438] lr: 2.3e-06, eta: 2:40:59.701818, loss: 1.8116
2023-04-12 14:15:18 - training - INFO - Epoch [3/5][211/438] lr: 2.3e-06, eta: 2:33:46.891579, loss: 1.7089
2023-04-12 14:15:26 - training - INFO - Epoch [3/5][221/438] lr: 2.3e-06, eta: 2:27:12.555952, loss: 1.9297
2023-04-12 14:15:33 - training - INFO - Epoch [3/5][231/438] lr: 2.2e-06, eta: 2:21:13.113816, loss: 1.5489
2023-04-12 14:15:41 - training - INFO - Epoch [3/5][241/438] lr: 2.2e-06, eta: 2:15:42.380178, loss: 1.3386
2023-04-12 14:15:49 - training - INFO - Epoch [3/5][251/438] lr: 2.2e-06, eta: 2:10:37.655168, loss: 2.1557
2023-04-12 14:15:56 - training - INFO - Epoch [3/5][261/438] lr: 2.2e-06, eta: 2:05:54.372948, loss: 1.4158
2023-04-12 14:16:04 - training - INFO - Epoch [3/5][271/438] lr: 2.2e-06, eta: 2:01:30.822158, loss: 1.0736
2023-04-12 14:16:11 - training - INFO - Epoch [3/5][281/438] lr: 2.1e-06, eta: 1:57:26.138090, loss: 1.3671
2023-04-12 14:16:19 - training - INFO - Epoch [3/5][291/438] lr: 2.1e-06, eta: 1:53:37.472667, loss: 1.7771
2023-04-12 14:16:27 - training - INFO - Epoch [3/5][301/438] lr: 2.1e-06, eta: 1:50:04.121566, loss: 2.1197
2023-04-12 14:16:34 - training - INFO - Epoch [3/5][311/438] lr: 2.1e-06, eta: 1:46:43.072058, loss: 1.8954
2023-04-12 14:16:42 - training - INFO - Epoch [3/5][321/438] lr: 2.1e-06, eta: 1:43:36.185598, loss: 2.5412
2023-04-12 14:16:50 - training - INFO - Epoch [3/5][331/438] lr: 2.0e-06, eta: 1:40:39.422532, loss: 1.0643
2023-04-12 14:16:57 - training - INFO - Epoch [3/5][341/438] lr: 2.0e-06, eta: 1:37:52.673615, loss: 1.7219
2023-04-12 14:17:05 - training - INFO - Epoch [3/5][351/438] lr: 2.0e-06, eta: 1:35:14.330217, loss: 1.1474
2023-04-12 14:17:13 - training - INFO - Epoch [3/5][361/438] lr: 2.0e-06, eta: 1:32:44.886136, loss: 1.2781
2023-04-12 14:17:20 - training - INFO - Epoch [3/5][371/438] lr: 2.0e-06, eta: 1:30:22.042458, loss: 2.0525
2023-04-12 14:17:28 - training - INFO - Epoch [3/5][381/438] lr: 1.9e-06, eta: 1:28:06.525723, loss: 1.8116
2023-04-12 14:17:35 - training - INFO - Epoch [3/5][391/438] lr: 1.9e-06, eta: 1:25:57.414577, loss: 0.9739
2023-04-12 14:17:43 - training - INFO - Epoch [3/5][401/438] lr: 1.9e-06, eta: 1:23:55.405272, loss: 1.6530
2023-04-12 14:17:50 - training - INFO - Epoch [3/5][411/438] lr: 1.9e-06, eta: 1:21:58.168251, loss: 1.3743
2023-04-12 14:17:58 - training - INFO - Epoch [3/5][421/438] lr: 1.9e-06, eta: 1:20:06.240325, loss: 1.1697
2023-04-12 14:18:06 - training - INFO - Epoch [3/5][431/438] lr: 1.8e-06, eta: 1:18:18.943348, loss: 1.0520
2023-04-12 14:18:59 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.5880, Validation Metrics: {'exact_match': 47.377938517179025, 'f1': 54.849057475063375}, Test Metrics: {'exact_match': 52.792792792792795, 'f1': 59.60586861557474}
2023-04-12 14:18:59 - training - INFO - Epoch [4/5][1/438] lr: 1.8e-06, eta: 30 days, 12:48:59.519092, loss: 1.2065
2023-04-12 14:19:07 - training - INFO - Epoch [4/5][11/438] lr: 1.8e-06, eta: 2 days, 18:44:10.397399, loss: 1.3975
2023-04-12 14:19:15 - training - INFO - Epoch [4/5][21/438] lr: 1.8e-06, eta: 1 day, 11:00:42.121314, loss: 1.4622
2023-04-12 14:19:22 - training - INFO - Epoch [4/5][31/438] lr: 1.8e-06, eta: 23:45:13.419397, loss: 1.5795
2023-04-12 14:19:30 - training - INFO - Epoch [4/5][41/438] lr: 1.7e-06, eta: 17:59:25.031912, loss: 1.0860
2023-04-12 14:19:37 - training - INFO - Epoch [4/5][51/438] lr: 1.7e-06, eta: 14:29:02.471448, loss: 1.5268
2023-04-12 14:19:45 - training - INFO - Epoch [4/5][61/438] lr: 1.7e-06, eta: 12:07:40.872010, loss: 1.3394
2023-04-12 14:19:53 - training - INFO - Epoch [4/5][71/438] lr: 1.7e-06, eta: 10:26:02.142007, loss: 1.0561
2023-04-12 14:20:00 - training - INFO - Epoch [4/5][81/438] lr: 1.6e-06, eta: 9:09:24.114999, loss: 0.8908
2023-04-12 14:20:08 - training - INFO - Epoch [4/5][91/438] lr: 1.6e-06, eta: 8:09:38.412115, loss: 1.6215
2023-04-12 14:20:15 - training - INFO - Epoch [4/5][101/438] lr: 1.6e-06, eta: 7:21:39.838202, loss: 1.4319
2023-04-12 14:20:23 - training - INFO - Epoch [4/5][111/438] lr: 1.6e-06, eta: 6:42:18.861516, loss: 1.1098
2023-04-12 14:20:31 - training - INFO - Epoch [4/5][121/438] lr: 1.6e-06, eta: 6:09:29.246033, loss: 0.9718
2023-04-12 14:20:38 - training - INFO - Epoch [4/5][131/438] lr: 1.5e-06, eta: 5:41:37.474717, loss: 1.0847
2023-04-12 14:20:46 - training - INFO - Epoch [4/5][141/438] lr: 1.5e-06, eta: 5:17:40.283613, loss: 1.9272
2023-04-12 14:20:53 - training - INFO - Epoch [4/5][151/438] lr: 1.5e-06, eta: 4:56:53.542029, loss: 0.9880
2023-04-12 14:21:01 - training - INFO - Epoch [4/5][161/438] lr: 1.5e-06, eta: 4:38:41.285234, loss: 1.5691
2023-04-12 14:21:09 - training - INFO - Epoch [4/5][171/438] lr: 1.5e-06, eta: 4:22:35.579445, loss: 1.6173
2023-04-12 14:21:16 - training - INFO - Epoch [4/5][181/438] lr: 1.4e-06, eta: 4:08:16.278957, loss: 1.2826
2023-04-12 14:21:24 - training - INFO - Epoch [4/5][191/438] lr: 1.4e-06, eta: 3:55:25.067933, loss: 1.8153
2023-04-12 14:21:31 - training - INFO - Epoch [4/5][201/438] lr: 1.4e-06, eta: 3:43:49.863252, loss: 1.6331
2023-04-12 14:21:39 - training - INFO - Epoch [4/5][211/438] lr: 1.4e-06, eta: 3:33:19.936499, loss: 2.1216
2023-04-12 14:21:47 - training - INFO - Epoch [4/5][221/438] lr: 1.4e-06, eta: 3:23:47.564822, loss: 1.0982
2023-04-12 14:21:54 - training - INFO - Epoch [4/5][231/438] lr: 1.3e-06, eta: 3:15:02.640897, loss: 1.0685
2023-04-12 14:22:02 - training - INFO - Epoch [4/5][241/438] lr: 1.3e-06, eta: 3:07:01.934659, loss: 1.4734
2023-04-12 14:22:10 - training - INFO - Epoch [4/5][251/438] lr: 1.3e-06, eta: 2:59:39.021218, loss: 1.2258
2023-04-12 14:22:17 - training - INFO - Epoch [4/5][261/438] lr: 1.3e-06, eta: 2:52:48.311343, loss: 0.9188
2023-04-12 14:22:25 - training - INFO - Epoch [4/5][271/438] lr: 1.3e-06, eta: 2:46:27.846166, loss: 1.6703
2023-04-12 14:22:32 - training - INFO - Epoch [4/5][281/438] lr: 1.2e-06, eta: 2:40:33.820043, loss: 1.2673
2023-04-12 14:22:40 - training - INFO - Epoch [4/5][291/438] lr: 1.2e-06, eta: 2:35:03.218091, loss: 0.9265
2023-04-12 14:22:47 - training - INFO - Epoch [4/5][301/438] lr: 1.2e-06, eta: 2:29:53.576225, loss: 1.9296
2023-04-12 14:22:55 - training - INFO - Epoch [4/5][311/438] lr: 1.2e-06, eta: 2:25:03.789181, loss: 1.4880
2023-04-12 14:23:02 - training - INFO - Epoch [4/5][321/438] lr: 1.2e-06, eta: 2:20:31.896312, loss: 1.7295
2023-04-12 14:23:10 - training - INFO - Epoch [4/5][331/438] lr: 1.1e-06, eta: 2:16:16.229633, loss: 1.6420
2023-04-12 14:23:18 - training - INFO - Epoch [4/5][341/438] lr: 1.1e-06, eta: 2:12:15.584425, loss: 1.9606
2023-04-12 14:23:25 - training - INFO - Epoch [4/5][351/438] lr: 1.1e-06, eta: 2:08:28.197924, loss: 1.5381
2023-04-12 14:23:33 - training - INFO - Epoch [4/5][361/438] lr: 1.1e-06, eta: 2:04:52.482039, loss: 1.3443
2023-04-12 14:23:41 - training - INFO - Epoch [4/5][371/438] lr: 1.0e-06, eta: 2:01:28.840321, loss: 1.2836
2023-04-12 14:23:49 - training - INFO - Epoch [4/5][381/438] lr: 1.0e-06, eta: 1:58:16.296357, loss: 1.3460
2023-04-12 14:23:56 - training - INFO - Epoch [4/5][391/438] lr: 1.0e-06, eta: 1:55:11.561909, loss: 1.3524
2023-04-12 14:24:04 - training - INFO - Epoch [4/5][401/438] lr: 9.8e-07, eta: 1:52:15.379265, loss: 1.4501
2023-04-12 14:24:12 - training - INFO - Epoch [4/5][411/438] lr: 9.6e-07, eta: 1:49:27.662388, loss: 1.2084
2023-04-12 14:24:19 - training - INFO - Epoch [4/5][421/438] lr: 9.4e-07, eta: 1:46:47.312693, loss: 1.3769
2023-04-12 14:24:27 - training - INFO - Epoch [4/5][431/438] lr: 9.2e-07, eta: 1:44:14.105151, loss: 1.0536
2023-04-12 14:25:20 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 1.4447, Validation Metrics: {'exact_match': 51.89873417721519, 'f1': 58.41967936094839}, Test Metrics: {'exact_match': 55.85585585585586, 'f1': 62.37510479959892}
2023-04-12 14:25:20 - training - INFO - Epoch [5/5][1/438] lr: 9.1e-07, eta: 40 days, 4:32:10.352755, loss: 1.6348
2023-04-12 14:25:28 - training - INFO - Epoch [5/5][11/438] lr: 8.9e-07, eta: 3 days, 15:42:11.160046, loss: 1.0533
2023-04-12 14:25:36 - training - INFO - Epoch [5/5][21/438] lr: 8.6e-07, eta: 1 day, 21:56:50.709813, loss: 1.3574
2023-04-12 14:25:43 - training - INFO - Epoch [5/5][31/438] lr: 8.4e-07, eta: 1 day, 7:07:40.571916, loss: 1.3243
2023-04-12 14:25:51 - training - INFO - Epoch [5/5][41/438] lr: 8.2e-07, eta: 23:32:17.148083, loss: 1.1169
2023-04-12 14:25:58 - training - INFO - Epoch [5/5][51/438] lr: 8.0e-07, eta: 18:55:21.607851, loss: 1.1016
2023-04-12 14:26:06 - training - INFO - Epoch [5/5][61/438] lr: 7.8e-07, eta: 15:49:22.197633, loss: 1.0718
2023-04-12 14:26:14 - training - INFO - Epoch [5/5][71/438] lr: 7.6e-07, eta: 13:35:35.372304, loss: 2.0229
2023-04-12 14:26:21 - training - INFO - Epoch [5/5][81/438] lr: 7.4e-07, eta: 11:54:49.100634, loss: 1.1272
2023-04-12 14:26:29 - training - INFO - Epoch [5/5][91/438] lr: 7.2e-07, eta: 10:36:07.745824, loss: 1.9020
2023-04-12 14:26:37 - training - INFO - Epoch [5/5][101/438] lr: 7.0e-07, eta: 9:33:05.146811, loss: 1.3228
2023-04-12 14:26:44 - training - INFO - Epoch [5/5][111/438] lr: 6.8e-07, eta: 8:41:18.646476, loss: 1.1730
2023-04-12 14:26:52 - training - INFO - Epoch [5/5][121/438] lr: 6.6e-07, eta: 7:58:04.104957, loss: 1.4442
2023-04-12 14:26:59 - training - INFO - Epoch [5/5][131/438] lr: 6.4e-07, eta: 7:21:26.603321, loss: 1.1081
2023-04-12 14:27:07 - training - INFO - Epoch [5/5][141/438] lr: 6.2e-07, eta: 6:49:58.568742, loss: 1.1966
2023-04-12 14:27:15 - training - INFO - Epoch [5/5][151/438] lr: 5.9e-07, eta: 6:22:40.104447, loss: 1.2515
2023-04-12 14:27:22 - training - INFO - Epoch [5/5][161/438] lr: 5.7e-07, eta: 5:58:44.192004, loss: 1.6274
2023-04-12 14:27:30 - training - INFO - Epoch [5/5][171/438] lr: 5.5e-07, eta: 5:37:35.241966, loss: 0.9076
2023-04-12 14:27:38 - training - INFO - Epoch [5/5][181/438] lr: 5.3e-07, eta: 5:18:48.492600, loss: 1.0917
2023-04-12 14:27:45 - training - INFO - Epoch [5/5][191/438] lr: 5.1e-07, eta: 5:01:56.229354, loss: 1.4133
2023-04-12 14:27:53 - training - INFO - Epoch [5/5][201/438] lr: 4.9e-07, eta: 4:46:43.513392, loss: 1.3748
2023-04-12 14:28:00 - training - INFO - Epoch [5/5][211/438] lr: 4.7e-07, eta: 4:32:56.565388, loss: 1.1245
2023-04-12 14:28:08 - training - INFO - Epoch [5/5][221/438] lr: 4.5e-07, eta: 4:20:23.920488, loss: 1.8891
2023-04-12 14:28:15 - training - INFO - Epoch [5/5][231/438] lr: 4.3e-07, eta: 4:08:56.087937, loss: 1.1652
2023-04-12 14:28:23 - training - INFO - Epoch [5/5][241/438] lr: 4.1e-07, eta: 3:58:24.747868, loss: 1.6821
2023-04-12 14:28:31 - training - INFO - Epoch [5/5][251/438] lr: 3.9e-07, eta: 3:48:42.851737, loss: 1.5576
2023-04-12 14:28:39 - training - INFO - Epoch [5/5][261/438] lr: 3.7e-07, eta: 3:39:49.475772, loss: 1.1039
2023-04-12 14:28:47 - training - INFO - Epoch [5/5][271/438] lr: 3.5e-07, eta: 3:31:31.454263, loss: 1.2179
2023-04-12 14:28:54 - training - INFO - Epoch [5/5][281/438] lr: 3.3e-07, eta: 3:23:47.973506, loss: 1.2018
2023-04-12 14:29:02 - training - INFO - Epoch [5/5][291/438] lr: 3.0e-07, eta: 3:16:35.135265, loss: 0.7427
2023-04-12 14:29:09 - training - INFO - Epoch [5/5][301/438] lr: 2.8e-07, eta: 3:09:51.189475, loss: 1.6740
2023-04-12 14:29:17 - training - INFO - Epoch [5/5][311/438] lr: 2.6e-07, eta: 3:03:32.471385, loss: 1.9859
2023-04-12 14:29:25 - training - INFO - Epoch [5/5][321/438] lr: 2.4e-07, eta: 2:57:36.944550, loss: 0.9329
2023-04-12 14:29:32 - training - INFO - Epoch [5/5][331/438] lr: 2.2e-07, eta: 2:52:02.922896, loss: 1.2845
2023-04-12 14:29:40 - training - INFO - Epoch [5/5][341/438] lr: 2.0e-07, eta: 2:46:48.080451, loss: 1.3468
2023-04-12 14:29:48 - training - INFO - Epoch [5/5][351/438] lr: 1.8e-07, eta: 2:41:51.152130, loss: 1.5252
2023-04-12 14:29:55 - training - INFO - Epoch [5/5][361/438] lr: 1.6e-07, eta: 2:37:09.874066, loss: 2.5561
2023-04-12 14:30:03 - training - INFO - Epoch [5/5][371/438] lr: 1.4e-07, eta: 2:32:43.996489, loss: 1.1930
2023-04-12 14:30:11 - training - INFO - Epoch [5/5][381/438] lr: 1.2e-07, eta: 2:28:30.180657, loss: 0.9999
2023-04-12 14:30:18 - training - INFO - Epoch [5/5][391/438] lr: 9.7e-08, eta: 2:24:29.451161, loss: 1.2182
2023-04-12 14:30:26 - training - INFO - Epoch [5/5][401/438] lr: 7.7e-08, eta: 2:20:40.516312, loss: 1.4775
2023-04-12 14:30:34 - training - INFO - Epoch [5/5][411/438] lr: 5.6e-08, eta: 2:17:03.304749, loss: 1.4574
2023-04-12 14:30:42 - training - INFO - Epoch [5/5][421/438] lr: 3.5e-08, eta: 2:13:35.022349, loss: 1.0444
2023-04-12 14:30:49 - training - INFO - Epoch [5/5][431/438] lr: 1.5e-08, eta: 2:10:15.657401, loss: 1.9336
2023-04-12 14:31:43 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 1.3814, Validation Metrics: {'exact_match': 49.18625678119349, 'f1': 55.47405265616176}, Test Metrics: {'exact_match': 54.234234234234236, 'f1': 60.328054189680344}
2023-04-12 14:32:07 - training - INFO - Final Test - Train Loss: 1.3814, Test Metrics: {'exact_match': 54.234234234234236, 'f1': 60.328054189680344}
