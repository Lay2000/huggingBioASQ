2023-04-12 14:32:28 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'srikanthkb/xlnet-base-cased-finetuned-squad'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 1e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_factoid_squad'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 579.03it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1247.08 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1453.98 examples/s]Map:  68%|██████▊   | 3000/4429 [00:02<00:00, 1501.61 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1530.87 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1531.59 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1246.61 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1225.54 examples/s]                                                               2023-04-12 14:33:28 - training - INFO - First Test - Val Metrics:{'exact_match': 10.126582278481013, 'f1': 18.748142397257652} Test Metrics: {'exact_match': 12.072072072072071, 'f1': 19.175582248527128}
2023-04-12 14:33:29 - training - INFO - Epoch [1/5][1/438] lr: 1.0e-05, eta: 1 day, 6:03:45.670410, loss: 9.3821
2023-04-12 14:33:36 - training - INFO - Epoch [1/5][11/438] lr: 9.9e-06, eta: 3:08:57.530931, loss: 5.2994
2023-04-12 14:33:44 - training - INFO - Epoch [1/5][21/438] lr: 9.9e-06, eta: 1:51:35.531649, loss: 4.5173
2023-04-12 14:33:52 - training - INFO - Epoch [1/5][31/438] lr: 9.9e-06, eta: 1:24:18.329736, loss: 4.1602
2023-04-12 14:33:59 - training - INFO - Epoch [1/5][41/438] lr: 9.8e-06, eta: 1:09:59.883107, loss: 4.0101
2023-04-12 14:34:07 - training - INFO - Epoch [1/5][51/438] lr: 9.8e-06, eta: 1:01:19.574109, loss: 4.9682
2023-04-12 14:34:15 - training - INFO - Epoch [1/5][61/438] lr: 9.7e-06, eta: 0:55:34.067225, loss: 3.0964
2023-04-12 14:34:22 - training - INFO - Epoch [1/5][71/438] lr: 9.7e-06, eta: 0:51:18.281895, loss: 2.8606
2023-04-12 14:34:30 - training - INFO - Epoch [1/5][81/438] lr: 9.6e-06, eta: 0:48:04.167168, loss: 3.8467
2023-04-12 14:34:38 - training - INFO - Epoch [1/5][91/438] lr: 9.6e-06, eta: 0:45:29.566887, loss: 2.8495
2023-04-12 14:34:45 - training - INFO - Epoch [1/5][101/438] lr: 9.5e-06, eta: 0:43:23.944767, loss: 2.9991
2023-04-12 14:34:53 - training - INFO - Epoch [1/5][111/438] lr: 9.5e-06, eta: 0:41:38.037003, loss: 2.1821
2023-04-12 14:35:00 - training - INFO - Epoch [1/5][121/438] lr: 9.4e-06, eta: 0:40:09.238774, loss: 2.5128
2023-04-12 14:35:08 - training - INFO - Epoch [1/5][131/438] lr: 9.4e-06, eta: 0:38:56.483194, loss: 2.6910
2023-04-12 14:35:16 - training - INFO - Epoch [1/5][141/438] lr: 9.4e-06, eta: 0:37:54.656370, loss: 3.1553
2023-04-12 14:35:23 - training - INFO - Epoch [1/5][151/438] lr: 9.3e-06, eta: 0:36:58.113916, loss: 1.8452
2023-04-12 14:35:31 - training - INFO - Epoch [1/5][161/438] lr: 9.3e-06, eta: 0:36:09.329698, loss: 2.8250
2023-04-12 14:35:40 - training - INFO - Epoch [1/5][171/438] lr: 9.2e-06, eta: 0:35:29.083956, loss: 1.9086
2023-04-12 14:35:47 - training - INFO - Epoch [1/5][181/438] lr: 9.2e-06, eta: 0:34:46.999425, loss: 2.3100
2023-04-12 14:35:55 - training - INFO - Epoch [1/5][191/438] lr: 9.1e-06, eta: 0:34:10.676149, loss: 2.1533
2023-04-12 14:36:03 - training - INFO - Epoch [1/5][201/438] lr: 9.1e-06, eta: 0:33:34.554672, loss: 1.6957
2023-04-12 14:36:10 - training - INFO - Epoch [1/5][211/438] lr: 9.0e-06, eta: 0:33:00.064702, loss: 1.5534
2023-04-12 14:36:18 - training - INFO - Epoch [1/5][221/438] lr: 9.0e-06, eta: 0:32:28.857130, loss: 2.1278
2023-04-12 14:36:26 - training - INFO - Epoch [1/5][231/438] lr: 8.9e-06, eta: 0:32:03.185562, loss: 1.9637
2023-04-12 14:36:34 - training - INFO - Epoch [1/5][241/438] lr: 8.9e-06, eta: 0:31:35.928730, loss: 1.9992
2023-04-12 14:36:42 - training - INFO - Epoch [1/5][251/438] lr: 8.9e-06, eta: 0:31:12.048269, loss: 2.4081
2023-04-12 14:36:49 - training - INFO - Epoch [1/5][261/438] lr: 8.8e-06, eta: 0:30:46.814955, loss: 1.8549
2023-04-12 14:36:57 - training - INFO - Epoch [1/5][271/438] lr: 8.8e-06, eta: 0:30:23.627619, loss: 2.0739
2023-04-12 14:37:04 - training - INFO - Epoch [1/5][281/438] lr: 8.7e-06, eta: 0:30:01.817286, loss: 1.4403
2023-04-12 14:37:12 - training - INFO - Epoch [1/5][291/438] lr: 8.7e-06, eta: 0:29:40.077024, loss: 1.9878
2023-04-12 14:37:20 - training - INFO - Epoch [1/5][301/438] lr: 8.6e-06, eta: 0:29:19.186031, loss: 1.9245
2023-04-12 14:37:27 - training - INFO - Epoch [1/5][311/438] lr: 8.6e-06, eta: 0:28:59.630812, loss: 2.0703
2023-04-12 14:37:35 - training - INFO - Epoch [1/5][321/438] lr: 8.5e-06, eta: 0:28:40.640649, loss: 1.7931
2023-04-12 14:37:43 - training - INFO - Epoch [1/5][331/438] lr: 8.5e-06, eta: 0:28:23.353366, loss: 1.7696
2023-04-12 14:37:50 - training - INFO - Epoch [1/5][341/438] lr: 8.4e-06, eta: 0:28:05.577984, loss: 2.4376
2023-04-12 14:37:58 - training - INFO - Epoch [1/5][351/438] lr: 8.4e-06, eta: 0:27:48.546768, loss: 2.1755
2023-04-12 14:38:05 - training - INFO - Epoch [1/5][361/438] lr: 8.4e-06, eta: 0:27:31.711372, loss: 2.1821
2023-04-12 14:38:13 - training - INFO - Epoch [1/5][371/438] lr: 8.3e-06, eta: 0:27:15.295552, loss: 1.1171
2023-04-12 14:38:20 - training - INFO - Epoch [1/5][381/438] lr: 8.3e-06, eta: 0:26:59.074899, loss: 2.1362
2023-04-12 14:38:28 - training - INFO - Epoch [1/5][391/438] lr: 8.2e-06, eta: 0:26:44.063958, loss: 1.5972
2023-04-12 14:38:35 - training - INFO - Epoch [1/5][401/438] lr: 8.2e-06, eta: 0:26:29.318976, loss: 1.4592
2023-04-12 14:38:44 - training - INFO - Epoch [1/5][411/438] lr: 8.1e-06, eta: 0:26:18.353706, loss: 0.8485
2023-04-12 14:38:52 - training - INFO - Epoch [1/5][421/438] lr: 8.1e-06, eta: 0:26:05.697675, loss: 1.7249
2023-04-12 14:38:59 - training - INFO - Epoch [1/5][431/438] lr: 8.0e-06, eta: 0:25:51.541781, loss: 1.5087
2023-04-12 14:39:56 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 2.4756, Validation Metrics: {'exact_match': 44.48462929475588, 'f1': 50.862627725262506}, Test Metrics: {'exact_match': 47.207207207207205, 'f1': 54.09354868136421}
2023-04-12 14:39:57 - training - INFO - Epoch [2/5][1/438] lr: 8.0e-06, eta: 11 days, 2:06:11.439568, loss: 1.7992
2023-04-12 14:40:05 - training - INFO - Epoch [2/5][11/438] lr: 7.9e-06, eta: 1 day, 0:30:55.176295, loss: 1.8564
2023-04-12 14:40:13 - training - INFO - Epoch [2/5][21/438] lr: 7.9e-06, eta: 13:00:16.917147, loss: 1.8627
2023-04-12 14:40:20 - training - INFO - Epoch [2/5][31/438] lr: 7.9e-06, eta: 8:55:11.651169, loss: 0.9853
2023-04-12 14:40:28 - training - INFO - Epoch [2/5][41/438] lr: 7.8e-06, eta: 6:49:30.647374, loss: 1.5417
2023-04-12 14:40:36 - training - INFO - Epoch [2/5][51/438] lr: 7.8e-06, eta: 5:33:10.411659, loss: 1.6196
2023-04-12 14:40:44 - training - INFO - Epoch [2/5][61/438] lr: 7.7e-06, eta: 4:41:47.370469, loss: 1.5053
2023-04-12 14:40:52 - training - INFO - Epoch [2/5][71/438] lr: 7.7e-06, eta: 4:04:52.213640, loss: 1.2725
2023-04-12 14:41:00 - training - INFO - Epoch [2/5][81/438] lr: 7.6e-06, eta: 3:37:07.219185, loss: 1.4610
2023-04-12 14:41:07 - training - INFO - Epoch [2/5][91/438] lr: 7.6e-06, eta: 3:15:20.660674, loss: 1.4024
2023-04-12 14:41:15 - training - INFO - Epoch [2/5][101/438] lr: 7.5e-06, eta: 2:57:47.913012, loss: 1.1901
2023-04-12 14:41:22 - training - INFO - Epoch [2/5][111/438] lr: 7.5e-06, eta: 2:43:20.418474, loss: 1.5405
2023-04-12 14:41:30 - training - INFO - Epoch [2/5][121/438] lr: 7.4e-06, eta: 2:31:19.171317, loss: 1.6684
2023-04-12 14:41:38 - training - INFO - Epoch [2/5][131/438] lr: 7.4e-06, eta: 2:21:07.606615, loss: 1.0005
2023-04-12 14:41:46 - training - INFO - Epoch [2/5][141/438] lr: 7.4e-06, eta: 2:12:22.247742, loss: 1.6032
2023-04-12 14:41:53 - training - INFO - Epoch [2/5][151/438] lr: 7.3e-06, eta: 2:04:44.027160, loss: 1.4042
2023-04-12 14:42:02 - training - INFO - Epoch [2/5][161/438] lr: 7.3e-06, eta: 1:58:06.069455, loss: 1.7756
2023-04-12 14:42:09 - training - INFO - Epoch [2/5][171/438] lr: 7.2e-06, eta: 1:52:08.670825, loss: 1.1186
2023-04-12 14:42:17 - training - INFO - Epoch [2/5][181/438] lr: 7.2e-06, eta: 1:46:49.206223, loss: 1.8388
2023-04-12 14:42:24 - training - INFO - Epoch [2/5][191/438] lr: 7.1e-06, eta: 1:42:01.657640, loss: 0.7498
2023-04-12 14:42:32 - training - INFO - Epoch [2/5][201/438] lr: 7.1e-06, eta: 1:37:42.241359, loss: 1.3280
2023-04-12 14:42:39 - training - INFO - Epoch [2/5][211/438] lr: 7.0e-06, eta: 1:33:49.534644, loss: 1.8110
2023-04-12 14:42:47 - training - INFO - Epoch [2/5][221/438] lr: 7.0e-06, eta: 1:30:16.720969, loss: 1.4954
2023-04-12 14:42:55 - training - INFO - Epoch [2/5][231/438] lr: 6.9e-06, eta: 1:27:01.720377, loss: 1.0744
2023-04-12 14:43:02 - training - INFO - Epoch [2/5][241/438] lr: 6.9e-06, eta: 1:24:00.102306, loss: 1.5750
2023-04-12 14:43:10 - training - INFO - Epoch [2/5][251/438] lr: 6.9e-06, eta: 1:21:13.156848, loss: 1.9207
2023-04-12 14:43:18 - training - INFO - Epoch [2/5][261/438] lr: 6.8e-06, eta: 1:18:38.002212, loss: 1.0571
2023-04-12 14:43:25 - training - INFO - Epoch [2/5][271/438] lr: 6.8e-06, eta: 1:16:16.124160, loss: 0.7871
2023-04-12 14:43:33 - training - INFO - Epoch [2/5][281/438] lr: 6.7e-06, eta: 1:14:03.014236, loss: 1.6498
2023-04-12 14:43:41 - training - INFO - Epoch [2/5][291/438] lr: 6.7e-06, eta: 1:11:59.070408, loss: 1.3426
2023-04-12 14:43:49 - training - INFO - Epoch [2/5][301/438] lr: 6.6e-06, eta: 1:10:03.289460, loss: 0.6782
2023-04-12 14:43:57 - training - INFO - Epoch [2/5][311/438] lr: 6.6e-06, eta: 1:08:12.339865, loss: 1.8310
2023-04-12 14:44:05 - training - INFO - Epoch [2/5][321/438] lr: 6.5e-06, eta: 1:06:30.331821, loss: 1.6222
2023-04-12 14:44:12 - training - INFO - Epoch [2/5][331/438] lr: 6.5e-06, eta: 1:04:52.318430, loss: 1.5626
2023-04-12 14:44:20 - training - INFO - Epoch [2/5][341/438] lr: 6.4e-06, eta: 1:03:19.031209, loss: 1.3283
2023-04-12 14:44:28 - training - INFO - Epoch [2/5][351/438] lr: 6.4e-06, eta: 1:01:52.453665, loss: 1.6207
2023-04-12 14:44:36 - training - INFO - Epoch [2/5][361/438] lr: 6.4e-06, eta: 1:00:29.284700, loss: 1.3690
2023-04-12 14:44:43 - training - INFO - Epoch [2/5][371/438] lr: 6.3e-06, eta: 0:59:09.873088, loss: 2.1803
2023-04-12 14:44:51 - training - INFO - Epoch [2/5][381/438] lr: 6.3e-06, eta: 0:57:55.239147, loss: 0.7031
2023-04-12 14:44:59 - training - INFO - Epoch [2/5][391/438] lr: 6.2e-06, eta: 0:56:43.535296, loss: 1.7533
2023-04-12 14:45:07 - training - INFO - Epoch [2/5][401/438] lr: 6.2e-06, eta: 0:55:36.363348, loss: 1.1980
2023-04-12 14:45:15 - training - INFO - Epoch [2/5][411/438] lr: 6.1e-06, eta: 0:54:29.389272, loss: 1.2281
2023-04-12 14:45:22 - training - INFO - Epoch [2/5][421/438] lr: 6.1e-06, eta: 0:53:26.627382, loss: 1.5436
2023-04-12 14:45:30 - training - INFO - Epoch [2/5][431/438] lr: 6.0e-06, eta: 0:52:27.134199, loss: 1.9545
2023-04-12 14:46:25 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.4308, Validation Metrics: {'exact_match': 39.78300180831826, 'f1': 44.212483673693086}, Test Metrics: {'exact_match': 41.26126126126126, 'f1': 45.556463043586284}
2023-04-12 14:46:25 - training - INFO - Epoch [3/5][1/438] lr: 6.0e-06, eta: 20 days, 22:23:38.168291, loss: 0.9709
2023-04-12 14:46:33 - training - INFO - Epoch [3/5][11/438] lr: 5.9e-06, eta: 1 day, 21:53:11.955458, loss: 0.9406
2023-04-12 14:46:41 - training - INFO - Epoch [3/5][21/438] lr: 5.9e-06, eta: 1 day, 0:08:48.372963, loss: 1.3093
2023-04-12 14:46:49 - training - INFO - Epoch [3/5][31/438] lr: 5.9e-06, eta: 16:25:48.443298, loss: 1.5606
2023-04-12 14:46:56 - training - INFO - Epoch [3/5][41/438] lr: 5.8e-06, eta: 12:28:40.912330, loss: 0.6723
2023-04-12 14:47:04 - training - INFO - Epoch [3/5][51/438] lr: 5.8e-06, eta: 10:04:29.827299, loss: 1.1843
2023-04-12 14:47:12 - training - INFO - Epoch [3/5][61/438] lr: 5.7e-06, eta: 8:27:29.207093, loss: 1.5218
2023-04-12 14:47:19 - training - INFO - Epoch [3/5][71/438] lr: 5.7e-06, eta: 7:17:47.810556, loss: 1.2456
2023-04-12 14:47:27 - training - INFO - Epoch [3/5][81/438] lr: 5.6e-06, eta: 6:25:16.341963, loss: 0.5177
2023-04-12 14:47:35 - training - INFO - Epoch [3/5][91/438] lr: 5.6e-06, eta: 5:44:15.933655, loss: 1.2773
2023-04-12 14:47:42 - training - INFO - Epoch [3/5][101/438] lr: 5.5e-06, eta: 5:11:18.344365, loss: 1.7270
2023-04-12 14:47:50 - training - INFO - Epoch [3/5][111/438] lr: 5.5e-06, eta: 4:44:15.897705, loss: 1.5776
2023-04-12 14:47:58 - training - INFO - Epoch [3/5][121/438] lr: 5.4e-06, eta: 4:21:46.794879, loss: 1.1040
2023-04-12 14:48:06 - training - INFO - Epoch [3/5][131/438] lr: 5.4e-06, eta: 4:02:39.744930, loss: 1.4804
2023-04-12 14:48:13 - training - INFO - Epoch [3/5][141/438] lr: 5.4e-06, eta: 3:46:11.496177, loss: 0.4983
2023-04-12 14:48:21 - training - INFO - Epoch [3/5][151/438] lr: 5.3e-06, eta: 3:31:54.363932, loss: 0.9080
2023-04-12 14:48:28 - training - INFO - Epoch [3/5][161/438] lr: 5.3e-06, eta: 3:19:21.038189, loss: 0.9768
2023-04-12 14:48:36 - training - INFO - Epoch [3/5][171/438] lr: 5.2e-06, eta: 3:08:17.227683, loss: 0.8283
2023-04-12 14:48:44 - training - INFO - Epoch [3/5][181/438] lr: 5.2e-06, eta: 2:58:26.238242, loss: 1.1507
2023-04-12 14:48:51 - training - INFO - Epoch [3/5][191/438] lr: 5.1e-06, eta: 2:49:34.310300, loss: 1.5300
2023-04-12 14:48:59 - training - INFO - Epoch [3/5][201/438] lr: 5.1e-06, eta: 2:41:34.928997, loss: 1.1814
2023-04-12 14:49:07 - training - INFO - Epoch [3/5][211/438] lr: 5.0e-06, eta: 2:34:20.316889, loss: 1.2072
2023-04-12 14:49:14 - training - INFO - Epoch [3/5][221/438] lr: 5.0e-06, eta: 2:27:43.868959, loss: 1.4555
2023-04-12 14:49:22 - training - INFO - Epoch [3/5][231/438] lr: 4.9e-06, eta: 2:21:41.572209, loss: 0.9914
2023-04-12 14:49:29 - training - INFO - Epoch [3/5][241/438] lr: 4.9e-06, eta: 2:16:08.588381, loss: 1.1463
2023-04-12 14:49:37 - training - INFO - Epoch [3/5][251/438] lr: 4.9e-06, eta: 2:11:02.169945, loss: 1.7940
2023-04-12 14:49:45 - training - INFO - Epoch [3/5][261/438] lr: 4.8e-06, eta: 2:06:19.104657, loss: 0.8688
2023-04-12 14:49:52 - training - INFO - Epoch [3/5][271/438] lr: 4.8e-06, eta: 2:01:55.396872, loss: 1.1526
2023-04-12 14:50:00 - training - INFO - Epoch [3/5][281/438] lr: 4.7e-06, eta: 1:57:49.996772, loss: 1.2797
2023-04-12 14:50:07 - training - INFO - Epoch [3/5][291/438] lr: 4.7e-06, eta: 1:54:00.598689, loss: 0.9318
2023-04-12 14:50:15 - training - INFO - Epoch [3/5][301/438] lr: 4.6e-06, eta: 1:50:25.777062, loss: 2.0544
2023-04-12 14:50:23 - training - INFO - Epoch [3/5][311/438] lr: 4.6e-06, eta: 1:47:04.487021, loss: 1.0518
2023-04-12 14:50:30 - training - INFO - Epoch [3/5][321/438] lr: 4.5e-06, eta: 1:43:55.456857, loss: 1.6461
2023-04-12 14:50:38 - training - INFO - Epoch [3/5][331/438] lr: 4.5e-06, eta: 1:40:57.664899, loss: 1.0112
2023-04-12 14:50:46 - training - INFO - Epoch [3/5][341/438] lr: 4.4e-06, eta: 1:38:10.941735, loss: 1.5178
2023-04-12 14:50:53 - training - INFO - Epoch [3/5][351/438] lr: 4.4e-06, eta: 1:35:32.275179, loss: 0.7792
2023-04-12 14:51:01 - training - INFO - Epoch [3/5][361/438] lr: 4.4e-06, eta: 1:33:01.632460, loss: 1.1637
2023-04-12 14:51:09 - training - INFO - Epoch [3/5][371/438] lr: 4.3e-06, eta: 1:30:38.744516, loss: 1.2060
2023-04-12 14:51:16 - training - INFO - Epoch [3/5][381/438] lr: 4.3e-06, eta: 1:28:23.703987, loss: 1.7463
2023-04-12 14:51:24 - training - INFO - Epoch [3/5][391/438] lr: 4.2e-06, eta: 1:26:14.456504, loss: 0.8283
2023-04-12 14:51:31 - training - INFO - Epoch [3/5][401/438] lr: 4.2e-06, eta: 1:24:11.316638, loss: 1.4373
2023-04-12 14:51:39 - training - INFO - Epoch [3/5][411/438] lr: 4.1e-06, eta: 1:22:14.113428, loss: 1.0679
2023-04-12 14:51:47 - training - INFO - Epoch [3/5][421/438] lr: 4.1e-06, eta: 1:20:22.184322, loss: 0.8790
2023-04-12 14:51:54 - training - INFO - Epoch [3/5][431/438] lr: 4.0e-06, eta: 1:18:34.336357, loss: 0.6981
2023-04-12 14:52:47 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.1977, Validation Metrics: {'exact_match': 44.30379746835443, 'f1': 48.96282792917337}, Test Metrics: {'exact_match': 46.306306306306304, 'f1': 51.572288699879095}
2023-04-12 14:52:48 - training - INFO - Epoch [4/5][1/438] lr: 4.0e-06, eta: 30 days, 15:04:18.500391, loss: 1.0339
2023-04-12 14:52:56 - training - INFO - Epoch [4/5][11/438] lr: 3.9e-06, eta: 2 days, 18:56:02.276699, loss: 1.2090
2023-04-12 14:53:03 - training - INFO - Epoch [4/5][21/438] lr: 3.9e-06, eta: 1 day, 11:06:51.881589, loss: 1.2858
2023-04-12 14:53:11 - training - INFO - Epoch [4/5][31/438] lr: 3.9e-06, eta: 23:49:31.018323, loss: 1.1456
2023-04-12 14:53:19 - training - INFO - Epoch [4/5][41/438] lr: 3.8e-06, eta: 18:02:44.098080, loss: 0.9109
2023-04-12 14:53:26 - training - INFO - Epoch [4/5][51/438] lr: 3.8e-06, eta: 14:31:35.707269, loss: 0.9215
2023-04-12 14:53:34 - training - INFO - Epoch [4/5][61/438] lr: 3.7e-06, eta: 12:09:42.748744, loss: 0.6134
2023-04-12 14:53:41 - training - INFO - Epoch [4/5][71/438] lr: 3.7e-06, eta: 10:27:48.111078, loss: 0.5131
2023-04-12 14:53:49 - training - INFO - Epoch [4/5][81/438] lr: 3.6e-06, eta: 9:11:03.240108, loss: 0.8463
2023-04-12 14:53:57 - training - INFO - Epoch [4/5][91/438] lr: 3.6e-06, eta: 8:11:07.443299, loss: 0.8290
2023-04-12 14:54:04 - training - INFO - Epoch [4/5][101/438] lr: 3.5e-06, eta: 7:22:59.525196, loss: 0.9482
2023-04-12 14:54:12 - training - INFO - Epoch [4/5][111/438] lr: 3.5e-06, eta: 6:43:37.185762, loss: 0.8096
2023-04-12 14:54:20 - training - INFO - Epoch [4/5][121/438] lr: 3.4e-06, eta: 6:10:39.734794, loss: 0.6432
2023-04-12 14:54:27 - training - INFO - Epoch [4/5][131/438] lr: 3.4e-06, eta: 5:42:42.588533, loss: 0.9837
2023-04-12 14:54:35 - training - INFO - Epoch [4/5][141/438] lr: 3.4e-06, eta: 5:18:43.089561, loss: 1.2804
2023-04-12 14:54:43 - training - INFO - Epoch [4/5][151/438] lr: 3.3e-06, eta: 4:57:51.949184, loss: 0.4899
2023-04-12 14:54:50 - training - INFO - Epoch [4/5][161/438] lr: 3.3e-06, eta: 4:39:35.944465, loss: 1.2494
2023-04-12 14:54:58 - training - INFO - Epoch [4/5][171/438] lr: 3.2e-06, eta: 4:23:26.421903, loss: 0.9895
2023-04-12 14:55:05 - training - INFO - Epoch [4/5][181/438] lr: 3.2e-06, eta: 4:09:02.060049, loss: 1.1668
2023-04-12 14:55:13 - training - INFO - Epoch [4/5][191/438] lr: 3.1e-06, eta: 3:56:10.693109, loss: 1.5506
2023-04-12 14:55:21 - training - INFO - Epoch [4/5][201/438] lr: 3.1e-06, eta: 3:44:33.527769, loss: 1.1210
2023-04-12 14:55:28 - training - INFO - Epoch [4/5][211/438] lr: 3.0e-06, eta: 3:34:01.732979, loss: 1.7998
2023-04-12 14:55:36 - training - INFO - Epoch [4/5][221/438] lr: 3.0e-06, eta: 3:24:25.934725, loss: 0.9188
2023-04-12 14:55:44 - training - INFO - Epoch [4/5][231/438] lr: 2.9e-06, eta: 3:15:39.391737, loss: 0.7701
2023-04-12 14:55:51 - training - INFO - Epoch [4/5][241/438] lr: 2.9e-06, eta: 3:07:35.940811, loss: 0.8920
2023-04-12 14:55:59 - training - INFO - Epoch [4/5][251/438] lr: 2.9e-06, eta: 3:00:12.296397, loss: 0.8620
2023-04-12 14:56:07 - training - INFO - Epoch [4/5][261/438] lr: 2.8e-06, eta: 2:53:21.312675, loss: 0.6715
2023-04-12 14:56:14 - training - INFO - Epoch [4/5][271/438] lr: 2.8e-06, eta: 2:47:00.436543, loss: 1.0734
2023-04-12 14:56:22 - training - INFO - Epoch [4/5][281/438] lr: 2.7e-06, eta: 2:41:05.749977, loss: 1.1112
2023-04-12 14:56:30 - training - INFO - Epoch [4/5][291/438] lr: 2.7e-06, eta: 2:35:34.329408, loss: 0.6669
2023-04-12 14:56:37 - training - INFO - Epoch [4/5][301/438] lr: 2.6e-06, eta: 2:30:24.722057, loss: 1.4325
2023-04-12 14:56:45 - training - INFO - Epoch [4/5][311/438] lr: 2.6e-06, eta: 2:25:34.228981, loss: 1.3043
2023-04-12 14:56:52 - training - INFO - Epoch [4/5][321/438] lr: 2.5e-06, eta: 2:21:01.370442, loss: 1.2013
2023-04-12 14:57:00 - training - INFO - Epoch [4/5][331/438] lr: 2.5e-06, eta: 2:16:45.345291, loss: 1.1884
2023-04-12 14:57:08 - training - INFO - Epoch [4/5][341/438] lr: 2.4e-06, eta: 2:12:42.995850, loss: 1.6036
2023-04-12 14:57:15 - training - INFO - Epoch [4/5][351/438] lr: 2.4e-06, eta: 2:08:54.091044, loss: 0.9324
2023-04-12 14:57:23 - training - INFO - Epoch [4/5][361/438] lr: 2.4e-06, eta: 2:05:17.788083, loss: 0.9177
2023-04-12 14:57:31 - training - INFO - Epoch [4/5][371/438] lr: 2.3e-06, eta: 2:01:52.836569, loss: 1.1221
2023-04-12 14:57:38 - training - INFO - Epoch [4/5][381/438] lr: 2.3e-06, eta: 1:58:38.413191, loss: 0.9637
2023-04-12 14:57:46 - training - INFO - Epoch [4/5][391/438] lr: 2.2e-06, eta: 1:55:33.007788, loss: 1.5407
2023-04-12 14:57:54 - training - INFO - Epoch [4/5][401/438] lr: 2.2e-06, eta: 1:52:37.296304, loss: 0.7060
2023-04-12 14:58:01 - training - INFO - Epoch [4/5][411/438] lr: 2.1e-06, eta: 1:49:48.604776, loss: 1.0565
2023-04-12 14:58:09 - training - INFO - Epoch [4/5][421/438] lr: 2.1e-06, eta: 1:47:08.383252, loss: 1.2066
2023-04-12 14:58:17 - training - INFO - Epoch [4/5][431/438] lr: 2.0e-06, eta: 1:44:35.433026, loss: 0.8519
2023-04-12 14:59:11 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 1.0708, Validation Metrics: {'exact_match': 52.622061482820975, 'f1': 55.53831873069781}, Test Metrics: {'exact_match': 56.03603603603604, 'f1': 59.45012367006215}
2023-04-12 14:59:11 - training - INFO - Epoch [5/5][1/438] lr: 2.0e-06, eta: 40 days, 8:03:00.570621, loss: 0.9803
2023-04-12 14:59:19 - training - INFO - Epoch [5/5][11/438] lr: 1.9e-06, eta: 3 days, 16:01:06.745896, loss: 0.6617
2023-04-12 14:59:26 - training - INFO - Epoch [5/5][21/438] lr: 1.9e-06, eta: 1 day, 22:06:43.399908, loss: 1.0664
2023-04-12 14:59:34 - training - INFO - Epoch [5/5][31/438] lr: 1.9e-06, eta: 1 day, 7:14:24.339460, loss: 0.9030
2023-04-12 14:59:42 - training - INFO - Epoch [5/5][41/438] lr: 1.8e-06, eta: 23:37:18.773127, loss: 0.9345
2023-04-12 14:59:49 - training - INFO - Epoch [5/5][51/438] lr: 1.8e-06, eta: 18:59:31.432356, loss: 0.9909
2023-04-12 14:59:57 - training - INFO - Epoch [5/5][61/438] lr: 1.7e-06, eta: 15:52:37.884668, loss: 0.5734
2023-04-12 15:00:04 - training - INFO - Epoch [5/5][71/438] lr: 1.7e-06, eta: 13:38:20.391548, loss: 1.3901
2023-04-12 15:00:12 - training - INFO - Epoch [5/5][81/438] lr: 1.6e-06, eta: 11:57:16.232910, loss: 0.7684
2023-04-12 15:00:20 - training - INFO - Epoch [5/5][91/438] lr: 1.6e-06, eta: 10:38:20.411020, loss: 1.3763
2023-04-12 15:00:27 - training - INFO - Epoch [5/5][101/438] lr: 1.5e-06, eta: 9:34:59.845445, loss: 1.0019
2023-04-12 15:00:35 - training - INFO - Epoch [5/5][111/438] lr: 1.5e-06, eta: 8:43:07.762791, loss: 1.0053
2023-04-12 15:00:43 - training - INFO - Epoch [5/5][121/438] lr: 1.4e-06, eta: 7:59:43.758342, loss: 0.6632
2023-04-12 15:00:50 - training - INFO - Epoch [5/5][131/438] lr: 1.4e-06, eta: 7:22:55.611832, loss: 0.9286
2023-04-12 15:00:58 - training - INFO - Epoch [5/5][141/438] lr: 1.4e-06, eta: 6:51:22.010169, loss: 0.9612
2023-04-12 15:01:05 - training - INFO - Epoch [5/5][151/438] lr: 1.3e-06, eta: 6:23:57.625188, loss: 1.0658
2023-04-12 15:01:13 - training - INFO - Epoch [5/5][161/438] lr: 1.3e-06, eta: 5:59:54.596275, loss: 1.1705
2023-04-12 15:01:21 - training - INFO - Epoch [5/5][171/438] lr: 1.2e-06, eta: 5:38:44.990340, loss: 0.8915
2023-04-12 15:01:28 - training - INFO - Epoch [5/5][181/438] lr: 1.2e-06, eta: 5:19:52.332593, loss: 0.8693
2023-04-12 15:01:36 - training - INFO - Epoch [5/5][191/438] lr: 1.1e-06, eta: 5:02:56.539184, loss: 0.9625
2023-04-12 15:01:44 - training - INFO - Epoch [5/5][201/438] lr: 1.1e-06, eta: 4:47:40.913943, loss: 1.1103
2023-04-12 15:01:51 - training - INFO - Epoch [5/5][211/438] lr: 1.0e-06, eta: 4:33:52.032800, loss: 1.2855
2023-04-12 15:01:59 - training - INFO - Epoch [5/5][221/438] lr: 9.9e-07, eta: 4:21:16.171841, loss: 1.4937
2023-04-12 15:02:06 - training - INFO - Epoch [5/5][231/438] lr: 9.5e-07, eta: 4:09:45.100158, loss: 0.8002
2023-04-12 15:02:14 - training - INFO - Epoch [5/5][241/438] lr: 9.0e-07, eta: 3:59:11.720717, loss: 1.3308
2023-04-12 15:02:21 - training - INFO - Epoch [5/5][251/438] lr: 8.5e-07, eta: 3:49:27.126863, loss: 1.0935
2023-04-12 15:02:29 - training - INFO - Epoch [5/5][261/438] lr: 8.1e-07, eta: 3:40:30.148737, loss: 0.5923
2023-04-12 15:02:37 - training - INFO - Epoch [5/5][271/438] lr: 7.6e-07, eta: 3:32:11.064342, loss: 0.9541
2023-04-12 15:02:45 - training - INFO - Epoch [5/5][281/438] lr: 7.2e-07, eta: 3:24:25.363180, loss: 0.9172
2023-04-12 15:02:52 - training - INFO - Epoch [5/5][291/438] lr: 6.7e-07, eta: 3:17:11.062446, loss: 0.8553
2023-04-12 15:03:00 - training - INFO - Epoch [5/5][301/438] lr: 6.3e-07, eta: 3:10:25.799733, loss: 1.1367
2023-04-12 15:03:07 - training - INFO - Epoch [5/5][311/438] lr: 5.8e-07, eta: 3:04:05.831151, loss: 1.5480
2023-04-12 15:03:15 - training - INFO - Epoch [5/5][321/438] lr: 5.3e-07, eta: 2:58:08.971734, loss: 0.9325
2023-04-12 15:03:23 - training - INFO - Epoch [5/5][331/438] lr: 4.9e-07, eta: 2:52:33.207865, loss: 0.7354
2023-04-12 15:03:30 - training - INFO - Epoch [5/5][341/438] lr: 4.4e-07, eta: 2:47:16.150120, loss: 1.0707
2023-04-12 15:03:38 - training - INFO - Epoch [5/5][351/438] lr: 4.0e-07, eta: 2:42:18.008886, loss: 1.2336
2023-04-12 15:03:46 - training - INFO - Epoch [5/5][361/438] lr: 3.5e-07, eta: 2:37:36.756708, loss: 1.9476
2023-04-12 15:03:53 - training - INFO - Epoch [5/5][371/438] lr: 3.1e-07, eta: 2:33:08.840391, loss: 0.8400
2023-04-12 15:04:01 - training - INFO - Epoch [5/5][381/438] lr: 2.6e-07, eta: 2:28:55.171992, loss: 0.6495
2023-04-12 15:04:09 - training - INFO - Epoch [5/5][391/438] lr: 2.1e-07, eta: 2:24:53.271720, loss: 0.7169
2023-04-12 15:04:16 - training - INFO - Epoch [5/5][401/438] lr: 1.7e-07, eta: 2:21:03.306383, loss: 1.1117
2023-04-12 15:04:24 - training - INFO - Epoch [5/5][411/438] lr: 1.2e-07, eta: 2:17:23.846862, loss: 1.3914
2023-04-12 15:04:31 - training - INFO - Epoch [5/5][421/438] lr: 7.8e-08, eta: 2:13:55.029739, loss: 0.4984
2023-04-12 15:04:39 - training - INFO - Epoch [5/5][431/438] lr: 3.2e-08, eta: 2:10:36.012549, loss: 1.3086
2023-04-12 15:05:33 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.9935, Validation Metrics: {'exact_match': 47.739602169981914, 'f1': 51.02243990738569}, Test Metrics: {'exact_match': 49.729729729729726, 'f1': 53.135362010543226}
2023-04-12 15:05:57 - training - INFO - Final Test - Train Loss: 0.9935, Test Metrics: {'exact_match': 49.729729729729726, 'f1': 53.135362010543226}
