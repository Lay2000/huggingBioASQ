2023-04-12 12:50:25 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepakvk/xlnet-base-cased-squad2'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/xlnet_factoid_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 591.75it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1245.41 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1458.10 examples/s]Map:  68%|██████▊   | 3000/4429 [00:02<00:00, 1515.04 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1544.45 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1544.86 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1238.97 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1236.14 examples/s]                                                               2023-04-12 12:51:24 - training - INFO - First Test - Val Metrics:{'exact_match': 0.3616636528028933, 'f1': 4.288024128918328} Test Metrics: {'exact_match': 0.18018018018018017, 'f1': 3.8611520082108313}
2023-04-12 12:51:24 - training - INFO - Epoch [1/5][1/438] lr: 4.5e-05, eta: 1 day, 5:26:05.267419, loss: 6.4757
2023-04-12 12:51:32 - training - INFO - Epoch [1/5][11/438] lr: 4.5e-05, eta: 3:05:16.331925, loss: 4.5525
2023-04-12 12:51:40 - training - INFO - Epoch [1/5][21/438] lr: 4.5e-05, eta: 1:49:51.243960, loss: 4.2459
2023-04-12 12:51:48 - training - INFO - Epoch [1/5][31/438] lr: 4.5e-05, eta: 1:23:04.478982, loss: 3.6166
2023-04-12 12:51:55 - training - INFO - Epoch [1/5][41/438] lr: 4.5e-05, eta: 1:09:06.985472, loss: 3.1916
2023-04-12 12:52:03 - training - INFO - Epoch [1/5][51/438] lr: 4.4e-05, eta: 1:00:38.988723, loss: 4.1847
2023-04-12 12:52:11 - training - INFO - Epoch [1/5][61/438] lr: 4.4e-05, eta: 0:54:57.252557, loss: 2.5864
2023-04-12 12:52:18 - training - INFO - Epoch [1/5][71/438] lr: 4.4e-05, eta: 0:50:50.325928, loss: 2.8450
2023-04-12 12:52:26 - training - INFO - Epoch [1/5][81/438] lr: 4.4e-05, eta: 0:47:35.518512, loss: 3.0376
2023-04-12 12:52:33 - training - INFO - Epoch [1/5][91/438] lr: 4.4e-05, eta: 0:45:04.697935, loss: 2.0210
2023-04-12 12:52:41 - training - INFO - Epoch [1/5][101/438] lr: 4.3e-05, eta: 0:43:07.002977, loss: 2.3737
2023-04-12 12:52:49 - training - INFO - Epoch [1/5][111/438] lr: 4.3e-05, eta: 0:41:28.365495, loss: 1.8032
2023-04-12 12:52:56 - training - INFO - Epoch [1/5][121/438] lr: 4.3e-05, eta: 0:40:00.915187, loss: 2.8650
2023-04-12 12:53:04 - training - INFO - Epoch [1/5][131/438] lr: 4.3e-05, eta: 0:38:52.165471, loss: 2.0861
2023-04-12 12:53:12 - training - INFO - Epoch [1/5][141/438] lr: 4.2e-05, eta: 0:37:47.040237, loss: 2.2995
2023-04-12 12:53:20 - training - INFO - Epoch [1/5][151/438] lr: 4.2e-05, eta: 0:36:47.802693, loss: 1.8191
2023-04-12 12:53:27 - training - INFO - Epoch [1/5][161/438] lr: 4.2e-05, eta: 0:35:55.806413, loss: 2.1127
2023-04-12 12:53:35 - training - INFO - Epoch [1/5][171/438] lr: 4.2e-05, eta: 0:35:10.115451, loss: 1.6092
2023-04-12 12:53:42 - training - INFO - Epoch [1/5][181/438] lr: 4.2e-05, eta: 0:34:28.619084, loss: 1.7531
2023-04-12 12:53:51 - training - INFO - Epoch [1/5][191/438] lr: 4.1e-05, eta: 0:33:56.467257, loss: 2.2134
2023-04-12 12:53:58 - training - INFO - Epoch [1/5][201/438] lr: 4.1e-05, eta: 0:33:21.492909, loss: 1.7911
2023-04-12 12:54:06 - training - INFO - Epoch [1/5][211/438] lr: 4.1e-05, eta: 0:32:50.268652, loss: 1.1944
2023-04-12 12:54:14 - training - INFO - Epoch [1/5][221/438] lr: 4.1e-05, eta: 0:32:21.048076, loss: 1.7100
2023-04-12 12:54:22 - training - INFO - Epoch [1/5][231/438] lr: 4.1e-05, eta: 0:31:55.361316, loss: 1.4335
2023-04-12 12:54:30 - training - INFO - Epoch [1/5][241/438] lr: 4.0e-05, eta: 0:31:27.653276, loss: 1.5471
2023-04-12 12:54:37 - training - INFO - Epoch [1/5][251/438] lr: 4.0e-05, eta: 0:31:02.655753, loss: 1.3772
2023-04-12 12:54:45 - training - INFO - Epoch [1/5][261/438] lr: 4.0e-05, eta: 0:30:37.920336, loss: 1.2598
2023-04-12 12:54:52 - training - INFO - Epoch [1/5][271/438] lr: 4.0e-05, eta: 0:30:15.042013, loss: 1.4238
2023-04-12 12:55:00 - training - INFO - Epoch [1/5][281/438] lr: 4.0e-05, eta: 0:29:52.625451, loss: 0.8903
2023-04-12 12:55:08 - training - INFO - Epoch [1/5][291/438] lr: 3.9e-05, eta: 0:29:32.230356, loss: 1.4900
2023-04-12 12:55:15 - training - INFO - Epoch [1/5][301/438] lr: 3.9e-05, eta: 0:29:12.744541, loss: 1.4318
2023-04-12 12:55:23 - training - INFO - Epoch [1/5][311/438] lr: 3.9e-05, eta: 0:28:53.227180, loss: 1.8220
2023-04-12 12:55:31 - training - INFO - Epoch [1/5][321/438] lr: 3.9e-05, eta: 0:28:34.280442, loss: 1.3598
2023-04-12 12:55:38 - training - INFO - Epoch [1/5][331/438] lr: 3.9e-05, eta: 0:28:15.963841, loss: 1.4336
2023-04-12 12:55:46 - training - INFO - Epoch [1/5][341/438] lr: 3.8e-05, eta: 0:27:59.100937, loss: 2.6093
2023-04-12 12:55:53 - training - INFO - Epoch [1/5][351/438] lr: 3.8e-05, eta: 0:27:42.150726, loss: 1.4629
2023-04-12 12:56:01 - training - INFO - Epoch [1/5][361/438] lr: 3.8e-05, eta: 0:27:25.105024, loss: 1.7630
2023-04-12 12:56:09 - training - INFO - Epoch [1/5][371/438] lr: 3.8e-05, eta: 0:27:10.087755, loss: 1.1905
2023-04-12 12:56:16 - training - INFO - Epoch [1/5][381/438] lr: 3.8e-05, eta: 0:26:55.151178, loss: 1.4358
2023-04-12 12:56:24 - training - INFO - Epoch [1/5][391/438] lr: 3.7e-05, eta: 0:26:39.814720, loss: 1.2536
2023-04-12 12:56:31 - training - INFO - Epoch [1/5][401/438] lr: 3.7e-05, eta: 0:26:25.469048, loss: 1.4369
2023-04-12 12:56:39 - training - INFO - Epoch [1/5][411/438] lr: 3.7e-05, eta: 0:26:11.275065, loss: 0.6531
2023-04-12 12:56:47 - training - INFO - Epoch [1/5][421/438] lr: 3.7e-05, eta: 0:25:56.985350, loss: 1.4260
2023-04-12 12:56:54 - training - INFO - Epoch [1/5][431/438] lr: 3.6e-05, eta: 0:25:43.501392, loss: 1.1104
2023-04-12 12:57:47 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 2.0199, Validation Metrics: {'exact_match': 49.00542495479204, 'f1': 53.04073423074808}, Test Metrics: {'exact_match': 50.090090090090094, 'f1': 53.91378177175119}
2023-04-12 12:57:48 - training - INFO - Epoch [2/5][1/438] lr: 3.6e-05, eta: 10 days, 22:21:43.881937, loss: 0.8833
2023-04-12 12:57:55 - training - INFO - Epoch [2/5][11/438] lr: 3.6e-05, eta: 1 day, 0:09:37.306103, loss: 1.2334
2023-04-12 12:58:03 - training - INFO - Epoch [2/5][21/438] lr: 3.6e-05, eta: 12:49:10.465869, loss: 1.0132
2023-04-12 12:58:11 - training - INFO - Epoch [2/5][31/438] lr: 3.6e-05, eta: 8:47:31.812236, loss: 0.8659
2023-04-12 12:58:18 - training - INFO - Epoch [2/5][41/438] lr: 3.5e-05, eta: 6:43:44.795910, loss: 1.2201
2023-04-12 12:58:26 - training - INFO - Epoch [2/5][51/438] lr: 3.5e-05, eta: 5:28:27.021966, loss: 1.4758
2023-04-12 12:58:34 - training - INFO - Epoch [2/5][61/438] lr: 3.5e-05, eta: 4:37:43.827772, loss: 1.0713
2023-04-12 12:58:42 - training - INFO - Epoch [2/5][71/438] lr: 3.5e-05, eta: 4:01:29.232511, loss: 0.9849
2023-04-12 12:58:49 - training - INFO - Epoch [2/5][81/438] lr: 3.5e-05, eta: 3:34:01.648275, loss: 1.3943
2023-04-12 12:58:57 - training - INFO - Epoch [2/5][91/438] lr: 3.4e-05, eta: 3:12:30.734030, loss: 1.3148
2023-04-12 12:59:04 - training - INFO - Epoch [2/5][101/438] lr: 3.4e-05, eta: 2:55:14.866605, loss: 0.9201
2023-04-12 12:59:12 - training - INFO - Epoch [2/5][111/438] lr: 3.4e-05, eta: 2:41:04.073496, loss: 0.9357
2023-04-12 12:59:20 - training - INFO - Epoch [2/5][121/438] lr: 3.4e-05, eta: 2:29:16.268579, loss: 1.2321
2023-04-12 12:59:28 - training - INFO - Epoch [2/5][131/438] lr: 3.4e-05, eta: 2:19:12.615583, loss: 0.5442
2023-04-12 12:59:35 - training - INFO - Epoch [2/5][141/438] lr: 3.3e-05, eta: 2:10:32.116041, loss: 1.4389
2023-04-12 12:59:43 - training - INFO - Epoch [2/5][151/438] lr: 3.3e-05, eta: 2:03:09.125983, loss: 0.9070
2023-04-12 12:59:51 - training - INFO - Epoch [2/5][161/438] lr: 3.3e-05, eta: 1:56:32.668498, loss: 1.4617
2023-04-12 12:59:59 - training - INFO - Epoch [2/5][171/438] lr: 3.3e-05, eta: 1:50:40.702995, loss: 1.0899
2023-04-12 13:00:06 - training - INFO - Epoch [2/5][181/438] lr: 3.3e-05, eta: 1:45:26.361090, loss: 1.5985
2023-04-12 13:00:14 - training - INFO - Epoch [2/5][191/438] lr: 3.2e-05, eta: 1:40:44.402287, loss: 0.6693
2023-04-12 13:00:21 - training - INFO - Epoch [2/5][201/438] lr: 3.2e-05, eta: 1:36:30.090384, loss: 0.5583
2023-04-12 13:00:29 - training - INFO - Epoch [2/5][211/438] lr: 3.2e-05, eta: 1:32:40.667423, loss: 1.2410
2023-04-12 13:00:37 - training - INFO - Epoch [2/5][221/438] lr: 3.2e-05, eta: 1:29:09.918706, loss: 1.3013
2023-04-12 13:00:44 - training - INFO - Epoch [2/5][231/438] lr: 3.2e-05, eta: 1:25:56.150688, loss: 0.8858
2023-04-12 13:00:52 - training - INFO - Epoch [2/5][241/438] lr: 3.1e-05, eta: 1:22:58.960227, loss: 1.4417
2023-04-12 13:00:59 - training - INFO - Epoch [2/5][251/438] lr: 3.1e-05, eta: 1:20:14.494342, loss: 1.3480
2023-04-12 13:01:07 - training - INFO - Epoch [2/5][261/438] lr: 3.1e-05, eta: 1:17:42.691995, loss: 1.0061
2023-04-12 13:01:15 - training - INFO - Epoch [2/5][271/438] lr: 3.1e-05, eta: 1:15:21.185109, loss: 0.8035
2023-04-12 13:01:22 - training - INFO - Epoch [2/5][281/438] lr: 3.0e-05, eta: 1:13:08.825362, loss: 1.2177
2023-04-12 13:01:30 - training - INFO - Epoch [2/5][291/438] lr: 3.0e-05, eta: 1:11:05.345799, loss: 1.0415
2023-04-12 13:01:37 - training - INFO - Epoch [2/5][301/438] lr: 3.0e-05, eta: 1:09:09.700419, loss: 0.7134
2023-04-12 13:01:45 - training - INFO - Epoch [2/5][311/438] lr: 3.0e-05, eta: 1:07:20.261501, loss: 1.1655
2023-04-12 13:01:52 - training - INFO - Epoch [2/5][321/438] lr: 3.0e-05, eta: 1:05:37.844694, loss: 0.9103
2023-04-12 13:02:00 - training - INFO - Epoch [2/5][331/438] lr: 2.9e-05, eta: 1:04:02.012031, loss: 0.8903
2023-04-12 13:02:08 - training - INFO - Epoch [2/5][341/438] lr: 2.9e-05, eta: 1:02:31.047810, loss: 1.0380
2023-04-12 13:02:15 - training - INFO - Epoch [2/5][351/438] lr: 2.9e-05, eta: 1:01:03.832344, loss: 1.3870
2023-04-12 13:02:23 - training - INFO - Epoch [2/5][361/438] lr: 2.9e-05, eta: 0:59:41.545971, loss: 1.0903
2023-04-12 13:02:31 - training - INFO - Epoch [2/5][371/438] lr: 2.9e-05, eta: 0:58:24.534513, loss: 1.3907
2023-04-12 13:02:39 - training - INFO - Epoch [2/5][381/438] lr: 2.8e-05, eta: 0:57:10.106406, loss: 0.4995
2023-04-12 13:02:46 - training - INFO - Epoch [2/5][391/438] lr: 2.8e-05, eta: 0:55:59.089202, loss: 0.6703
2023-04-12 13:02:54 - training - INFO - Epoch [2/5][401/438] lr: 2.8e-05, eta: 0:54:51.441558, loss: 0.6569
2023-04-12 13:03:01 - training - INFO - Epoch [2/5][411/438] lr: 2.8e-05, eta: 0:53:45.818004, loss: 0.5336
2023-04-12 13:03:09 - training - INFO - Epoch [2/5][421/438] lr: 2.8e-05, eta: 0:52:43.311648, loss: 1.1683
2023-04-12 13:03:17 - training - INFO - Epoch [2/5][431/438] lr: 2.7e-05, eta: 0:51:43.671068, loss: 1.0758
2023-04-12 13:04:12 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.0684, Validation Metrics: {'exact_match': 48.64376130198915, 'f1': 51.662165197050626}, Test Metrics: {'exact_match': 47.747747747747745, 'f1': 50.87058148806201}
2023-04-12 13:04:12 - training - INFO - Epoch [3/5][1/438] lr: 2.7e-05, eta: 20 days, 16:24:20.003179, loss: 0.5784
2023-04-12 13:04:20 - training - INFO - Epoch [3/5][11/438] lr: 2.7e-05, eta: 1 day, 21:21:02.420452, loss: 0.5701
2023-04-12 13:04:28 - training - INFO - Epoch [3/5][21/438] lr: 2.7e-05, eta: 23:52:52.806999, loss: 0.6862
2023-04-12 13:04:37 - training - INFO - Epoch [3/5][31/438] lr: 2.7e-05, eta: 16:15:56.158351, loss: 1.0969
2023-04-12 13:04:45 - training - INFO - Epoch [3/5][41/438] lr: 2.6e-05, eta: 12:21:16.744116, loss: 0.6584
2023-04-12 13:04:52 - training - INFO - Epoch [3/5][51/438] lr: 2.6e-05, eta: 9:58:31.330899, loss: 0.8916
2023-04-12 13:05:00 - training - INFO - Epoch [3/5][61/438] lr: 2.6e-05, eta: 8:22:30.376395, loss: 0.7645
2023-04-12 13:05:08 - training - INFO - Epoch [3/5][71/438] lr: 2.6e-05, eta: 7:13:27.544381, loss: 0.9313
2023-04-12 13:05:15 - training - INFO - Epoch [3/5][81/438] lr: 2.6e-05, eta: 6:21:27.038829, loss: 0.4565
2023-04-12 13:05:23 - training - INFO - Epoch [3/5][91/438] lr: 2.5e-05, eta: 5:40:48.132655, loss: 1.0963
2023-04-12 13:05:30 - training - INFO - Epoch [3/5][101/438] lr: 2.5e-05, eta: 5:08:14.345245, loss: 0.9683
2023-04-12 13:05:38 - training - INFO - Epoch [3/5][111/438] lr: 2.5e-05, eta: 4:41:31.841736, loss: 1.2821
2023-04-12 13:05:46 - training - INFO - Epoch [3/5][121/438] lr: 2.5e-05, eta: 4:19:11.230907, loss: 0.7106
2023-04-12 13:05:53 - training - INFO - Epoch [3/5][131/438] lr: 2.5e-05, eta: 4:00:14.859277, loss: 0.8067
2023-04-12 13:06:01 - training - INFO - Epoch [3/5][141/438] lr: 2.4e-05, eta: 3:44:00.231090, loss: 0.4048
2023-04-12 13:06:09 - training - INFO - Epoch [3/5][151/438] lr: 2.4e-05, eta: 3:29:51.559040, loss: 0.7819
2023-04-12 13:06:16 - training - INFO - Epoch [3/5][161/438] lr: 2.4e-05, eta: 3:17:28.493617, loss: 0.7543
2023-04-12 13:06:24 - training - INFO - Epoch [3/5][171/438] lr: 2.4e-05, eta: 3:06:30.874839, loss: 0.8327
2023-04-12 13:06:32 - training - INFO - Epoch [3/5][181/438] lr: 2.3e-05, eta: 2:56:44.604941, loss: 0.7109
2023-04-12 13:06:39 - training - INFO - Epoch [3/5][191/438] lr: 2.3e-05, eta: 2:47:59.973492, loss: 1.1053
2023-04-12 13:06:47 - training - INFO - Epoch [3/5][201/438] lr: 2.3e-05, eta: 2:40:06.856077, loss: 0.6724
2023-04-12 13:06:54 - training - INFO - Epoch [3/5][211/438] lr: 2.3e-05, eta: 2:32:56.161893, loss: 1.1325
2023-04-12 13:07:02 - training - INFO - Epoch [3/5][221/438] lr: 2.3e-05, eta: 2:26:25.837489, loss: 0.7566
2023-04-12 13:07:10 - training - INFO - Epoch [3/5][231/438] lr: 2.2e-05, eta: 2:20:26.393625, loss: 0.7203
2023-04-12 13:07:17 - training - INFO - Epoch [3/5][241/438] lr: 2.2e-05, eta: 2:14:56.641046, loss: 0.8170
2023-04-12 13:07:25 - training - INFO - Epoch [3/5][251/438] lr: 2.2e-05, eta: 2:09:52.885597, loss: 1.1461
2023-04-12 13:07:33 - training - INFO - Epoch [3/5][261/438] lr: 2.2e-05, eta: 2:05:13.296822, loss: 0.5558
2023-04-12 13:07:40 - training - INFO - Epoch [3/5][271/438] lr: 2.2e-05, eta: 2:00:53.052400, loss: 0.5955
2023-04-12 13:07:48 - training - INFO - Epoch [3/5][281/438] lr: 2.1e-05, eta: 1:56:50.126714, loss: 1.1511
2023-04-12 13:07:56 - training - INFO - Epoch [3/5][291/438] lr: 2.1e-05, eta: 1:53:03.378021, loss: 0.5422
2023-04-12 13:08:03 - training - INFO - Epoch [3/5][301/438] lr: 2.1e-05, eta: 1:49:31.838556, loss: 1.6138
2023-04-12 13:08:11 - training - INFO - Epoch [3/5][311/438] lr: 2.1e-05, eta: 1:46:13.930647, loss: 0.8554
2023-04-12 13:08:19 - training - INFO - Epoch [3/5][321/438] lr: 2.1e-05, eta: 1:43:07.001163, loss: 1.0405
2023-04-12 13:08:26 - training - INFO - Epoch [3/5][331/438] lr: 2.0e-05, eta: 1:40:10.990986, loss: 0.8861
2023-04-12 13:08:34 - training - INFO - Epoch [3/5][341/438] lr: 2.0e-05, eta: 1:37:24.522590, loss: 1.0748
2023-04-12 13:08:42 - training - INFO - Epoch [3/5][351/438] lr: 2.0e-05, eta: 1:34:47.094627, loss: 0.5255
2023-04-12 13:08:49 - training - INFO - Epoch [3/5][361/438] lr: 2.0e-05, eta: 1:32:18.233948, loss: 0.7169
2023-04-12 13:08:57 - training - INFO - Epoch [3/5][371/438] lr: 2.0e-05, eta: 1:29:58.033477, loss: 0.9603
2023-04-12 13:09:05 - training - INFO - Epoch [3/5][381/438] lr: 1.9e-05, eta: 1:27:42.963498, loss: 1.1510
2023-04-12 13:09:12 - training - INFO - Epoch [3/5][391/438] lr: 1.9e-05, eta: 1:25:35.535139, loss: 0.6460
2023-04-12 13:09:20 - training - INFO - Epoch [3/5][401/438] lr: 1.9e-05, eta: 1:23:33.742271, loss: 0.9661
2023-04-12 13:09:28 - training - INFO - Epoch [3/5][411/438] lr: 1.9e-05, eta: 1:21:37.494492, loss: 0.5667
2023-04-12 13:09:35 - training - INFO - Epoch [3/5][421/438] lr: 1.9e-05, eta: 1:19:46.887465, loss: 0.6877
2023-04-12 13:09:43 - training - INFO - Epoch [3/5][431/438] lr: 1.8e-05, eta: 1:18:00.802781, loss: 0.8559
2023-04-12 13:10:36 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 0.8485, Validation Metrics: {'exact_match': 55.69620253164557, 'f1': 58.65898074381717}, Test Metrics: {'exact_match': 58.73873873873874, 'f1': 60.980882066311096}
2023-04-12 13:10:37 - training - INFO - Epoch [4/5][1/438] lr: 1.8e-05, eta: 30 days, 10:18:50.737750, loss: 0.7824
2023-04-12 13:10:45 - training - INFO - Epoch [4/5][11/438] lr: 1.8e-05, eta: 2 days, 18:30:26.896645, loss: 0.7133
2023-04-12 13:10:53 - training - INFO - Epoch [4/5][21/438] lr: 1.8e-05, eta: 1 day, 10:54:13.479894, loss: 0.7753
2023-04-12 13:11:00 - training - INFO - Epoch [4/5][31/438] lr: 1.8e-05, eta: 23:41:13.049291, loss: 0.6901
2023-04-12 13:11:08 - training - INFO - Epoch [4/5][41/438] lr: 1.7e-05, eta: 17:56:34.345438, loss: 0.4651
2023-04-12 13:11:17 - training - INFO - Epoch [4/5][51/438] lr: 1.7e-05, eta: 14:27:09.581445, loss: 0.4424
2023-04-12 13:11:24 - training - INFO - Epoch [4/5][61/438] lr: 1.7e-05, eta: 12:06:00.447080, loss: 0.5854
2023-04-12 13:11:32 - training - INFO - Epoch [4/5][71/438] lr: 1.7e-05, eta: 10:24:50.591853, loss: 0.2670
2023-04-12 13:11:40 - training - INFO - Epoch [4/5][81/438] lr: 1.6e-05, eta: 9:08:31.352037, loss: 0.5463
2023-04-12 13:11:48 - training - INFO - Epoch [4/5][91/438] lr: 1.6e-05, eta: 8:08:52.307580, loss: 0.7636
2023-04-12 13:11:56 - training - INFO - Epoch [4/5][101/438] lr: 1.6e-05, eta: 7:21:06.416291, loss: 0.4940
2023-04-12 13:12:04 - training - INFO - Epoch [4/5][111/438] lr: 1.6e-05, eta: 6:41:54.038256, loss: 0.6644
2023-04-12 13:12:11 - training - INFO - Epoch [4/5][121/438] lr: 1.6e-05, eta: 6:09:02.202134, loss: 0.4788
2023-04-12 13:12:19 - training - INFO - Epoch [4/5][131/438] lr: 1.5e-05, eta: 5:41:13.252641, loss: 0.6080
2023-04-12 13:12:26 - training - INFO - Epoch [4/5][141/438] lr: 1.5e-05, eta: 5:17:20.660340, loss: 1.1599
2023-04-12 13:12:34 - training - INFO - Epoch [4/5][151/438] lr: 1.5e-05, eta: 4:56:35.513191, loss: 0.2283
2023-04-12 13:12:42 - training - INFO - Epoch [4/5][161/438] lr: 1.5e-05, eta: 4:38:25.515846, loss: 0.9803
2023-04-12 13:12:49 - training - INFO - Epoch [4/5][171/438] lr: 1.5e-05, eta: 4:22:21.981480, loss: 0.5880
2023-04-12 13:12:57 - training - INFO - Epoch [4/5][181/438] lr: 1.4e-05, eta: 4:08:04.112453, loss: 0.8732
2023-04-12 13:13:05 - training - INFO - Epoch [4/5][191/438] lr: 1.4e-05, eta: 3:55:14.181379, loss: 1.1086
2023-04-12 13:13:12 - training - INFO - Epoch [4/5][201/438] lr: 1.4e-05, eta: 3:43:42.313008, loss: 0.4385
2023-04-12 13:13:20 - training - INFO - Epoch [4/5][211/438] lr: 1.4e-05, eta: 3:33:13.332576, loss: 1.1408
2023-04-12 13:13:28 - training - INFO - Epoch [4/5][221/438] lr: 1.4e-05, eta: 3:23:40.978517, loss: 0.5533
2023-04-12 13:13:36 - training - INFO - Epoch [4/5][231/438] lr: 1.3e-05, eta: 3:14:59.557431, loss: 0.4278
2023-04-12 13:13:43 - training - INFO - Epoch [4/5][241/438] lr: 1.3e-05, eta: 3:06:59.077425, loss: 0.6081
2023-04-12 13:13:51 - training - INFO - Epoch [4/5][251/438] lr: 1.3e-05, eta: 2:59:35.519384, loss: 0.4333
2023-04-12 13:13:59 - training - INFO - Epoch [4/5][261/438] lr: 1.3e-05, eta: 2:52:45.431346, loss: 0.5245
2023-04-12 13:14:06 - training - INFO - Epoch [4/5][271/438] lr: 1.3e-05, eta: 2:46:24.983018, loss: 0.8526
2023-04-12 13:14:14 - training - INFO - Epoch [4/5][281/438] lr: 1.2e-05, eta: 2:40:31.189441, loss: 0.6368
2023-04-12 13:14:22 - training - INFO - Epoch [4/5][291/438] lr: 1.2e-05, eta: 2:35:02.327460, loss: 0.4821
2023-04-12 13:14:29 - training - INFO - Epoch [4/5][301/438] lr: 1.2e-05, eta: 2:29:53.614005, loss: 0.9559
2023-04-12 13:14:37 - training - INFO - Epoch [4/5][311/438] lr: 1.2e-05, eta: 2:25:04.304027, loss: 1.0195
2023-04-12 13:14:44 - training - INFO - Epoch [4/5][321/438] lr: 1.2e-05, eta: 2:20:33.090603, loss: 0.6633
2023-04-12 13:14:52 - training - INFO - Epoch [4/5][331/438] lr: 1.1e-05, eta: 2:16:16.551240, loss: 0.8815
2023-04-12 13:15:00 - training - INFO - Epoch [4/5][341/438] lr: 1.1e-05, eta: 2:12:15.403223, loss: 0.9178
2023-04-12 13:15:07 - training - INFO - Epoch [4/5][351/438] lr: 1.1e-05, eta: 2:08:28.185051, loss: 0.6334
2023-04-12 13:15:15 - training - INFO - Epoch [4/5][361/438] lr: 1.1e-05, eta: 2:04:52.399734, loss: 0.4668
2023-04-12 13:15:23 - training - INFO - Epoch [4/5][371/438] lr: 1.0e-05, eta: 2:01:28.285526, loss: 0.3121
2023-04-12 13:15:30 - training - INFO - Epoch [4/5][381/438] lr: 1.0e-05, eta: 1:58:14.337210, loss: 0.5931
2023-04-12 13:15:38 - training - INFO - Epoch [4/5][391/438] lr: 1.0e-05, eta: 1:55:09.917623, loss: 1.0585
2023-04-12 13:15:45 - training - INFO - Epoch [4/5][401/438] lr: 9.8e-06, eta: 1:52:13.869349, loss: 0.5579
2023-04-12 13:15:53 - training - INFO - Epoch [4/5][411/438] lr: 9.6e-06, eta: 1:49:26.623452, loss: 0.6442
2023-04-12 13:16:01 - training - INFO - Epoch [4/5][421/438] lr: 9.4e-06, eta: 1:46:46.532564, loss: 0.8870
2023-04-12 13:16:09 - training - INFO - Epoch [4/5][431/438] lr: 9.2e-06, eta: 1:44:14.142090, loss: 0.5889
2023-04-12 13:17:02 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.7027, Validation Metrics: {'exact_match': 59.3128390596745, 'f1': 62.324926456809536}, Test Metrics: {'exact_match': 62.16216216216216, 'f1': 64.53862362901504}
2023-04-12 13:17:03 - training - INFO - Epoch [5/5][1/438] lr: 9.1e-06, eta: 40 days, 4:53:39.321326, loss: 0.7539
2023-04-12 13:17:10 - training - INFO - Epoch [5/5][11/438] lr: 8.9e-06, eta: 3 days, 15:43:57.070341, loss: 0.4826
2023-04-12 13:17:19 - training - INFO - Epoch [5/5][21/438] lr: 8.6e-06, eta: 1 day, 21:59:46.346757, loss: 0.5066
2023-04-12 13:17:27 - training - INFO - Epoch [5/5][31/438] lr: 8.4e-06, eta: 1 day, 7:09:33.606361, loss: 0.6622
2023-04-12 13:17:35 - training - INFO - Epoch [5/5][41/438] lr: 8.2e-06, eta: 23:33:54.375290, loss: 0.3448
2023-04-12 13:17:42 - training - INFO - Epoch [5/5][51/438] lr: 8.0e-06, eta: 18:56:43.634223, loss: 0.4979
2023-04-12 13:17:50 - training - INFO - Epoch [5/5][61/438] lr: 7.8e-06, eta: 15:50:27.832574, loss: 0.2697
2023-04-12 13:17:58 - training - INFO - Epoch [5/5][71/438] lr: 7.6e-06, eta: 13:36:35.178960, loss: 0.7335
2023-04-12 13:18:05 - training - INFO - Epoch [5/5][81/438] lr: 7.4e-06, eta: 11:55:40.859712, loss: 0.4980
2023-04-12 13:18:13 - training - INFO - Epoch [5/5][91/438] lr: 7.2e-06, eta: 10:36:55.332253, loss: 0.7450
2023-04-12 13:18:20 - training - INFO - Epoch [5/5][101/438] lr: 7.0e-06, eta: 9:33:44.401210, loss: 0.5300
2023-04-12 13:18:28 - training - INFO - Epoch [5/5][111/438] lr: 6.8e-06, eta: 8:41:55.170348, loss: 0.7756
2023-04-12 13:18:36 - training - INFO - Epoch [5/5][121/438] lr: 6.6e-06, eta: 7:58:37.688965, loss: 0.2961
2023-04-12 13:18:43 - training - INFO - Epoch [5/5][131/438] lr: 6.4e-06, eta: 7:21:58.756665, loss: 0.4782
2023-04-12 13:18:51 - training - INFO - Epoch [5/5][141/438] lr: 6.2e-06, eta: 6:50:28.803786, loss: 0.4632
2023-04-12 13:18:58 - training - INFO - Epoch [5/5][151/438] lr: 5.9e-06, eta: 6:23:07.765521, loss: 0.8706
2023-04-12 13:19:06 - training - INFO - Epoch [5/5][161/438] lr: 5.7e-06, eta: 5:59:11.662635, loss: 0.7357
2023-04-12 13:19:14 - training - INFO - Epoch [5/5][171/438] lr: 5.5e-06, eta: 5:38:03.473643, loss: 0.4956
2023-04-12 13:19:22 - training - INFO - Epoch [5/5][181/438] lr: 5.3e-06, eta: 5:19:12.867797, loss: 0.4554
2023-04-12 13:19:29 - training - INFO - Epoch [5/5][191/438] lr: 5.1e-06, eta: 5:02:19.047939, loss: 0.5628
2023-04-12 13:19:37 - training - INFO - Epoch [5/5][201/438] lr: 4.9e-06, eta: 4:47:05.802126, loss: 0.6591
2023-04-12 13:19:45 - training - INFO - Epoch [5/5][211/438] lr: 4.7e-06, eta: 4:33:24.878941, loss: 0.6358
2023-04-12 13:19:53 - training - INFO - Epoch [5/5][221/438] lr: 4.5e-06, eta: 4:20:52.868726, loss: 0.8429
2023-04-12 13:20:01 - training - INFO - Epoch [5/5][231/438] lr: 4.3e-06, eta: 4:09:25.394577, loss: 0.4826
2023-04-12 13:20:08 - training - INFO - Epoch [5/5][241/438] lr: 4.1e-06, eta: 3:58:52.887530, loss: 0.5214
2023-04-12 13:20:16 - training - INFO - Epoch [5/5][251/438] lr: 3.9e-06, eta: 3:49:09.993859, loss: 0.5792
2023-04-12 13:20:24 - training - INFO - Epoch [5/5][261/438] lr: 3.7e-06, eta: 3:40:10.906962, loss: 0.5104
2023-04-12 13:20:31 - training - INFO - Epoch [5/5][271/438] lr: 3.5e-06, eta: 3:31:51.939588, loss: 0.5757
2023-04-12 13:20:39 - training - INFO - Epoch [5/5][281/438] lr: 3.3e-06, eta: 3:24:06.324723, loss: 0.6524
2023-04-12 13:20:46 - training - INFO - Epoch [5/5][291/438] lr: 3.0e-06, eta: 3:16:52.813056, loss: 0.4214
2023-04-12 13:20:54 - training - INFO - Epoch [5/5][301/438] lr: 2.8e-06, eta: 3:10:07.474544, loss: 0.4658
2023-04-12 13:21:01 - training - INFO - Epoch [5/5][311/438] lr: 2.6e-06, eta: 3:03:48.542472, loss: 1.0024
2023-04-12 13:21:09 - training - INFO - Epoch [5/5][321/438] lr: 2.4e-06, eta: 2:57:52.943190, loss: 0.7792
2023-04-12 13:21:17 - training - INFO - Epoch [5/5][331/438] lr: 2.2e-06, eta: 2:52:20.564806, loss: 0.4391
2023-04-12 13:21:25 - training - INFO - Epoch [5/5][341/438] lr: 2.0e-06, eta: 2:47:05.952885, loss: 1.0626
2023-04-12 13:21:33 - training - INFO - Epoch [5/5][351/438] lr: 1.8e-06, eta: 2:42:07.920132, loss: 0.9576
2023-04-12 13:21:40 - training - INFO - Epoch [5/5][361/438] lr: 1.6e-06, eta: 2:37:25.495555, loss: 1.2672
2023-04-12 13:21:48 - training - INFO - Epoch [5/5][371/438] lr: 1.4e-06, eta: 2:32:58.295648, loss: 0.4311
2023-04-12 13:21:56 - training - INFO - Epoch [5/5][381/438] lr: 1.2e-06, eta: 2:28:44.770242, loss: 0.4850
2023-04-12 13:22:04 - training - INFO - Epoch [5/5][391/438] lr: 9.7e-07, eta: 2:24:44.310901, loss: 0.5480
2023-04-12 13:22:11 - training - INFO - Epoch [5/5][401/438] lr: 7.7e-07, eta: 2:20:55.695977, loss: 0.6611
2023-04-12 13:22:19 - training - INFO - Epoch [5/5][411/438] lr: 5.6e-07, eta: 2:17:17.116905, loss: 0.7370
2023-04-12 13:22:27 - training - INFO - Epoch [5/5][421/438] lr: 3.5e-07, eta: 2:13:49.540532, loss: 0.3677
2023-04-12 13:22:35 - training - INFO - Epoch [5/5][431/438] lr: 1.5e-07, eta: 2:10:29.641451, loss: 0.4662
2023-04-12 13:23:30 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.6089, Validation Metrics: {'exact_match': 53.34538878842676, 'f1': 56.127568371545784}, Test Metrics: {'exact_match': 58.55855855855856, 'f1': 60.57697602594521}
2023-04-12 13:23:54 - training - INFO - Final Test - Train Loss: 0.6089, Test Metrics: {'exact_match': 58.55855855855856, 'f1': 60.57697602594521}
