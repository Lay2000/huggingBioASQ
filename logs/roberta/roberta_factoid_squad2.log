2023-04-11 00:20:34 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepset/roberta-base-squad2'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/roberta_factoid_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 550.07it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1544.47 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1856.47 examples/s]Map:  68%|██████▊   | 3000/4429 [00:01<00:00, 1940.71 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1972.02 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1979.93 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1533.49 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1553.37 examples/s]                                                               2023-04-11 00:21:01 - training - INFO - First Test - Val Metrics:{'exact_match': 46.835443037974684, 'f1': 58.833915162172495} Test Metrics: {'exact_match': 47.747747747747745, 'f1': 61.90147040611443}
2023-04-11 00:21:01 - training - INFO - Epoch [1/5][1/402] lr: 4.5e-05, eta: 9:20:16.197209, loss: 3.9716
2023-04-11 00:21:05 - training - INFO - Epoch [1/5][11/402] lr: 4.5e-05, eta: 1:01:49.880132, loss: 2.1208
2023-04-11 00:21:09 - training - INFO - Epoch [1/5][21/402] lr: 4.5e-05, eta: 0:38:02.801157, loss: 2.0257
2023-04-11 00:21:12 - training - INFO - Epoch [1/5][31/402] lr: 4.5e-05, eta: 0:29:33.997369, loss: 2.1647
2023-04-11 00:21:16 - training - INFO - Epoch [1/5][41/402] lr: 4.4e-05, eta: 0:25:11.963596, loss: 1.4436
2023-04-11 00:21:20 - training - INFO - Epoch [1/5][51/402] lr: 4.4e-05, eta: 0:22:31.067448, loss: 1.7507
2023-04-11 00:21:23 - training - INFO - Epoch [1/5][61/402] lr: 4.4e-05, eta: 0:20:41.818993, loss: 1.5334
2023-04-11 00:21:27 - training - INFO - Epoch [1/5][71/402] lr: 4.4e-05, eta: 0:19:22.242417, loss: 1.9000
2023-04-11 00:21:31 - training - INFO - Epoch [1/5][81/402] lr: 4.4e-05, eta: 0:18:21.320112, loss: 2.2021
2023-04-11 00:21:34 - training - INFO - Epoch [1/5][91/402] lr: 4.3e-05, eta: 0:17:33.016708, loss: 1.9666
2023-04-11 00:21:38 - training - INFO - Epoch [1/5][101/402] lr: 4.3e-05, eta: 0:16:53.558733, loss: 0.9196
2023-04-11 00:21:42 - training - INFO - Epoch [1/5][111/402] lr: 4.3e-05, eta: 0:16:20.594226, loss: 1.4660
2023-04-11 00:21:45 - training - INFO - Epoch [1/5][121/402] lr: 4.3e-05, eta: 0:15:52.469691, loss: 1.1918
2023-04-11 00:21:49 - training - INFO - Epoch [1/5][131/402] lr: 4.2e-05, eta: 0:15:28.032463, loss: 1.5918
2023-04-11 00:21:53 - training - INFO - Epoch [1/5][141/402] lr: 4.2e-05, eta: 0:15:06.588354, loss: 1.7907
2023-04-11 00:21:57 - training - INFO - Epoch [1/5][151/402] lr: 4.2e-05, eta: 0:14:47.475446, loss: 1.0056
2023-04-11 00:22:00 - training - INFO - Epoch [1/5][161/402] lr: 4.2e-05, eta: 0:14:30.274377, loss: 1.0586
2023-04-11 00:22:04 - training - INFO - Epoch [1/5][171/402] lr: 4.2e-05, eta: 0:14:14.677089, loss: 0.8962
2023-04-11 00:22:08 - training - INFO - Epoch [1/5][181/402] lr: 4.1e-05, eta: 0:14:00.438303, loss: 1.0831
2023-04-11 00:22:11 - training - INFO - Epoch [1/5][191/402] lr: 4.1e-05, eta: 0:13:47.237544, loss: 0.6118
2023-04-11 00:22:15 - training - INFO - Epoch [1/5][201/402] lr: 4.1e-05, eta: 0:13:35.028669, loss: 1.4901
2023-04-11 00:22:19 - training - INFO - Epoch [1/5][211/402] lr: 4.1e-05, eta: 0:13:23.625893, loss: 1.9866
2023-04-11 00:22:22 - training - INFO - Epoch [1/5][221/402] lr: 4.0e-05, eta: 0:13:12.961727, loss: 1.5912
2023-04-11 00:22:26 - training - INFO - Epoch [1/5][231/402] lr: 4.0e-05, eta: 0:13:02.900541, loss: 1.5552
2023-04-11 00:22:30 - training - INFO - Epoch [1/5][241/402] lr: 4.0e-05, eta: 0:12:53.341347, loss: 1.8055
2023-04-11 00:22:33 - training - INFO - Epoch [1/5][251/402] lr: 4.0e-05, eta: 0:12:44.232730, loss: 1.4190
2023-04-11 00:22:37 - training - INFO - Epoch [1/5][261/402] lr: 4.0e-05, eta: 0:12:35.559255, loss: 0.9605
2023-04-11 00:22:41 - training - INFO - Epoch [1/5][271/402] lr: 3.9e-05, eta: 0:12:27.239605, loss: 1.0866
2023-04-11 00:22:45 - training - INFO - Epoch [1/5][281/402] lr: 3.9e-05, eta: 0:12:19.228763, loss: 1.7851
2023-04-11 00:22:48 - training - INFO - Epoch [1/5][291/402] lr: 3.9e-05, eta: 0:12:11.520450, loss: 0.9097
2023-04-11 00:22:52 - training - INFO - Epoch [1/5][301/402] lr: 3.9e-05, eta: 0:12:04.122099, loss: 1.1774
2023-04-11 00:22:56 - training - INFO - Epoch [1/5][311/402] lr: 3.8e-05, eta: 0:11:56.950816, loss: 1.4538
2023-04-11 00:22:59 - training - INFO - Epoch [1/5][321/402] lr: 3.8e-05, eta: 0:11:49.994796, loss: 1.3059
2023-04-11 00:23:03 - training - INFO - Epoch [1/5][331/402] lr: 3.8e-05, eta: 0:11:43.229002, loss: 1.3133
2023-04-11 00:23:07 - training - INFO - Epoch [1/5][341/402] lr: 3.8e-05, eta: 0:11:36.667304, loss: 1.0553
2023-04-11 00:23:10 - training - INFO - Epoch [1/5][351/402] lr: 3.7e-05, eta: 0:11:30.301605, loss: 1.3012
2023-04-11 00:23:14 - training - INFO - Epoch [1/5][361/402] lr: 3.7e-05, eta: 0:11:24.056319, loss: 1.2215
2023-04-11 00:23:18 - training - INFO - Epoch [1/5][371/402] lr: 3.7e-05, eta: 0:11:17.949404, loss: 1.2209
2023-04-11 00:23:22 - training - INFO - Epoch [1/5][381/402] lr: 3.7e-05, eta: 0:11:11.960871, loss: 0.9947
2023-04-11 00:23:25 - training - INFO - Epoch [1/5][391/402] lr: 3.7e-05, eta: 0:11:06.101932, loss: 1.3207
2023-04-11 00:23:29 - training - INFO - Epoch [1/5][401/402] lr: 3.6e-05, eta: 0:11:00.341645, loss: 0.7274
2023-04-11 00:23:37 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 1.4864, Validation Metrics: {'exact_match': 74.86437613019892, 'f1': 80.32160763843748}
2023-04-11 00:23:38 - training - INFO - Epoch [2/5][1/402] lr: 3.6e-05, eta: 4 days, 0:43:08.193647, loss: 0.6465
2023-04-11 00:23:41 - training - INFO - Epoch [2/5][11/402] lr: 3.6e-05, eta: 8:56:08.953477, loss: 0.8267
2023-04-11 00:23:45 - training - INFO - Epoch [2/5][21/402] lr: 3.6e-05, eta: 4:45:16.466796, loss: 0.8101
2023-04-11 00:23:49 - training - INFO - Epoch [2/5][31/402] lr: 3.6e-05, eta: 3:16:13.255047, loss: 1.1050
2023-04-11 00:23:53 - training - INFO - Epoch [2/5][41/402] lr: 3.5e-05, eta: 2:30:34.545817, loss: 1.1506
2023-04-11 00:23:56 - training - INFO - Epoch [2/5][51/402] lr: 3.5e-05, eta: 2:02:48.447429, loss: 1.0525
2023-04-11 00:24:00 - training - INFO - Epoch [2/5][61/402] lr: 3.5e-05, eta: 1:44:07.262232, loss: 0.4126
2023-04-11 00:24:04 - training - INFO - Epoch [2/5][71/402] lr: 3.5e-05, eta: 1:30:40.938706, loss: 0.8821
2023-04-11 00:24:07 - training - INFO - Epoch [2/5][81/402] lr: 3.4e-05, eta: 1:20:32.791215, loss: 0.8802
2023-04-11 00:24:11 - training - INFO - Epoch [2/5][91/402] lr: 3.4e-05, eta: 1:12:37.571169, loss: 0.9410
2023-04-11 00:24:15 - training - INFO - Epoch [2/5][101/402] lr: 3.4e-05, eta: 1:06:15.742579, loss: 0.6634
2023-04-11 00:24:18 - training - INFO - Epoch [2/5][111/402] lr: 3.4e-05, eta: 1:01:02.008812, loss: 1.6317
2023-04-11 00:24:22 - training - INFO - Epoch [2/5][121/402] lr: 3.4e-05, eta: 0:56:39.485958, loss: 0.9850
2023-04-11 00:24:26 - training - INFO - Epoch [2/5][131/402] lr: 3.3e-05, eta: 0:52:56.549087, loss: 1.6477
2023-04-11 00:24:30 - training - INFO - Epoch [2/5][141/402] lr: 3.3e-05, eta: 0:49:44.593017, loss: 1.0746
2023-04-11 00:24:33 - training - INFO - Epoch [2/5][151/402] lr: 3.3e-05, eta: 0:46:57.593350, loss: 1.1022
2023-04-11 00:24:37 - training - INFO - Epoch [2/5][161/402] lr: 3.3e-05, eta: 0:44:30.917480, loss: 1.0472
2023-04-11 00:24:41 - training - INFO - Epoch [2/5][171/402] lr: 3.2e-05, eta: 0:42:21.063996, loss: 1.2773
2023-04-11 00:24:44 - training - INFO - Epoch [2/5][181/402] lr: 3.2e-05, eta: 0:40:25.144260, loss: 0.8399
2023-04-11 00:24:48 - training - INFO - Epoch [2/5][191/402] lr: 3.2e-05, eta: 0:38:40.907575, loss: 1.1843
2023-04-11 00:24:52 - training - INFO - Epoch [2/5][201/402] lr: 3.2e-05, eta: 0:37:06.651066, loss: 0.9738
2023-04-11 00:24:56 - training - INFO - Epoch [2/5][211/402] lr: 3.2e-05, eta: 0:35:40.970111, loss: 1.0724
2023-04-11 00:24:59 - training - INFO - Epoch [2/5][221/402] lr: 3.1e-05, eta: 0:34:22.706266, loss: 0.8870
2023-04-11 00:25:03 - training - INFO - Epoch [2/5][231/402] lr: 3.1e-05, eta: 0:33:10.916259, loss: 1.1805
2023-04-11 00:25:07 - training - INFO - Epoch [2/5][241/402] lr: 3.1e-05, eta: 0:32:04.799368, loss: 0.6193
2023-04-11 00:25:10 - training - INFO - Epoch [2/5][251/402] lr: 3.1e-05, eta: 0:31:03.686885, loss: 0.7591
2023-04-11 00:25:14 - training - INFO - Epoch [2/5][261/402] lr: 3.0e-05, eta: 0:30:06.942621, loss: 1.0551
2023-04-11 00:25:18 - training - INFO - Epoch [2/5][271/402] lr: 3.0e-05, eta: 0:29:14.120605, loss: 0.8550
2023-04-11 00:25:21 - training - INFO - Epoch [2/5][281/402] lr: 3.0e-05, eta: 0:28:24.790542, loss: 0.7231
2023-04-11 00:25:25 - training - INFO - Epoch [2/5][291/402] lr: 3.0e-05, eta: 0:27:38.597778, loss: 1.0291
2023-04-11 00:25:29 - training - INFO - Epoch [2/5][301/402] lr: 3.0e-05, eta: 0:26:55.235715, loss: 0.8291
2023-04-11 00:25:33 - training - INFO - Epoch [2/5][311/402] lr: 2.9e-05, eta: 0:26:14.417427, loss: 1.5901
2023-04-11 00:25:36 - training - INFO - Epoch [2/5][321/402] lr: 2.9e-05, eta: 0:25:35.898906, loss: 1.7095
2023-04-11 00:25:40 - training - INFO - Epoch [2/5][331/402] lr: 2.9e-05, eta: 0:24:59.501468, loss: 0.8200
2023-04-11 00:25:44 - training - INFO - Epoch [2/5][341/402] lr: 2.9e-05, eta: 0:24:25.023165, loss: 0.8331
2023-04-11 00:25:47 - training - INFO - Epoch [2/5][351/402] lr: 2.8e-05, eta: 0:23:52.307604, loss: 0.9911
2023-04-11 00:25:51 - training - INFO - Epoch [2/5][361/402] lr: 2.8e-05, eta: 0:23:21.204770, loss: 1.4399
2023-04-11 00:25:55 - training - INFO - Epoch [2/5][371/402] lr: 2.8e-05, eta: 0:22:51.559453, loss: 1.2243
2023-04-11 00:25:59 - training - INFO - Epoch [2/5][381/402] lr: 2.8e-05, eta: 0:22:23.281545, loss: 0.6800
2023-04-11 00:26:02 - training - INFO - Epoch [2/5][391/402] lr: 2.7e-05, eta: 0:21:56.263190, loss: 0.8549
2023-04-11 00:26:06 - training - INFO - Epoch [2/5][401/402] lr: 2.7e-05, eta: 0:21:30.401910, loss: 1.4274
2023-04-11 00:26:14 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 0.9824, Validation Metrics: {'exact_match': 76.49186256781194, 'f1': 80.01539563698952}
2023-04-11 00:26:15 - training - INFO - Epoch [3/5][1/402] lr: 2.7e-05, eta: 7 days, 16:22:00.737183, loss: 0.8821
2023-04-11 00:26:18 - training - INFO - Epoch [3/5][11/402] lr: 2.7e-05, eta: 16:51:50.867381, loss: 0.5463
2023-04-11 00:26:22 - training - INFO - Epoch [3/5][21/402] lr: 2.7e-05, eta: 8:53:13.108758, loss: 0.6432
2023-04-11 00:26:26 - training - INFO - Epoch [3/5][31/402] lr: 2.7e-05, eta: 6:03:20.853984, loss: 0.9999
2023-04-11 00:26:30 - training - INFO - Epoch [3/5][41/402] lr: 2.6e-05, eta: 4:36:18.243594, loss: 0.6484
2023-04-11 00:26:33 - training - INFO - Epoch [3/5][51/402] lr: 2.6e-05, eta: 3:43:22.461279, loss: 0.8018
2023-04-11 00:26:37 - training - INFO - Epoch [3/5][61/402] lr: 2.6e-05, eta: 3:07:46.672005, loss: 0.7286
2023-04-11 00:26:41 - training - INFO - Epoch [3/5][71/402] lr: 2.6e-05, eta: 2:42:11.563723, loss: 0.9667
2023-04-11 00:26:44 - training - INFO - Epoch [3/5][81/402] lr: 2.5e-05, eta: 2:22:54.561249, loss: 0.5962
2023-04-11 00:26:48 - training - INFO - Epoch [3/5][91/402] lr: 2.5e-05, eta: 2:07:50.954949, loss: 1.2507
2023-04-11 00:26:52 - training - INFO - Epoch [3/5][101/402] lr: 2.5e-05, eta: 1:55:45.621604, loss: 0.9870
2023-04-11 00:26:56 - training - INFO - Epoch [3/5][111/402] lr: 2.5e-05, eta: 1:45:50.335758, loss: 0.8315
2023-04-11 00:26:59 - training - INFO - Epoch [3/5][121/402] lr: 2.5e-05, eta: 1:37:32.894601, loss: 0.9863
2023-04-11 00:27:03 - training - INFO - Epoch [3/5][131/402] lr: 2.4e-05, eta: 1:30:30.738412, loss: 1.0949
2023-04-11 00:27:07 - training - INFO - Epoch [3/5][141/402] lr: 2.4e-05, eta: 1:24:27.907509, loss: 0.9984
2023-04-11 00:27:10 - training - INFO - Epoch [3/5][151/402] lr: 2.4e-05, eta: 1:19:12.632027, loss: 0.6109
2023-04-11 00:27:14 - training - INFO - Epoch [3/5][161/402] lr: 2.4e-05, eta: 1:14:36.020371, loss: 0.6242
2023-04-11 00:27:18 - training - INFO - Epoch [3/5][171/402] lr: 2.3e-05, eta: 1:10:31.333032, loss: 1.2113
2023-04-11 00:27:22 - training - INFO - Epoch [3/5][181/402] lr: 2.3e-05, eta: 1:06:53.281421, loss: 0.6982
2023-04-11 00:27:25 - training - INFO - Epoch [3/5][191/402] lr: 2.3e-05, eta: 1:03:37.708105, loss: 0.9792
2023-04-11 00:27:29 - training - INFO - Epoch [3/5][201/402] lr: 2.3e-05, eta: 1:00:41.200425, loss: 0.6894
2023-04-11 00:27:33 - training - INFO - Epoch [3/5][211/402] lr: 2.2e-05, eta: 0:58:01.030819, loss: 0.6054
2023-04-11 00:27:36 - training - INFO - Epoch [3/5][221/402] lr: 2.2e-05, eta: 0:55:35.082424, loss: 0.7971
2023-04-11 00:27:40 - training - INFO - Epoch [3/5][231/402] lr: 2.2e-05, eta: 0:53:21.507969, loss: 1.0780
2023-04-11 00:27:44 - training - INFO - Epoch [3/5][241/402] lr: 2.2e-05, eta: 0:51:18.643770, loss: 0.6447
2023-04-11 00:27:48 - training - INFO - Epoch [3/5][251/402] lr: 2.2e-05, eta: 0:49:25.285261, loss: 0.8220
2023-04-11 00:27:51 - training - INFO - Epoch [3/5][261/402] lr: 2.1e-05, eta: 0:47:40.293612, loss: 0.6389
2023-04-11 00:27:55 - training - INFO - Epoch [3/5][271/402] lr: 2.1e-05, eta: 0:46:02.803209, loss: 0.9960
2023-04-11 00:27:59 - training - INFO - Epoch [3/5][281/402] lr: 2.1e-05, eta: 0:44:32.000058, loss: 0.5694
2023-04-11 00:28:02 - training - INFO - Epoch [3/5][291/402] lr: 2.1e-05, eta: 0:43:07.194702, loss: 0.8069
2023-04-11 00:28:06 - training - INFO - Epoch [3/5][301/402] lr: 2.0e-05, eta: 0:41:47.771219, loss: 1.2548
2023-04-11 00:28:10 - training - INFO - Epoch [3/5][311/402] lr: 2.0e-05, eta: 0:40:33.239840, loss: 1.2213
2023-04-11 00:28:14 - training - INFO - Epoch [3/5][321/402] lr: 2.0e-05, eta: 0:39:23.084967, loss: 1.3661
2023-04-11 00:28:17 - training - INFO - Epoch [3/5][331/402] lr: 2.0e-05, eta: 0:38:16.920691, loss: 0.8615
2023-04-11 00:28:21 - training - INFO - Epoch [3/5][341/402] lr: 2.0e-05, eta: 0:37:14.415475, loss: 0.7486
2023-04-11 00:28:25 - training - INFO - Epoch [3/5][351/402] lr: 1.9e-05, eta: 0:36:15.289095, loss: 0.3156
2023-04-11 00:28:28 - training - INFO - Epoch [3/5][361/402] lr: 1.9e-05, eta: 0:35:19.248628, loss: 0.7724
2023-04-11 00:28:32 - training - INFO - Epoch [3/5][371/402] lr: 1.9e-05, eta: 0:34:26.000475, loss: 1.2190
2023-04-11 00:28:36 - training - INFO - Epoch [3/5][381/402] lr: 1.9e-05, eta: 0:33:35.358075, loss: 0.7063
2023-04-11 00:28:39 - training - INFO - Epoch [3/5][391/402] lr: 1.8e-05, eta: 0:32:47.135189, loss: 0.4243
2023-04-11 00:28:43 - training - INFO - Epoch [3/5][401/402] lr: 1.8e-05, eta: 0:32:01.113820, loss: 0.8515
2023-04-11 00:28:52 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 0.7901, Validation Metrics: {'exact_match': 77.75768535262206, 'f1': 80.67054989022124}
2023-04-11 00:28:52 - training - INFO - Epoch [4/5][1/402] lr: 1.8e-05, eta: 11 days, 8:04:54.937302, loss: 0.6625
2023-04-11 00:28:56 - training - INFO - Epoch [4/5][11/402] lr: 1.8e-05, eta: 1 day, 0:47:55.308016, loss: 0.6580
2023-04-11 00:28:59 - training - INFO - Epoch [4/5][21/402] lr: 1.8e-05, eta: 13:01:20.226783, loss: 0.7002
2023-04-11 00:29:03 - training - INFO - Epoch [4/5][31/402] lr: 1.7e-05, eta: 8:50:34.550220, loss: 0.5370
2023-04-11 00:29:07 - training - INFO - Epoch [4/5][41/402] lr: 1.7e-05, eta: 6:42:06.474009, loss: 0.6000
2023-04-11 00:29:11 - training - INFO - Epoch [4/5][51/402] lr: 1.7e-05, eta: 5:24:00.071853, loss: 0.6200
2023-04-11 00:29:14 - training - INFO - Epoch [4/5][61/402] lr: 1.7e-05, eta: 4:31:28.786990, loss: 0.3534
2023-04-11 00:29:18 - training - INFO - Epoch [4/5][71/402] lr: 1.7e-05, eta: 3:53:43.986193, loss: 0.6150
2023-04-11 00:29:22 - training - INFO - Epoch [4/5][81/402] lr: 1.6e-05, eta: 3:25:17.438529, loss: 0.6435
2023-04-11 00:29:25 - training - INFO - Epoch [4/5][91/402] lr: 1.6e-05, eta: 3:03:05.254092, loss: 0.6413
2023-04-11 00:29:29 - training - INFO - Epoch [4/5][101/402] lr: 1.6e-05, eta: 2:45:16.002696, loss: 0.4362
2023-04-11 00:29:33 - training - INFO - Epoch [4/5][111/402] lr: 1.6e-05, eta: 2:30:38.774745, loss: 0.9500
2023-04-11 00:29:36 - training - INFO - Epoch [4/5][121/402] lr: 1.5e-05, eta: 2:18:26.018005, loss: 0.5453
2023-04-11 00:29:40 - training - INFO - Epoch [4/5][131/402] lr: 1.5e-05, eta: 2:08:04.538784, loss: 0.5991
2023-04-11 00:29:44 - training - INFO - Epoch [4/5][141/402] lr: 1.5e-05, eta: 1:59:10.655694, loss: 0.5897
2023-04-11 00:29:48 - training - INFO - Epoch [4/5][151/402] lr: 1.5e-05, eta: 1:51:27.044221, loss: 0.5045
2023-04-11 00:29:51 - training - INFO - Epoch [4/5][161/402] lr: 1.5e-05, eta: 1:44:40.501998, loss: 0.9264
2023-04-11 00:29:55 - training - INFO - Epoch [4/5][171/402] lr: 1.4e-05, eta: 1:38:41.144157, loss: 0.5063
2023-04-11 00:29:59 - training - INFO - Epoch [4/5][181/402] lr: 1.4e-05, eta: 1:33:21.067414, loss: 0.7468
2023-04-11 00:30:02 - training - INFO - Epoch [4/5][191/402] lr: 1.4e-05, eta: 1:28:34.097541, loss: 1.0257
2023-04-11 00:30:06 - training - INFO - Epoch [4/5][201/402] lr: 1.4e-05, eta: 1:24:15.319242, loss: 0.4942
2023-04-11 00:30:10 - training - INFO - Epoch [4/5][211/402] lr: 1.3e-05, eta: 1:20:20.728129, loss: 0.5797
2023-04-11 00:30:14 - training - INFO - Epoch [4/5][221/402] lr: 1.3e-05, eta: 1:16:47.050690, loss: 0.8621
2023-04-11 00:30:17 - training - INFO - Epoch [4/5][231/402] lr: 1.3e-05, eta: 1:13:31.583769, loss: 0.6474
2023-04-11 00:30:21 - training - INFO - Epoch [4/5][241/402] lr: 1.3e-05, eta: 1:10:32.005235, loss: 0.4027
2023-04-11 00:30:25 - training - INFO - Epoch [4/5][251/402] lr: 1.2e-05, eta: 1:07:46.421020, loss: 0.5537
2023-04-11 00:30:28 - training - INFO - Epoch [4/5][261/402] lr: 1.2e-05, eta: 1:05:13.231839, loss: 0.3286
2023-04-11 00:30:32 - training - INFO - Epoch [4/5][271/402] lr: 1.2e-05, eta: 1:02:51.071931, loss: 0.5772
2023-04-11 00:30:36 - training - INFO - Epoch [4/5][281/402] lr: 1.2e-05, eta: 1:00:38.780782, loss: 0.6144
2023-04-11 00:30:40 - training - INFO - Epoch [4/5][291/402] lr: 1.2e-05, eta: 0:58:35.332653, loss: 0.5248
2023-04-11 00:30:43 - training - INFO - Epoch [4/5][301/402] lr: 1.1e-05, eta: 0:56:39.838457, loss: 0.6802
2023-04-11 00:30:47 - training - INFO - Epoch [4/5][311/402] lr: 1.1e-05, eta: 0:54:51.525369, loss: 1.1057
2023-04-11 00:30:51 - training - INFO - Epoch [4/5][321/402] lr: 1.1e-05, eta: 0:53:09.728859, loss: 1.2494
2023-04-11 00:30:54 - training - INFO - Epoch [4/5][331/402] lr: 1.1e-05, eta: 0:51:33.847967, loss: 0.7727
2023-04-11 00:30:58 - training - INFO - Epoch [4/5][341/402] lr: 1.0e-05, eta: 0:50:03.380521, loss: 0.6695
2023-04-11 00:31:02 - training - INFO - Epoch [4/5][351/402] lr: 1.0e-05, eta: 0:48:37.862472, loss: 0.7887
2023-04-11 00:31:05 - training - INFO - Epoch [4/5][361/402] lr: 1.0e-05, eta: 0:47:16.873640, loss: 0.6888
2023-04-11 00:31:09 - training - INFO - Epoch [4/5][371/402] lr: 9.8e-06, eta: 0:46:00.062888, loss: 0.4559
2023-04-11 00:31:13 - training - INFO - Epoch [4/5][381/402] lr: 9.6e-06, eta: 0:44:47.105547, loss: 0.7546
2023-04-11 00:31:17 - training - INFO - Epoch [4/5][391/402] lr: 9.3e-06, eta: 0:43:37.688245, loss: 0.6041
2023-04-11 00:31:20 - training - INFO - Epoch [4/5][401/402] lr: 9.1e-06, eta: 0:42:31.520020, loss: 0.5585
2023-04-11 00:31:29 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.6796, Validation Metrics: {'exact_match': 78.48101265822785, 'f1': 81.69908852862794}
2023-04-11 00:31:29 - training - INFO - Epoch [5/5][1/402] lr: 9.1e-06, eta: 14 days, 23:45:46.068090, loss: 1.0179
2023-04-11 00:31:33 - training - INFO - Epoch [5/5][11/402] lr: 8.8e-06, eta: 1 day, 8:43:56.494279, loss: 0.8634
2023-04-11 00:31:37 - training - INFO - Epoch [5/5][21/402] lr: 8.6e-06, eta: 17:09:26.415945, loss: 0.4903
2023-04-11 00:31:40 - training - INFO - Epoch [5/5][31/402] lr: 8.4e-06, eta: 11:37:48.293952, loss: 0.3451
2023-04-11 00:31:44 - training - INFO - Epoch [5/5][41/402] lr: 8.2e-06, eta: 8:47:54.712300, loss: 0.4428
2023-04-11 00:31:48 - training - INFO - Epoch [5/5][51/402] lr: 7.9e-06, eta: 7:04:37.204431, loss: 0.7154
2023-04-11 00:31:51 - training - INFO - Epoch [5/5][61/402] lr: 7.7e-06, eta: 5:55:10.629115, loss: 0.6853
2023-04-11 00:31:55 - training - INFO - Epoch [5/5][71/402] lr: 7.5e-06, eta: 5:05:16.577356, loss: 0.6447
2023-04-11 00:31:59 - training - INFO - Epoch [5/5][81/402] lr: 7.3e-06, eta: 4:27:40.745976, loss: 0.7158
2023-04-11 00:32:03 - training - INFO - Epoch [5/5][91/402] lr: 7.0e-06, eta: 3:58:20.144287, loss: 0.6286
2023-04-11 00:32:06 - training - INFO - Epoch [5/5][101/402] lr: 6.8e-06, eta: 3:34:47.319198, loss: 0.6496
2023-04-11 00:32:10 - training - INFO - Epoch [5/5][111/402] lr: 6.6e-06, eta: 3:15:28.398708, loss: 0.7202
2023-04-11 00:32:14 - training - INFO - Epoch [5/5][121/402] lr: 6.3e-06, eta: 2:59:20.388149, loss: 0.5257
2023-04-11 00:32:17 - training - INFO - Epoch [5/5][131/402] lr: 6.1e-06, eta: 2:45:39.637545, loss: 0.8440
2023-04-11 00:32:21 - training - INFO - Epoch [5/5][141/402] lr: 5.9e-06, eta: 2:33:54.777594, loss: 0.7867
2023-04-11 00:32:25 - training - INFO - Epoch [5/5][151/402] lr: 5.7e-06, eta: 2:23:42.735407, loss: 0.6580
2023-04-11 00:32:29 - training - INFO - Epoch [5/5][161/402] lr: 5.4e-06, eta: 2:14:46.313056, loss: 0.3655
2023-04-11 00:32:32 - training - INFO - Epoch [5/5][171/402] lr: 5.2e-06, eta: 2:06:52.161666, loss: 0.5400
2023-04-11 00:32:36 - training - INFO - Epoch [5/5][181/402] lr: 5.0e-06, eta: 1:59:50.011164, loss: 0.5854
2023-04-11 00:32:40 - training - INFO - Epoch [5/5][191/402] lr: 4.8e-06, eta: 1:53:31.700250, loss: 0.5923
2023-04-11 00:32:43 - training - INFO - Epoch [5/5][201/402] lr: 4.5e-06, eta: 1:47:50.695314, loss: 0.5456
2023-04-11 00:32:47 - training - INFO - Epoch [5/5][211/402] lr: 4.3e-06, eta: 1:42:41.594789, loss: 0.6751
2023-04-11 00:32:51 - training - INFO - Epoch [5/5][221/402] lr: 4.1e-06, eta: 1:38:00.144237, loss: 0.7066
2023-04-11 00:32:55 - training - INFO - Epoch [5/5][231/402] lr: 3.9e-06, eta: 1:33:42.748317, loss: 0.7799
2023-04-11 00:32:58 - training - INFO - Epoch [5/5][241/402] lr: 3.6e-06, eta: 1:29:46.396258, loss: 0.5818
2023-04-11 00:33:02 - training - INFO - Epoch [5/5][251/402] lr: 3.4e-06, eta: 1:26:08.610420, loss: 0.6540
2023-04-11 00:33:06 - training - INFO - Epoch [5/5][261/402] lr: 3.2e-06, eta: 1:22:47.201976, loss: 0.7905
2023-04-11 00:33:09 - training - INFO - Epoch [5/5][271/402] lr: 3.0e-06, eta: 1:19:40.380575, loss: 0.4776
2023-04-11 00:33:13 - training - INFO - Epoch [5/5][281/402] lr: 2.7e-06, eta: 1:16:46.578158, loss: 0.8134
2023-04-11 00:33:17 - training - INFO - Epoch [5/5][291/402] lr: 2.5e-06, eta: 1:14:04.459029, loss: 0.5259
2023-04-11 00:33:21 - training - INFO - Epoch [5/5][301/402] lr: 2.3e-06, eta: 1:11:32.854190, loss: 0.4685
2023-04-11 00:33:24 - training - INFO - Epoch [5/5][311/402] lr: 2.1e-06, eta: 1:09:10.803114, loss: 0.6407
2023-04-11 00:33:28 - training - INFO - Epoch [5/5][321/402] lr: 1.8e-06, eta: 1:06:57.350682, loss: 0.5930
2023-04-11 00:33:32 - training - INFO - Epoch [5/5][331/402] lr: 1.6e-06, eta: 1:04:51.744026, loss: 0.5244
2023-04-11 00:33:35 - training - INFO - Epoch [5/5][341/402] lr: 1.4e-06, eta: 1:02:53.295228, loss: 0.4344
2023-04-11 00:33:39 - training - INFO - Epoch [5/5][351/402] lr: 1.2e-06, eta: 1:01:01.388115, loss: 0.2788
2023-04-11 00:33:43 - training - INFO - Epoch [5/5][361/402] lr: 9.3e-07, eta: 0:59:15.481456, loss: 0.7440
2023-04-11 00:33:47 - training - INFO - Epoch [5/5][371/402] lr: 7.0e-07, eta: 0:57:35.062809, loss: 0.4439
2023-04-11 00:33:50 - training - INFO - Epoch [5/5][381/402] lr: 4.7e-07, eta: 0:55:59.718018, loss: 0.4963
2023-04-11 00:33:54 - training - INFO - Epoch [5/5][391/402] lr: 2.5e-07, eta: 0:54:29.062134, loss: 0.6488
2023-04-11 00:33:58 - training - INFO - Epoch [5/5][401/402] lr: 2.3e-08, eta: 0:53:02.762900, loss: 0.6219
2023-04-11 00:34:06 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.6004, Validation Metrics: {'exact_match': 78.6618444846293, 'f1': 81.79571380312052}
2023-04-11 00:34:14 - training - INFO - Final Test - Train Loss: 0.6004, Test Metrics: {'exact_match': 78.91891891891892, 'f1': 82.28330586225326}
