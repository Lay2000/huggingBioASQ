2023-04-11 00:06:32 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'csarron/roberta-base-squad-v1'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/roberta_factoid_squad'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 587.93it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1537.71 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1856.26 examples/s]Map:  68%|██████▊   | 3000/4429 [00:01<00:00, 1922.74 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1981.44 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1997.56 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1539.15 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1543.40 examples/s]                                                               2023-04-11 00:06:59 - training - INFO - First Test - Val Metrics:{'exact_match': 43.942133815551536, 'f1': 54.490151258048286} Test Metrics: {'exact_match': 43.24324324324324, 'f1': 55.515517020161006}
2023-04-11 00:06:59 - training - INFO - Epoch [1/5][1/402] lr: 4.5e-05, eta: 9:17:55.111166, loss: 2.2983
2023-04-11 00:07:03 - training - INFO - Epoch [1/5][11/402] lr: 4.5e-05, eta: 1:01:36.123014, loss: 1.8891
2023-04-11 00:07:06 - training - INFO - Epoch [1/5][21/402] lr: 4.5e-05, eta: 0:37:54.749685, loss: 2.0575
2023-04-11 00:07:10 - training - INFO - Epoch [1/5][31/402] lr: 4.5e-05, eta: 0:29:28.669901, loss: 1.4821
2023-04-11 00:07:14 - training - INFO - Epoch [1/5][41/402] lr: 4.4e-05, eta: 0:25:07.560912, loss: 1.7567
2023-04-11 00:07:17 - training - INFO - Epoch [1/5][51/402] lr: 4.4e-05, eta: 0:22:27.486396, loss: 1.4805
2023-04-11 00:07:21 - training - INFO - Epoch [1/5][61/402] lr: 4.4e-05, eta: 0:20:38.681103, loss: 1.1669
2023-04-11 00:07:25 - training - INFO - Epoch [1/5][71/402] lr: 4.4e-05, eta: 0:19:19.456074, loss: 1.1949
2023-04-11 00:07:28 - training - INFO - Epoch [1/5][81/402] lr: 4.4e-05, eta: 0:18:18.920436, loss: 1.8784
2023-04-11 00:07:32 - training - INFO - Epoch [1/5][91/402] lr: 4.3e-05, eta: 0:17:30.900051, loss: 1.7952
2023-04-11 00:07:36 - training - INFO - Epoch [1/5][101/402] lr: 4.3e-05, eta: 0:16:51.613462, loss: 1.1108
2023-04-11 00:07:39 - training - INFO - Epoch [1/5][111/402] lr: 4.3e-05, eta: 0:16:18.718014, loss: 1.3081
2023-04-11 00:07:43 - training - INFO - Epoch [1/5][121/402] lr: 4.3e-05, eta: 0:15:50.805482, loss: 0.7949
2023-04-11 00:07:47 - training - INFO - Epoch [1/5][131/402] lr: 4.2e-05, eta: 0:15:26.454103, loss: 1.2596
2023-04-11 00:07:51 - training - INFO - Epoch [1/5][141/402] lr: 4.2e-05, eta: 0:15:05.126796, loss: 1.8248
2023-04-11 00:07:54 - training - INFO - Epoch [1/5][151/402] lr: 4.2e-05, eta: 0:14:46.146261, loss: 1.1088
2023-04-11 00:07:58 - training - INFO - Epoch [1/5][161/402] lr: 4.2e-05, eta: 0:14:29.052188, loss: 1.3677
2023-04-11 00:08:02 - training - INFO - Epoch [1/5][171/402] lr: 4.2e-05, eta: 0:14:13.593918, loss: 1.5154
2023-04-11 00:08:05 - training - INFO - Epoch [1/5][181/402] lr: 4.1e-05, eta: 0:13:59.366509, loss: 0.8314
2023-04-11 00:08:09 - training - INFO - Epoch [1/5][191/402] lr: 4.1e-05, eta: 0:13:46.202533, loss: 1.3507
2023-04-11 00:08:13 - training - INFO - Epoch [1/5][201/402] lr: 4.1e-05, eta: 0:13:34.050000, loss: 1.4128
2023-04-11 00:08:16 - training - INFO - Epoch [1/5][211/402] lr: 4.1e-05, eta: 0:13:22.658031, loss: 1.7283
2023-04-11 00:08:20 - training - INFO - Epoch [1/5][221/402] lr: 4.0e-05, eta: 0:13:11.941997, loss: 1.3040
2023-04-11 00:08:24 - training - INFO - Epoch [1/5][231/402] lr: 4.0e-05, eta: 0:13:01.859826, loss: 1.2311
2023-04-11 00:08:27 - training - INFO - Epoch [1/5][241/402] lr: 4.0e-05, eta: 0:12:52.318865, loss: 1.7301
2023-04-11 00:08:31 - training - INFO - Epoch [1/5][251/402] lr: 4.0e-05, eta: 0:12:43.247690, loss: 1.6269
2023-04-11 00:08:35 - training - INFO - Epoch [1/5][261/402] lr: 4.0e-05, eta: 0:12:34.600803, loss: 1.3492
2023-04-11 00:08:39 - training - INFO - Epoch [1/5][271/402] lr: 3.9e-05, eta: 0:12:26.304023, loss: 1.5694
2023-04-11 00:08:42 - training - INFO - Epoch [1/5][281/402] lr: 3.9e-05, eta: 0:12:18.379824, loss: 1.7560
2023-04-11 00:08:46 - training - INFO - Epoch [1/5][291/402] lr: 3.9e-05, eta: 0:12:10.734867, loss: 1.5720
2023-04-11 00:08:50 - training - INFO - Epoch [1/5][301/402] lr: 3.9e-05, eta: 0:12:03.347922, loss: 1.2977
2023-04-11 00:08:53 - training - INFO - Epoch [1/5][311/402] lr: 3.8e-05, eta: 0:11:56.203256, loss: 0.5981
2023-04-11 00:08:57 - training - INFO - Epoch [1/5][321/402] lr: 3.8e-05, eta: 0:11:49.305684, loss: 1.0723
2023-04-11 00:09:01 - training - INFO - Epoch [1/5][331/402] lr: 3.8e-05, eta: 0:11:42.582587, loss: 1.0606
2023-04-11 00:09:04 - training - INFO - Epoch [1/5][341/402] lr: 3.8e-05, eta: 0:11:36.049774, loss: 1.3010
2023-04-11 00:09:08 - training - INFO - Epoch [1/5][351/402] lr: 3.7e-05, eta: 0:11:29.682798, loss: 1.7231
2023-04-11 00:09:12 - training - INFO - Epoch [1/5][361/402] lr: 3.7e-05, eta: 0:11:23.441242, loss: 1.1137
2023-04-11 00:09:16 - training - INFO - Epoch [1/5][371/402] lr: 3.7e-05, eta: 0:11:17.344613, loss: 1.0333
2023-04-11 00:09:19 - training - INFO - Epoch [1/5][381/402] lr: 3.7e-05, eta: 0:11:11.363028, loss: 1.1757
2023-04-11 00:09:23 - training - INFO - Epoch [1/5][391/402] lr: 3.7e-05, eta: 0:11:05.515854, loss: 1.2170
2023-04-11 00:09:27 - training - INFO - Epoch [1/5][401/402] lr: 3.6e-05, eta: 0:10:59.765623, loss: 0.8919
2023-04-11 00:09:35 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 1.4870, Validation Metrics: {'exact_match': 77.03435804701627, 'f1': 80.29165267428264}
2023-04-11 00:09:35 - training - INFO - Epoch [2/5][1/402] lr: 3.6e-05, eta: 4 days, 0:38:02.277190, loss: 0.9876
2023-04-11 00:09:39 - training - INFO - Epoch [2/5][11/402] lr: 3.6e-05, eta: 8:55:39.918002, loss: 0.8406
2023-04-11 00:09:43 - training - INFO - Epoch [2/5][21/402] lr: 3.6e-05, eta: 4:45:01.334484, loss: 0.6065
2023-04-11 00:09:47 - training - INFO - Epoch [2/5][31/402] lr: 3.6e-05, eta: 3:16:02.936541, loss: 1.2802
2023-04-11 00:09:50 - training - INFO - Epoch [2/5][41/402] lr: 3.5e-05, eta: 2:30:26.965167, loss: 0.6794
2023-04-11 00:09:54 - training - INFO - Epoch [2/5][51/402] lr: 3.5e-05, eta: 2:02:42.296169, loss: 0.4195
2023-04-11 00:09:58 - training - INFO - Epoch [2/5][61/402] lr: 3.5e-05, eta: 1:44:02.259149, loss: 0.9211
2023-04-11 00:10:01 - training - INFO - Epoch [2/5][71/402] lr: 3.5e-05, eta: 1:30:36.663211, loss: 0.8953
2023-04-11 00:10:05 - training - INFO - Epoch [2/5][81/402] lr: 3.4e-05, eta: 1:20:29.137689, loss: 1.1609
2023-04-11 00:10:09 - training - INFO - Epoch [2/5][91/402] lr: 3.4e-05, eta: 1:12:34.377953, loss: 1.1802
2023-04-11 00:10:12 - training - INFO - Epoch [2/5][101/402] lr: 3.4e-05, eta: 1:06:12.894351, loss: 1.0789
2023-04-11 00:10:16 - training - INFO - Epoch [2/5][111/402] lr: 3.4e-05, eta: 1:00:59.422374, loss: 0.7200
2023-04-11 00:10:20 - training - INFO - Epoch [2/5][121/402] lr: 3.4e-05, eta: 0:56:37.147376, loss: 0.8367
2023-04-11 00:10:24 - training - INFO - Epoch [2/5][131/402] lr: 3.3e-05, eta: 0:52:54.363810, loss: 0.7394
2023-04-11 00:10:27 - training - INFO - Epoch [2/5][141/402] lr: 3.3e-05, eta: 0:49:42.712803, loss: 1.0182
2023-04-11 00:10:31 - training - INFO - Epoch [2/5][151/402] lr: 3.3e-05, eta: 0:46:55.879352, loss: 0.8085
2023-04-11 00:10:35 - training - INFO - Epoch [2/5][161/402] lr: 3.3e-05, eta: 0:44:29.343981, loss: 0.9856
2023-04-11 00:10:38 - training - INFO - Epoch [2/5][171/402] lr: 3.2e-05, eta: 0:42:19.499007, loss: 1.0464
2023-04-11 00:10:42 - training - INFO - Epoch [2/5][181/402] lr: 3.2e-05, eta: 0:40:23.617045, loss: 0.9463
2023-04-11 00:10:46 - training - INFO - Epoch [2/5][191/402] lr: 3.2e-05, eta: 0:38:39.452375, loss: 1.3865
2023-04-11 00:10:50 - training - INFO - Epoch [2/5][201/402] lr: 3.2e-05, eta: 0:37:05.337732, loss: 1.1221
2023-04-11 00:10:53 - training - INFO - Epoch [2/5][211/402] lr: 3.2e-05, eta: 0:35:39.762982, loss: 1.0862
2023-04-11 00:10:57 - training - INFO - Epoch [2/5][221/402] lr: 3.1e-05, eta: 0:34:21.591719, loss: 1.2147
2023-04-11 00:11:01 - training - INFO - Epoch [2/5][231/402] lr: 3.1e-05, eta: 0:33:09.895113, loss: 1.3825
2023-04-11 00:11:04 - training - INFO - Epoch [2/5][241/402] lr: 3.1e-05, eta: 0:32:03.829956, loss: 0.9235
2023-04-11 00:11:08 - training - INFO - Epoch [2/5][251/402] lr: 3.1e-05, eta: 0:31:02.701845, loss: 0.9742
2023-04-11 00:11:12 - training - INFO - Epoch [2/5][261/402] lr: 3.0e-05, eta: 0:30:06.050631, loss: 0.8649
2023-04-11 00:11:15 - training - INFO - Epoch [2/5][271/402] lr: 3.0e-05, eta: 0:29:13.282407, loss: 1.0267
2023-04-11 00:11:19 - training - INFO - Epoch [2/5][281/402] lr: 3.0e-05, eta: 0:28:24.005576, loss: 1.8115
2023-04-11 00:11:23 - training - INFO - Epoch [2/5][291/402] lr: 3.0e-05, eta: 0:27:37.850013, loss: 0.6180
2023-04-11 00:11:27 - training - INFO - Epoch [2/5][301/402] lr: 3.0e-05, eta: 0:26:54.511099, loss: 1.1214
2023-04-11 00:11:30 - training - INFO - Epoch [2/5][311/402] lr: 2.9e-05, eta: 0:26:13.736128, loss: 0.8353
2023-04-11 00:11:34 - training - INFO - Epoch [2/5][321/402] lr: 2.9e-05, eta: 0:25:35.241885, loss: 0.8001
2023-04-11 00:11:38 - training - INFO - Epoch [2/5][331/402] lr: 2.9e-05, eta: 0:24:58.871843, loss: 0.8028
2023-04-11 00:11:41 - training - INFO - Epoch [2/5][341/402] lr: 2.9e-05, eta: 0:24:24.464050, loss: 0.9306
2023-04-11 00:11:45 - training - INFO - Epoch [2/5][351/402] lr: 2.8e-05, eta: 0:23:51.758475, loss: 0.8559
2023-04-11 00:11:49 - training - INFO - Epoch [2/5][361/402] lr: 2.8e-05, eta: 0:23:20.647408, loss: 1.3271
2023-04-11 00:11:53 - training - INFO - Epoch [2/5][371/402] lr: 2.8e-05, eta: 0:22:51.020222, loss: 0.8251
2023-04-11 00:11:56 - training - INFO - Epoch [2/5][381/402] lr: 2.8e-05, eta: 0:22:22.753749, loss: 0.8438
2023-04-11 00:12:00 - training - INFO - Epoch [2/5][391/402] lr: 2.7e-05, eta: 0:21:55.733777, loss: 0.9407
2023-04-11 00:12:04 - training - INFO - Epoch [2/5][401/402] lr: 2.7e-05, eta: 0:21:29.869331, loss: 0.6192
2023-04-11 00:12:12 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 0.9874, Validation Metrics: {'exact_match': 77.9385171790235, 'f1': 81.57895984474332}
2023-04-11 00:12:13 - training - INFO - Epoch [3/5][1/402] lr: 2.7e-05, eta: 7 days, 16:17:54.976213, loss: 1.1149
2023-04-11 00:12:16 - training - INFO - Epoch [3/5][11/402] lr: 2.7e-05, eta: 16:51:29.130255, loss: 0.9271
2023-04-11 00:12:20 - training - INFO - Epoch [3/5][21/402] lr: 2.7e-05, eta: 8:53:02.022072, loss: 0.7659
2023-04-11 00:12:24 - training - INFO - Epoch [3/5][31/402] lr: 2.7e-05, eta: 6:03:13.329826, loss: 0.9590
2023-04-11 00:12:27 - training - INFO - Epoch [3/5][41/402] lr: 2.6e-05, eta: 4:36:12.905635, loss: 0.9608
2023-04-11 00:12:31 - training - INFO - Epoch [3/5][51/402] lr: 2.6e-05, eta: 3:43:18.141684, loss: 0.2919
2023-04-11 00:12:35 - training - INFO - Epoch [3/5][61/402] lr: 2.6e-05, eta: 3:07:43.126774, loss: 1.0376
2023-04-11 00:12:38 - training - INFO - Epoch [3/5][71/402] lr: 2.6e-05, eta: 2:42:08.536944, loss: 1.1224
2023-04-11 00:12:42 - training - INFO - Epoch [3/5][81/402] lr: 2.5e-05, eta: 2:22:51.889584, loss: 0.3022
2023-04-11 00:12:46 - training - INFO - Epoch [3/5][91/402] lr: 2.5e-05, eta: 2:07:48.663663, loss: 0.4219
2023-04-11 00:12:50 - training - INFO - Epoch [3/5][101/402] lr: 2.5e-05, eta: 1:55:43.489251, loss: 0.8243
2023-04-11 00:12:53 - training - INFO - Epoch [3/5][111/402] lr: 2.5e-05, eta: 1:45:48.322818, loss: 0.6537
2023-04-11 00:12:57 - training - INFO - Epoch [3/5][121/402] lr: 2.5e-05, eta: 1:37:30.924374, loss: 0.6472
2023-04-11 00:13:01 - training - INFO - Epoch [3/5][131/402] lr: 2.4e-05, eta: 1:30:28.985305, loss: 0.9612
2023-04-11 00:13:04 - training - INFO - Epoch [3/5][141/402] lr: 2.4e-05, eta: 1:24:26.328204, loss: 0.5347
2023-04-11 00:13:08 - training - INFO - Epoch [3/5][151/402] lr: 2.4e-05, eta: 1:19:11.196879, loss: 0.7817
2023-04-11 00:13:12 - training - INFO - Epoch [3/5][161/402] lr: 2.4e-05, eta: 1:14:34.729769, loss: 0.8405
2023-04-11 00:13:16 - training - INFO - Epoch [3/5][171/402] lr: 2.3e-05, eta: 1:10:30.191013, loss: 1.3433
2023-04-11 00:13:19 - training - INFO - Epoch [3/5][181/402] lr: 2.3e-05, eta: 1:06:52.227917, loss: 0.8833
2023-04-11 00:13:23 - training - INFO - Epoch [3/5][191/402] lr: 2.3e-05, eta: 1:03:36.698560, loss: 1.0678
2023-04-11 00:13:27 - training - INFO - Epoch [3/5][201/402] lr: 2.3e-05, eta: 1:00:40.303161, loss: 0.7133
2023-04-11 00:13:30 - training - INFO - Epoch [3/5][211/402] lr: 2.2e-05, eta: 0:58:00.291430, loss: 0.7517
2023-04-11 00:13:34 - training - INFO - Epoch [3/5][221/402] lr: 2.2e-05, eta: 0:55:34.377558, loss: 0.6388
2023-04-11 00:13:38 - training - INFO - Epoch [3/5][231/402] lr: 2.2e-05, eta: 0:53:20.791032, loss: 1.2499
2023-04-11 00:13:42 - training - INFO - Epoch [3/5][241/402] lr: 2.2e-05, eta: 0:51:17.936170, loss: 0.7654
2023-04-11 00:13:45 - training - INFO - Epoch [3/5][251/402] lr: 2.2e-05, eta: 0:49:24.615082, loss: 0.4365
2023-04-11 00:13:49 - training - INFO - Epoch [3/5][261/402] lr: 2.1e-05, eta: 0:47:39.672717, loss: 0.8029
2023-04-11 00:13:53 - training - INFO - Epoch [3/5][271/402] lr: 2.1e-05, eta: 0:46:02.201515, loss: 0.7290
2023-04-11 00:13:56 - training - INFO - Epoch [3/5][281/402] lr: 2.1e-05, eta: 0:44:31.403553, loss: 0.8457
2023-04-11 00:14:00 - training - INFO - Epoch [3/5][291/402] lr: 2.1e-05, eta: 0:43:06.577581, loss: 0.6244
2023-04-11 00:14:04 - training - INFO - Epoch [3/5][301/402] lr: 2.0e-05, eta: 0:41:47.181614, loss: 0.9521
2023-04-11 00:14:08 - training - INFO - Epoch [3/5][311/402] lr: 2.0e-05, eta: 0:40:32.623103, loss: 0.9461
2023-04-11 00:14:11 - training - INFO - Epoch [3/5][321/402] lr: 2.0e-05, eta: 0:39:22.490439, loss: 0.7363
2023-04-11 00:14:15 - training - INFO - Epoch [3/5][331/402] lr: 2.0e-05, eta: 0:38:16.348152, loss: 0.6900
2023-04-11 00:14:19 - training - INFO - Epoch [3/5][341/402] lr: 2.0e-05, eta: 0:37:13.886402, loss: 0.8271
2023-04-11 00:14:22 - training - INFO - Epoch [3/5][351/402] lr: 1.9e-05, eta: 0:36:14.784759, loss: 0.7703
2023-04-11 00:14:26 - training - INFO - Epoch [3/5][361/402] lr: 1.9e-05, eta: 0:35:18.740736, loss: 1.7168
2023-04-11 00:14:30 - training - INFO - Epoch [3/5][371/402] lr: 1.9e-05, eta: 0:34:25.520248, loss: 0.7989
2023-04-11 00:14:34 - training - INFO - Epoch [3/5][381/402] lr: 1.9e-05, eta: 0:33:34.919874, loss: 0.8973
2023-04-11 00:14:37 - training - INFO - Epoch [3/5][391/402] lr: 1.8e-05, eta: 0:32:46.725582, loss: 0.8602
2023-04-11 00:14:41 - training - INFO - Epoch [3/5][401/402] lr: 1.8e-05, eta: 0:32:00.738923, loss: 0.8282
2023-04-11 00:14:49 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 0.7982, Validation Metrics: {'exact_match': 80.10849909584087, 'f1': 82.63094625601403}
2023-04-11 00:14:50 - training - INFO - Epoch [4/5][1/402] lr: 1.8e-05, eta: 11 days, 8:00:46.978486, loss: 0.8044
2023-04-11 00:14:53 - training - INFO - Epoch [4/5][11/402] lr: 1.8e-05, eta: 1 day, 0:47:32.545403, loss: 0.7170
2023-04-11 00:14:57 - training - INFO - Epoch [4/5][21/402] lr: 1.8e-05, eta: 13:01:08.525496, loss: 0.6349
2023-04-11 00:15:01 - training - INFO - Epoch [4/5][31/402] lr: 1.7e-05, eta: 8:50:26.923154, loss: 0.7453
2023-04-11 00:15:05 - training - INFO - Epoch [4/5][41/402] lr: 1.7e-05, eta: 6:42:00.828886, loss: 1.1518
2023-04-11 00:15:08 - training - INFO - Epoch [4/5][51/402] lr: 1.7e-05, eta: 5:23:55.409433, loss: 0.8164
2023-04-11 00:15:12 - training - INFO - Epoch [4/5][61/402] lr: 1.7e-05, eta: 4:31:24.871449, loss: 0.2054
2023-04-11 00:15:16 - training - INFO - Epoch [4/5][71/402] lr: 1.7e-05, eta: 3:53:40.709283, loss: 0.7510
2023-04-11 00:15:19 - training - INFO - Epoch [4/5][81/402] lr: 1.6e-05, eta: 3:25:14.676201, loss: 0.5359
2023-04-11 00:15:23 - training - INFO - Epoch [4/5][91/402] lr: 1.6e-05, eta: 3:03:02.730607, loss: 0.7017
2023-04-11 00:15:27 - training - INFO - Epoch [4/5][101/402] lr: 1.6e-05, eta: 2:45:13.881797, loss: 0.7128
2023-04-11 00:15:30 - training - INFO - Epoch [4/5][111/402] lr: 1.6e-05, eta: 2:30:37.130211, loss: 0.7935
2023-04-11 00:15:34 - training - INFO - Epoch [4/5][121/402] lr: 1.5e-05, eta: 2:18:24.452024, loss: 0.6107
2023-04-11 00:15:38 - training - INFO - Epoch [4/5][131/402] lr: 1.5e-05, eta: 2:08:03.063769, loss: 0.6119
2023-04-11 00:15:42 - training - INFO - Epoch [4/5][141/402] lr: 1.5e-05, eta: 1:59:09.362346, loss: 0.5615
2023-04-11 00:15:45 - training - INFO - Epoch [4/5][151/402] lr: 1.5e-05, eta: 1:51:25.837730, loss: 0.6643
2023-04-11 00:15:49 - training - INFO - Epoch [4/5][161/402] lr: 1.5e-05, eta: 1:44:39.414786, loss: 0.8778
2023-04-11 00:15:53 - training - INFO - Epoch [4/5][171/402] lr: 1.4e-05, eta: 1:38:40.095927, loss: 0.9199
2023-04-11 00:15:56 - training - INFO - Epoch [4/5][181/402] lr: 1.4e-05, eta: 1:33:20.028542, loss: 0.4131
2023-04-11 00:16:00 - training - INFO - Epoch [4/5][191/402] lr: 1.4e-05, eta: 1:28:33.149842, loss: 0.5766
2023-04-11 00:16:04 - training - INFO - Epoch [4/5][201/402] lr: 1.4e-05, eta: 1:24:14.432832, loss: 0.9399
2023-04-11 00:16:08 - training - INFO - Epoch [4/5][211/402] lr: 1.3e-05, eta: 1:20:19.880800, loss: 0.7224
2023-04-11 00:16:11 - training - INFO - Epoch [4/5][221/402] lr: 1.3e-05, eta: 1:16:46.209860, loss: 0.7283
2023-04-11 00:16:15 - training - INFO - Epoch [4/5][231/402] lr: 1.3e-05, eta: 1:13:30.722733, loss: 0.6424
2023-04-11 00:16:19 - training - INFO - Epoch [4/5][241/402] lr: 1.3e-05, eta: 1:10:31.149039, loss: 0.8979
2023-04-11 00:16:22 - training - INFO - Epoch [4/5][251/402] lr: 1.2e-05, eta: 1:07:45.603085, loss: 0.7572
2023-04-11 00:16:26 - training - INFO - Epoch [4/5][261/402] lr: 1.2e-05, eta: 1:05:12.458781, loss: 1.1815
2023-04-11 00:16:30 - training - INFO - Epoch [4/5][271/402] lr: 1.2e-05, eta: 1:02:50.343290, loss: 0.4767
2023-04-11 00:16:34 - training - INFO - Epoch [4/5][281/402] lr: 1.2e-05, eta: 1:00:38.132407, loss: 0.7407
2023-04-11 00:16:37 - training - INFO - Epoch [4/5][291/402] lr: 1.2e-05, eta: 0:58:34.703499, loss: 0.9659
2023-04-11 00:16:41 - training - INFO - Epoch [4/5][301/402] lr: 1.1e-05, eta: 0:56:39.236889, loss: 0.8659
2023-04-11 00:16:45 - training - INFO - Epoch [4/5][311/402] lr: 1.1e-05, eta: 0:54:50.990184, loss: 0.9060
2023-04-11 00:16:48 - training - INFO - Epoch [4/5][321/402] lr: 1.1e-05, eta: 0:53:09.235671, loss: 0.5411
2023-04-11 00:16:52 - training - INFO - Epoch [4/5][331/402] lr: 1.1e-05, eta: 0:51:33.406390, loss: 0.6878
2023-04-11 00:16:56 - training - INFO - Epoch [4/5][341/402] lr: 1.0e-05, eta: 0:50:02.981630, loss: 0.7236
2023-04-11 00:17:00 - training - INFO - Epoch [4/5][351/402] lr: 1.0e-05, eta: 0:48:37.502469, loss: 0.8233
2023-04-11 00:17:03 - training - INFO - Epoch [4/5][361/402] lr: 1.0e-05, eta: 0:47:16.532297, loss: 0.8803
2023-04-11 00:17:07 - training - INFO - Epoch [4/5][371/402] lr: 9.8e-06, eta: 0:45:59.730171, loss: 0.7767
2023-04-11 00:17:11 - training - INFO - Epoch [4/5][381/402] lr: 9.6e-06, eta: 0:44:46.768344, loss: 0.7163
2023-04-11 00:17:14 - training - INFO - Epoch [4/5][391/402] lr: 9.3e-06, eta: 0:43:37.345017, loss: 0.8800
2023-04-11 00:17:18 - training - INFO - Epoch [4/5][401/402] lr: 9.1e-06, eta: 0:42:31.177303, loss: 0.6540
2023-04-11 00:17:27 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.6814, Validation Metrics: {'exact_match': 76.85352622061482, 'f1': 80.0008240316857}
2023-04-11 00:17:27 - training - INFO - Epoch [5/5][1/402] lr: 9.1e-06, eta: 14 days, 23:46:42.731935, loss: 0.5789
2023-04-11 00:17:31 - training - INFO - Epoch [5/5][11/402] lr: 8.8e-06, eta: 1 day, 8:43:53.065994, loss: 0.5196
2023-04-11 00:17:34 - training - INFO - Epoch [5/5][21/402] lr: 8.6e-06, eta: 17:09:24.681537, loss: 0.6322
2023-04-11 00:17:38 - training - INFO - Epoch [5/5][31/402] lr: 8.4e-06, eta: 11:37:47.104573, loss: 0.4887
2023-04-11 00:17:42 - training - INFO - Epoch [5/5][41/402] lr: 8.2e-06, eta: 8:47:54.208236, loss: 0.5682
2023-04-11 00:17:46 - training - INFO - Epoch [5/5][51/402] lr: 7.9e-06, eta: 7:04:36.769533, loss: 0.8403
2023-04-11 00:17:49 - training - INFO - Epoch [5/5][61/402] lr: 7.7e-06, eta: 5:55:09.974251, loss: 0.6741
2023-04-11 00:17:53 - training - INFO - Epoch [5/5][71/402] lr: 7.5e-06, eta: 5:05:16.011168, loss: 0.4969
2023-04-11 00:17:57 - training - INFO - Epoch [5/5][81/402] lr: 7.3e-06, eta: 4:27:40.392969, loss: 0.5135
2023-04-11 00:18:00 - training - INFO - Epoch [5/5][91/402] lr: 7.0e-06, eta: 3:58:19.724026, loss: 0.6096
2023-04-11 00:18:04 - training - INFO - Epoch [5/5][101/402] lr: 6.8e-06, eta: 3:34:46.920217, loss: 0.7740
2023-04-11 00:18:08 - training - INFO - Epoch [5/5][111/402] lr: 6.6e-06, eta: 3:15:27.946746, loss: 0.7749
2023-04-11 00:18:11 - training - INFO - Epoch [5/5][121/402] lr: 6.3e-06, eta: 2:59:19.993348, loss: 0.5295
2023-04-11 00:18:15 - training - INFO - Epoch [5/5][131/402] lr: 6.1e-06, eta: 2:45:39.248592, loss: 0.8575
2023-04-11 00:18:19 - training - INFO - Epoch [5/5][141/402] lr: 5.9e-06, eta: 2:33:54.338379, loss: 0.4111
2023-04-11 00:18:23 - training - INFO - Epoch [5/5][151/402] lr: 5.7e-06, eta: 2:23:42.512327, loss: 0.3397
2023-04-11 00:18:26 - training - INFO - Epoch [5/5][161/402] lr: 5.4e-06, eta: 2:14:46.072686, loss: 0.5164
2023-04-11 00:18:30 - training - INFO - Epoch [5/5][171/402] lr: 5.2e-06, eta: 2:06:51.893172, loss: 0.2625
2023-04-11 00:18:34 - training - INFO - Epoch [5/5][181/402] lr: 5.0e-06, eta: 1:59:49.793513, loss: 0.2904
2023-04-11 00:18:37 - training - INFO - Epoch [5/5][191/402] lr: 4.8e-06, eta: 1:53:31.434676, loss: 1.0329
2023-04-11 00:18:41 - training - INFO - Epoch [5/5][201/402] lr: 4.5e-06, eta: 1:47:50.358840, loss: 0.7865
2023-04-11 00:18:45 - training - INFO - Epoch [5/5][211/402] lr: 4.3e-06, eta: 1:42:41.287160, loss: 0.5637
2023-04-11 00:18:49 - training - INFO - Epoch [5/5][221/402] lr: 4.1e-06, eta: 1:37:59.822217, loss: 0.5224
2023-04-11 00:18:52 - training - INFO - Epoch [5/5][231/402] lr: 3.9e-06, eta: 1:33:42.422760, loss: 0.6715
2023-04-11 00:18:56 - training - INFO - Epoch [5/5][241/402] lr: 3.6e-06, eta: 1:29:46.053072, loss: 0.7365
2023-04-11 00:19:00 - training - INFO - Epoch [5/5][251/402] lr: 3.4e-06, eta: 1:26:08.230476, loss: 0.4959
2023-04-11 00:19:03 - training - INFO - Epoch [5/5][261/402] lr: 3.2e-06, eta: 1:22:46.846929, loss: 0.4957
2023-04-11 00:19:07 - training - INFO - Epoch [5/5][271/402] lr: 3.0e-06, eta: 1:19:40.058860, loss: 0.6529
2023-04-11 00:19:11 - training - INFO - Epoch [5/5][281/402] lr: 2.7e-06, eta: 1:16:46.277312, loss: 0.4504
2023-04-11 00:19:15 - training - INFO - Epoch [5/5][291/402] lr: 2.5e-06, eta: 1:14:04.183989, loss: 0.6329
2023-04-11 00:19:18 - training - INFO - Epoch [5/5][301/402] lr: 2.3e-06, eta: 1:11:32.579041, loss: 0.6867
2023-04-11 00:19:22 - training - INFO - Epoch [5/5][311/402] lr: 2.1e-06, eta: 1:09:10.504090, loss: 0.4535
2023-04-11 00:19:26 - training - INFO - Epoch [5/5][321/402] lr: 1.8e-06, eta: 1:06:57.071997, loss: 0.7728
2023-04-11 00:19:29 - training - INFO - Epoch [5/5][331/402] lr: 1.6e-06, eta: 1:04:51.460275, loss: 0.4000
2023-04-11 00:19:33 - training - INFO - Epoch [5/5][341/402] lr: 1.4e-06, eta: 1:02:52.993139, loss: 0.7562
2023-04-11 00:19:37 - training - INFO - Epoch [5/5][351/402] lr: 1.2e-06, eta: 1:01:01.067928, loss: 0.7485
2023-04-11 00:19:41 - training - INFO - Epoch [5/5][361/402] lr: 9.3e-07, eta: 0:59:15.143411, loss: 0.6363
2023-04-11 00:19:44 - training - INFO - Epoch [5/5][371/402] lr: 7.0e-07, eta: 0:57:34.739926, loss: 0.9053
2023-04-11 00:19:48 - training - INFO - Epoch [5/5][381/402] lr: 4.7e-07, eta: 0:55:59.410137, loss: 0.5263
2023-04-11 00:19:52 - training - INFO - Epoch [5/5][391/402] lr: 2.5e-07, eta: 0:54:28.775571, loss: 0.4195
2023-04-11 00:19:55 - training - INFO - Epoch [5/5][401/402] lr: 2.3e-08, eta: 0:53:02.457190, loss: 0.8785
2023-04-11 00:20:04 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.6053, Validation Metrics: {'exact_match': 76.31103074141049, 'f1': 79.33131812142359}
2023-04-11 00:20:12 - training - INFO - Final Test - Train Loss: 0.6053, Test Metrics: {'exact_match': 81.08108108108108, 'f1': 84.12183271625997}
