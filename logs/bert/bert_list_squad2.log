2023-04-12 02:58:54 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-44a167365c0b341b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'deepset/bert-base-uncased-squad2'}, 'data': {'task_type': 'list', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/bert_list_squad2'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 572.86it/s]
Map:   0%|          | 0/6878 [00:00<?, ? examples/s]Map:  15%|█▍        | 1000/6878 [00:00<00:03, 1645.39 examples/s]Map:  29%|██▉       | 2000/6878 [00:01<00:02, 1732.20 examples/s]Map:  44%|████▎     | 3000/6878 [00:01<00:02, 1751.26 examples/s]Map:  58%|█████▊    | 4000/6878 [00:02<00:01, 1759.43 examples/s]Map:  73%|███████▎  | 5000/6878 [00:02<00:01, 1754.89 examples/s]Map:  87%|████████▋ | 6000/6878 [00:03<00:00, 1728.62 examples/s]Map: 100%|██████████| 6878/6878 [00:04<00:00, 1599.12 examples/s]                                                                 Map:   0%|          | 0/859 [00:00<?, ? examples/s]Map: 100%|██████████| 859/859 [00:00<00:00, 1378.66 examples/s]                                                               Map:   0%|          | 0/861 [00:00<?, ? examples/s]Map: 100%|██████████| 861/861 [00:00<00:00, 1353.70 examples/s]                                                               2023-04-12 02:59:33 - training - INFO - First Test - Val Metrics:{'exact_match': 10.477299185098952, 'f1': 28.1929062730593} Test Metrics: {'exact_match': 12.427409988385598, 'f1': 29.849086933426168}
2023-04-12 02:59:34 - training - INFO - Epoch [1/5][1/649] lr: 4.5e-05, eta: 1 day, 0:46:51.673904, loss: 5.7828
2023-04-12 02:59:37 - training - INFO - Epoch [1/5][11/649] lr: 4.5e-05, eta: 2:32:47.516820, loss: 2.5307
2023-04-12 02:59:41 - training - INFO - Epoch [1/5][21/649] lr: 4.5e-05, eta: 1:29:13.790520, loss: 2.6843
2023-04-12 02:59:45 - training - INFO - Epoch [1/5][31/649] lr: 4.5e-05, eta: 1:06:38.858800, loss: 2.4476
2023-04-12 02:59:48 - training - INFO - Epoch [1/5][41/649] lr: 4.5e-05, eta: 0:55:02.920296, loss: 2.1436
2023-04-12 02:59:52 - training - INFO - Epoch [1/5][51/649] lr: 4.5e-05, eta: 0:47:58.455158, loss: 1.6898
2023-04-12 02:59:56 - training - INFO - Epoch [1/5][61/649] lr: 4.5e-05, eta: 0:43:12.068928, loss: 3.2475
2023-04-12 03:00:00 - training - INFO - Epoch [1/5][71/649] lr: 4.4e-05, eta: 0:39:45.356220, loss: 1.5286
2023-04-12 03:00:03 - training - INFO - Epoch [1/5][81/649] lr: 4.4e-05, eta: 0:37:08.977884, loss: 2.0825
2023-04-12 03:00:07 - training - INFO - Epoch [1/5][91/649] lr: 4.4e-05, eta: 0:35:05.966802, loss: 2.2134
2023-04-12 03:00:11 - training - INFO - Epoch [1/5][101/649] lr: 4.4e-05, eta: 0:33:26.488224, loss: 2.4057
2023-04-12 03:00:14 - training - INFO - Epoch [1/5][111/649] lr: 4.4e-05, eta: 0:32:04.285402, loss: 2.4579
2023-04-12 03:00:18 - training - INFO - Epoch [1/5][121/649] lr: 4.4e-05, eta: 0:30:55.096804, loss: 2.0601
2023-04-12 03:00:22 - training - INFO - Epoch [1/5][131/649] lr: 4.4e-05, eta: 0:29:55.874940, loss: 1.7600
2023-04-12 03:00:25 - training - INFO - Epoch [1/5][141/649] lr: 4.3e-05, eta: 0:29:04.528704, loss: 1.7007
2023-04-12 03:00:29 - training - INFO - Epoch [1/5][151/649] lr: 4.3e-05, eta: 0:28:19.506354, loss: 1.9466
2023-04-12 03:00:33 - training - INFO - Epoch [1/5][161/649] lr: 4.3e-05, eta: 0:27:39.555912, loss: 1.5597
2023-04-12 03:00:37 - training - INFO - Epoch [1/5][171/649] lr: 4.3e-05, eta: 0:27:03.889684, loss: 1.8259
2023-04-12 03:00:40 - training - INFO - Epoch [1/5][181/649] lr: 4.3e-05, eta: 0:26:31.748000, loss: 2.0807
2023-04-12 03:00:44 - training - INFO - Epoch [1/5][191/649] lr: 4.3e-05, eta: 0:26:02.557722, loss: 1.8563
2023-04-12 03:00:48 - training - INFO - Epoch [1/5][201/649] lr: 4.3e-05, eta: 0:25:35.929344, loss: 2.5084
2023-04-12 03:00:51 - training - INFO - Epoch [1/5][211/649] lr: 4.2e-05, eta: 0:25:11.493290, loss: 2.4616
2023-04-12 03:00:55 - training - INFO - Epoch [1/5][221/649] lr: 4.2e-05, eta: 0:24:48.905712, loss: 2.1328
2023-04-12 03:00:59 - training - INFO - Epoch [1/5][231/649] lr: 4.2e-05, eta: 0:24:27.998840, loss: 2.1577
2023-04-12 03:01:02 - training - INFO - Epoch [1/5][241/649] lr: 4.2e-05, eta: 0:24:08.594888, loss: 2.4324
2023-04-12 03:01:06 - training - INFO - Epoch [1/5][251/649] lr: 4.2e-05, eta: 0:23:50.425416, loss: 1.5481
2023-04-12 03:01:10 - training - INFO - Epoch [1/5][261/649] lr: 4.2e-05, eta: 0:23:33.398456, loss: 2.5655
2023-04-12 03:01:14 - training - INFO - Epoch [1/5][271/649] lr: 4.2e-05, eta: 0:23:17.307134, loss: 1.7155
2023-04-12 03:01:17 - training - INFO - Epoch [1/5][281/649] lr: 4.1e-05, eta: 0:23:02.080596, loss: 2.6218
2023-04-12 03:01:21 - training - INFO - Epoch [1/5][291/649] lr: 4.1e-05, eta: 0:22:47.637012, loss: 1.4505
2023-04-12 03:01:25 - training - INFO - Epoch [1/5][301/649] lr: 4.1e-05, eta: 0:22:33.895552, loss: 2.1862
2023-04-12 03:01:28 - training - INFO - Epoch [1/5][311/649] lr: 4.1e-05, eta: 0:22:20.791056, loss: 1.6888
2023-04-12 03:01:32 - training - INFO - Epoch [1/5][321/649] lr: 4.1e-05, eta: 0:22:08.259164, loss: 1.9197
2023-04-12 03:01:36 - training - INFO - Epoch [1/5][331/649] lr: 4.1e-05, eta: 0:21:56.300424, loss: 1.4512
2023-04-12 03:01:39 - training - INFO - Epoch [1/5][341/649] lr: 4.1e-05, eta: 0:21:44.796240, loss: 1.9132
2023-04-12 03:01:43 - training - INFO - Epoch [1/5][351/649] lr: 4.0e-05, eta: 0:21:33.736654, loss: 1.6802
2023-04-12 03:01:47 - training - INFO - Epoch [1/5][361/649] lr: 4.0e-05, eta: 0:21:23.094484, loss: 1.8354
2023-04-12 03:01:51 - training - INFO - Epoch [1/5][371/649] lr: 4.0e-05, eta: 0:21:12.998064, loss: 1.6327
2023-04-12 03:01:54 - training - INFO - Epoch [1/5][381/649] lr: 4.0e-05, eta: 0:21:03.187248, loss: 1.5483
2023-04-12 03:01:58 - training - INFO - Epoch [1/5][391/649] lr: 4.0e-05, eta: 0:20:53.673726, loss: 1.9548
2023-04-12 03:02:02 - training - INFO - Epoch [1/5][401/649] lr: 4.0e-05, eta: 0:20:44.505960, loss: 2.0626
2023-04-12 03:02:05 - training - INFO - Epoch [1/5][411/649] lr: 4.0e-05, eta: 0:20:35.624000, loss: 1.6978
2023-04-12 03:02:09 - training - INFO - Epoch [1/5][421/649] lr: 4.0e-05, eta: 0:20:26.946104, loss: 2.0589
2023-04-12 03:02:13 - training - INFO - Epoch [1/5][431/649] lr: 3.9e-05, eta: 0:20:18.509838, loss: 2.1215
2023-04-12 03:02:17 - training - INFO - Epoch [1/5][441/649] lr: 3.9e-05, eta: 0:20:10.321364, loss: 1.6546
2023-04-12 03:02:20 - training - INFO - Epoch [1/5][451/649] lr: 3.9e-05, eta: 0:20:02.316874, loss: 1.6351
2023-04-12 03:02:24 - training - INFO - Epoch [1/5][461/649] lr: 3.9e-05, eta: 0:19:54.469632, loss: 1.8992
2023-04-12 03:02:28 - training - INFO - Epoch [1/5][471/649] lr: 3.9e-05, eta: 0:19:46.769906, loss: 1.2247
2023-04-12 03:02:31 - training - INFO - Epoch [1/5][481/649] lr: 3.9e-05, eta: 0:19:39.252308, loss: 1.0054
2023-04-12 03:02:35 - training - INFO - Epoch [1/5][491/649] lr: 3.9e-05, eta: 0:19:31.873818, loss: 0.9102
2023-04-12 03:02:39 - training - INFO - Epoch [1/5][501/649] lr: 3.8e-05, eta: 0:19:24.597504, loss: 1.6148
2023-04-12 03:02:43 - training - INFO - Epoch [1/5][511/649] lr: 3.8e-05, eta: 0:19:17.444368, loss: 1.8866
2023-04-12 03:02:46 - training - INFO - Epoch [1/5][521/649] lr: 3.8e-05, eta: 0:19:10.426920, loss: 1.8500
2023-04-12 03:02:50 - training - INFO - Epoch [1/5][531/649] lr: 3.8e-05, eta: 0:19:03.522188, loss: 2.0822
2023-04-12 03:02:54 - training - INFO - Epoch [1/5][541/649] lr: 3.8e-05, eta: 0:18:56.764304, loss: 2.1790
2023-04-12 03:02:57 - training - INFO - Epoch [1/5][551/649] lr: 3.8e-05, eta: 0:18:50.100672, loss: 1.5552
2023-04-12 03:03:01 - training - INFO - Epoch [1/5][561/649] lr: 3.8e-05, eta: 0:18:43.549240, loss: 1.1508
2023-04-12 03:03:05 - training - INFO - Epoch [1/5][571/649] lr: 3.7e-05, eta: 0:18:37.111632, loss: 1.1834
2023-04-12 03:03:08 - training - INFO - Epoch [1/5][581/649] lr: 3.7e-05, eta: 0:18:30.789432, loss: 1.4691
2023-04-12 03:03:12 - training - INFO - Epoch [1/5][591/649] lr: 3.7e-05, eta: 0:18:24.531104, loss: 1.7275
2023-04-12 03:03:16 - training - INFO - Epoch [1/5][601/649] lr: 3.7e-05, eta: 0:18:18.457732, loss: 1.5562
2023-04-12 03:03:20 - training - INFO - Epoch [1/5][611/649] lr: 3.7e-05, eta: 0:18:12.417258, loss: 1.9695
2023-04-12 03:03:23 - training - INFO - Epoch [1/5][621/649] lr: 3.7e-05, eta: 0:18:06.430464, loss: 1.6849
2023-04-12 03:03:27 - training - INFO - Epoch [1/5][631/649] lr: 3.7e-05, eta: 0:18:00.546566, loss: 2.1189
2023-04-12 03:03:31 - training - INFO - Epoch [1/5][641/649] lr: 3.6e-05, eta: 0:17:54.754128, loss: 2.1161
2023-04-12 03:04:02 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 1.9385, Validation Metrics: {'exact_match': 36.43771827706636, 'f1': 44.60897053507797}, Test Metrics: {'exact_match': 38.21138211382114, 'f1': 46.045116086377774}
2023-04-12 03:04:02 - training - INFO - Epoch [2/5][1/649] lr: 3.6e-05, eta: 11 days, 2:58:47.596736, loss: 1.3784
2023-04-12 03:04:06 - training - INFO - Epoch [2/5][11/649] lr: 3.6e-05, eta: 1 day, 0:29:54.239364, loss: 1.6275
2023-04-12 03:04:10 - training - INFO - Epoch [2/5][21/649] lr: 3.6e-05, eta: 12:57:03.373056, loss: 0.8567
2023-04-12 03:04:14 - training - INFO - Epoch [2/5][31/649] lr: 3.6e-05, eta: 8:51:09.201216, loss: 1.1018
2023-04-12 03:04:17 - training - INFO - Epoch [2/5][41/649] lr: 3.6e-05, eta: 6:45:10.209024, loss: 1.7530
2023-04-12 03:04:21 - training - INFO - Epoch [2/5][51/649] lr: 3.6e-05, eta: 5:28:34.677540, loss: 1.3830
2023-04-12 03:04:25 - training - INFO - Epoch [2/5][61/649] lr: 3.5e-05, eta: 4:37:04.514128, loss: 1.2123
2023-04-12 03:04:28 - training - INFO - Epoch [2/5][71/649] lr: 3.5e-05, eta: 4:00:03.783396, loss: 1.2369
2023-04-12 03:04:32 - training - INFO - Epoch [2/5][81/649] lr: 3.5e-05, eta: 3:32:10.512200, loss: 1.3929
2023-04-12 03:04:36 - training - INFO - Epoch [2/5][91/649] lr: 3.5e-05, eta: 3:10:24.112862, loss: 1.6311
2023-04-12 03:04:40 - training - INFO - Epoch [2/5][101/649] lr: 3.5e-05, eta: 2:52:56.309832, loss: 2.1398
2023-04-12 03:04:43 - training - INFO - Epoch [2/5][111/649] lr: 3.5e-05, eta: 2:38:36.666792, loss: 1.0175
2023-04-12 03:04:47 - training - INFO - Epoch [2/5][121/649] lr: 3.5e-05, eta: 2:26:38.399236, loss: 1.1743
2023-04-12 03:04:51 - training - INFO - Epoch [2/5][131/649] lr: 3.4e-05, eta: 2:16:29.231454, loss: 1.2004
2023-04-12 03:04:54 - training - INFO - Epoch [2/5][141/649] lr: 3.4e-05, eta: 2:07:46.017088, loss: 1.2386
2023-04-12 03:04:58 - training - INFO - Epoch [2/5][151/649] lr: 3.4e-05, eta: 2:00:11.359064, loss: 1.1961
2023-04-12 03:05:02 - training - INFO - Epoch [2/5][161/649] lr: 3.4e-05, eta: 1:53:32.963088, loss: 2.0601
2023-04-12 03:05:06 - training - INFO - Epoch [2/5][171/649] lr: 3.4e-05, eta: 1:47:40.794870, loss: 1.3992
2023-04-12 03:05:09 - training - INFO - Epoch [2/5][181/649] lr: 3.4e-05, eta: 1:42:27.125488, loss: 1.5481
2023-04-12 03:05:13 - training - INFO - Epoch [2/5][191/649] lr: 3.4e-05, eta: 1:37:45.903312, loss: 1.3837
2023-04-12 03:05:17 - training - INFO - Epoch [2/5][201/649] lr: 3.4e-05, eta: 1:33:32.015808, loss: 1.0958
2023-04-12 03:05:20 - training - INFO - Epoch [2/5][211/649] lr: 3.3e-05, eta: 1:29:41.951920, loss: 1.4055
2023-04-12 03:05:24 - training - INFO - Epoch [2/5][221/649] lr: 3.3e-05, eta: 1:26:12.343344, loss: 1.6040
2023-04-12 03:05:28 - training - INFO - Epoch [2/5][231/649] lr: 3.3e-05, eta: 1:23:00.535538, loss: 1.0242
2023-04-12 03:05:32 - training - INFO - Epoch [2/5][241/649] lr: 3.3e-05, eta: 1:20:04.360284, loss: 1.8459
2023-04-12 03:05:35 - training - INFO - Epoch [2/5][251/649] lr: 3.3e-05, eta: 1:17:21.927540, loss: 1.6065
2023-04-12 03:05:39 - training - INFO - Epoch [2/5][261/649] lr: 3.3e-05, eta: 1:14:51.809232, loss: 1.0016
2023-04-12 03:05:43 - training - INFO - Epoch [2/5][271/649] lr: 3.3e-05, eta: 1:12:32.389520, loss: 1.5921
2023-04-12 03:05:47 - training - INFO - Epoch [2/5][281/649] lr: 3.2e-05, eta: 1:10:22.686312, loss: 1.0073
2023-04-12 03:05:50 - training - INFO - Epoch [2/5][291/649] lr: 3.2e-05, eta: 1:08:21.510840, loss: 1.5111
2023-04-12 03:05:54 - training - INFO - Epoch [2/5][301/649] lr: 3.2e-05, eta: 1:06:28.230912, loss: 1.3979
2023-04-12 03:05:58 - training - INFO - Epoch [2/5][311/649] lr: 3.2e-05, eta: 1:04:41.969532, loss: 1.4455
2023-04-12 03:06:01 - training - INFO - Epoch [2/5][321/649] lr: 3.2e-05, eta: 1:03:02.112128, loss: 1.2976
2023-04-12 03:06:05 - training - INFO - Epoch [2/5][331/649] lr: 3.2e-05, eta: 1:01:28.101186, loss: 1.4375
2023-04-12 03:06:09 - training - INFO - Epoch [2/5][341/649] lr: 3.2e-05, eta: 0:59:59.296008, loss: 1.2693
2023-04-12 03:06:13 - training - INFO - Epoch [2/5][351/649] lr: 3.1e-05, eta: 0:58:35.454666, loss: 1.4685
2023-04-12 03:06:16 - training - INFO - Epoch [2/5][361/649] lr: 3.1e-05, eta: 0:57:16.069700, loss: 1.3928
2023-04-12 03:06:20 - training - INFO - Epoch [2/5][371/649] lr: 3.1e-05, eta: 0:56:00.651546, loss: 1.5005
2023-04-12 03:06:24 - training - INFO - Epoch [2/5][381/649] lr: 3.1e-05, eta: 0:54:48.911632, loss: 0.8964
2023-04-12 03:06:27 - training - INFO - Epoch [2/5][391/649] lr: 3.1e-05, eta: 0:53:40.656234, loss: 1.1346
2023-04-12 03:06:31 - training - INFO - Epoch [2/5][401/649] lr: 3.1e-05, eta: 0:52:35.608548, loss: 1.1207
2023-04-12 03:06:35 - training - INFO - Epoch [2/5][411/649] lr: 3.1e-05, eta: 0:51:33.614238, loss: 2.3767
2023-04-12 03:06:39 - training - INFO - Epoch [2/5][421/649] lr: 3.0e-05, eta: 0:50:34.433184, loss: 0.9204
2023-04-12 03:06:42 - training - INFO - Epoch [2/5][431/649] lr: 3.0e-05, eta: 0:49:37.847964, loss: 1.4516
2023-04-12 03:06:46 - training - INFO - Epoch [2/5][441/649] lr: 3.0e-05, eta: 0:48:43.641072, loss: 1.3033
2023-04-12 03:06:50 - training - INFO - Epoch [2/5][451/649] lr: 3.0e-05, eta: 0:47:51.659230, loss: 1.5391
2023-04-12 03:06:53 - training - INFO - Epoch [2/5][461/649] lr: 3.0e-05, eta: 0:47:01.773312, loss: 1.7252
2023-04-12 03:06:57 - training - INFO - Epoch [2/5][471/649] lr: 3.0e-05, eta: 0:46:13.891814, loss: 1.1092
2023-04-12 03:07:01 - training - INFO - Epoch [2/5][481/649] lr: 3.0e-05, eta: 0:45:27.813712, loss: 1.2643
2023-04-12 03:07:05 - training - INFO - Epoch [2/5][491/649] lr: 2.9e-05, eta: 0:44:43.541664, loss: 1.6011
2023-04-12 03:07:08 - training - INFO - Epoch [2/5][501/649] lr: 2.9e-05, eta: 0:44:00.792672, loss: 1.4678
2023-04-12 03:07:12 - training - INFO - Epoch [2/5][511/649] lr: 2.9e-05, eta: 0:43:19.612964, loss: 0.9495
2023-04-12 03:07:16 - training - INFO - Epoch [2/5][521/649] lr: 2.9e-05, eta: 0:42:39.805452, loss: 1.3951
2023-04-12 03:07:20 - training - INFO - Epoch [2/5][531/649] lr: 2.9e-05, eta: 0:42:01.387420, loss: 1.7633
2023-04-12 03:07:23 - training - INFO - Epoch [2/5][541/649] lr: 2.9e-05, eta: 0:41:24.275664, loss: 1.6275
2023-04-12 03:07:27 - training - INFO - Epoch [2/5][551/649] lr: 2.9e-05, eta: 0:40:48.339528, loss: 0.9645
2023-04-12 03:07:31 - training - INFO - Epoch [2/5][561/649] lr: 2.8e-05, eta: 0:40:13.664836, loss: 1.2634
2023-04-12 03:07:34 - training - INFO - Epoch [2/5][571/649] lr: 2.8e-05, eta: 0:39:40.028462, loss: 1.5857
2023-04-12 03:07:38 - training - INFO - Epoch [2/5][581/649] lr: 2.8e-05, eta: 0:39:07.399584, loss: 1.2256
2023-04-12 03:07:42 - training - INFO - Epoch [2/5][591/649] lr: 2.8e-05, eta: 0:38:35.779548, loss: 1.2602
2023-04-12 03:07:46 - training - INFO - Epoch [2/5][601/649] lr: 2.8e-05, eta: 0:38:05.063780, loss: 0.9884
2023-04-12 03:07:49 - training - INFO - Epoch [2/5][611/649] lr: 2.8e-05, eta: 0:37:35.246604, loss: 1.4684
2023-04-12 03:07:53 - training - INFO - Epoch [2/5][621/649] lr: 2.8e-05, eta: 0:37:06.264576, loss: 1.0890
2023-04-12 03:07:57 - training - INFO - Epoch [2/5][631/649] lr: 2.7e-05, eta: 0:36:38.044636, loss: 1.2326
2023-04-12 03:08:00 - training - INFO - Epoch [2/5][641/649] lr: 2.7e-05, eta: 0:36:10.525140, loss: 0.9667
2023-04-12 03:08:30 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.4155, Validation Metrics: {'exact_match': 39.34807916181607, 'f1': 45.6774407731403}, Test Metrics: {'exact_match': 39.48896631823461, 'f1': 45.70220977886483}
2023-04-12 03:08:31 - training - INFO - Epoch [3/5][1/649] lr: 2.7e-05, eta: 21 days, 4:46:12.378544, loss: 1.5059
2023-04-12 03:08:34 - training - INFO - Epoch [3/5][11/649] lr: 2.7e-05, eta: 1 day, 22:24:40.421970, loss: 1.0979
2023-04-12 03:08:38 - training - INFO - Epoch [3/5][21/649] lr: 2.7e-05, eta: 1 day, 0:23:35.895544, loss: 0.9567
2023-04-12 03:08:42 - training - INFO - Epoch [3/5][31/649] lr: 2.7e-05, eta: 16:34:47.705026, loss: 0.6174
2023-04-12 03:08:46 - training - INFO - Epoch [3/5][41/649] lr: 2.7e-05, eta: 12:34:38.803044, loss: 1.2487
2023-04-12 03:08:49 - training - INFO - Epoch [3/5][51/649] lr: 2.7e-05, eta: 10:08:38.870490, loss: 0.7861
2023-04-12 03:08:53 - training - INFO - Epoch [3/5][61/649] lr: 2.6e-05, eta: 8:30:30.758192, loss: 1.4024
2023-04-12 03:08:57 - training - INFO - Epoch [3/5][71/649] lr: 2.6e-05, eta: 7:19:59.792610, loss: 1.1563
2023-04-12 03:09:00 - training - INFO - Epoch [3/5][81/649] lr: 2.6e-05, eta: 6:26:52.515144, loss: 1.1960
2023-04-12 03:09:04 - training - INFO - Epoch [3/5][91/649] lr: 2.6e-05, eta: 5:45:24.851996, loss: 1.0482
2023-04-12 03:09:08 - training - INFO - Epoch [3/5][101/649] lr: 2.6e-05, eta: 5:12:09.034368, loss: 1.1506
2023-04-12 03:09:12 - training - INFO - Epoch [3/5][111/649] lr: 2.6e-05, eta: 4:44:52.168458, loss: 1.1879
2023-04-12 03:09:15 - training - INFO - Epoch [3/5][121/649] lr: 2.6e-05, eta: 4:22:05.344404, loss: 0.9712
2023-04-12 03:09:19 - training - INFO - Epoch [3/5][131/649] lr: 2.5e-05, eta: 4:02:46.501044, loss: 1.1656
2023-04-12 03:09:23 - training - INFO - Epoch [3/5][141/649] lr: 2.5e-05, eta: 3:46:11.594368, loss: 1.4832
2023-04-12 03:09:26 - training - INFO - Epoch [3/5][151/649] lr: 2.5e-05, eta: 3:31:47.945978, loss: 1.2406
2023-04-12 03:09:30 - training - INFO - Epoch [3/5][161/649] lr: 2.5e-05, eta: 3:19:11.175396, loss: 1.3351
2023-04-12 03:09:34 - training - INFO - Epoch [3/5][171/649] lr: 2.5e-05, eta: 3:08:02.437646, loss: 0.8128
2023-04-12 03:09:38 - training - INFO - Epoch [3/5][181/649] lr: 2.5e-05, eta: 2:58:07.244256, loss: 1.0484
2023-04-12 03:09:41 - training - INFO - Epoch [3/5][191/649] lr: 2.5e-05, eta: 2:49:13.887282, loss: 0.9393
2023-04-12 03:09:45 - training - INFO - Epoch [3/5][201/649] lr: 2.4e-05, eta: 2:41:13.265816, loss: 0.7331
2023-04-12 03:09:49 - training - INFO - Epoch [3/5][211/649] lr: 2.4e-05, eta: 2:33:57.829146, loss: 1.0972
2023-04-12 03:09:52 - training - INFO - Epoch [3/5][221/649] lr: 2.4e-05, eta: 2:27:21.468384, loss: 1.5171
2023-04-12 03:09:56 - training - INFO - Epoch [3/5][231/649] lr: 2.4e-05, eta: 2:21:19.135500, loss: 0.5617
2023-04-12 03:10:00 - training - INFO - Epoch [3/5][241/649] lr: 2.4e-05, eta: 2:15:46.568628, loss: 0.8446
2023-04-12 03:10:03 - training - INFO - Epoch [3/5][251/649] lr: 2.4e-05, eta: 2:10:40.184208, loss: 1.0281
2023-04-12 03:10:07 - training - INFO - Epoch [3/5][261/649] lr: 2.4e-05, eta: 2:05:57.078472, loss: 1.0900
2023-04-12 03:10:11 - training - INFO - Epoch [3/5][271/649] lr: 2.3e-05, eta: 2:01:34.523110, loss: 1.2735
2023-04-12 03:10:15 - training - INFO - Epoch [3/5][281/649] lr: 2.3e-05, eta: 1:57:30.366024, loss: 1.3052
2023-04-12 03:10:18 - training - INFO - Epoch [3/5][291/649] lr: 2.3e-05, eta: 1:53:42.709054, loss: 0.8823
2023-04-12 03:10:22 - training - INFO - Epoch [3/5][301/649] lr: 2.3e-05, eta: 1:50:09.939456, loss: 1.4593
2023-04-12 03:10:26 - training - INFO - Epoch [3/5][311/649] lr: 2.3e-05, eta: 1:46:50.599290, loss: 0.9534
2023-04-12 03:10:29 - training - INFO - Epoch [3/5][321/649] lr: 2.3e-05, eta: 1:43:43.421132, loss: 1.5856
2023-04-12 03:10:33 - training - INFO - Epoch [3/5][331/649] lr: 2.3e-05, eta: 1:40:47.345522, loss: 1.4219
2023-04-12 03:10:37 - training - INFO - Epoch [3/5][341/649] lr: 2.2e-05, eta: 1:38:01.386984, loss: 1.5180
2023-04-12 03:10:41 - training - INFO - Epoch [3/5][351/649] lr: 2.2e-05, eta: 1:35:24.682174, loss: 1.2750
2023-04-12 03:10:44 - training - INFO - Epoch [3/5][361/649] lr: 2.2e-05, eta: 1:32:56.444720, loss: 1.2778
2023-04-12 03:10:48 - training - INFO - Epoch [3/5][371/649] lr: 2.2e-05, eta: 1:30:35.938206, loss: 1.3379
2023-04-12 03:10:52 - training - INFO - Epoch [3/5][381/649] lr: 2.2e-05, eta: 1:28:22.653040, loss: 1.4783
2023-04-12 03:10:55 - training - INFO - Epoch [3/5][391/649] lr: 2.2e-05, eta: 1:26:15.988714, loss: 0.8762
2023-04-12 03:10:59 - training - INFO - Epoch [3/5][401/649] lr: 2.2e-05, eta: 1:24:15.454584, loss: 1.0170
2023-04-12 03:11:03 - training - INFO - Epoch [3/5][411/649] lr: 2.1e-05, eta: 1:22:20.608556, loss: 1.0935
2023-04-12 03:11:06 - training - INFO - Epoch [3/5][421/649] lr: 2.1e-05, eta: 1:20:31.033744, loss: 1.2256
2023-04-12 03:11:10 - training - INFO - Epoch [3/5][431/649] lr: 2.1e-05, eta: 1:18:46.400028, loss: 1.1267
2023-04-12 03:11:14 - training - INFO - Epoch [3/5][441/649] lr: 2.1e-05, eta: 1:17:06.356052, loss: 1.7968
2023-04-12 03:11:18 - training - INFO - Epoch [3/5][451/649] lr: 2.1e-05, eta: 1:15:30.557614, loss: 0.7904
2023-04-12 03:11:21 - training - INFO - Epoch [3/5][461/649] lr: 2.1e-05, eta: 1:13:58.717728, loss: 1.2595
2023-04-12 03:11:25 - training - INFO - Epoch [3/5][471/649] lr: 2.1e-05, eta: 1:12:30.625092, loss: 1.2690
2023-04-12 03:11:29 - training - INFO - Epoch [3/5][481/649] lr: 2.1e-05, eta: 1:11:06.054340, loss: 1.1274
2023-04-12 03:11:32 - training - INFO - Epoch [3/5][491/649] lr: 2.0e-05, eta: 1:09:45.669654, loss: 1.3410
2023-04-12 03:11:36 - training - INFO - Epoch [3/5][501/649] lr: 2.0e-05, eta: 1:08:27.493600, loss: 0.8738
2023-04-12 03:11:40 - training - INFO - Epoch [3/5][511/649] lr: 2.0e-05, eta: 1:07:12.212560, loss: 1.2920
2023-04-12 03:11:44 - training - INFO - Epoch [3/5][521/649] lr: 2.0e-05, eta: 1:05:59.658156, loss: 0.9759
2023-04-12 03:11:47 - training - INFO - Epoch [3/5][531/649] lr: 2.0e-05, eta: 1:04:49.699372, loss: 1.1648
2023-04-12 03:11:51 - training - INFO - Epoch [3/5][541/649] lr: 2.0e-05, eta: 1:03:42.193232, loss: 1.4246
2023-04-12 03:11:55 - training - INFO - Epoch [3/5][551/649] lr: 2.0e-05, eta: 1:02:36.990438, loss: 1.1036
2023-04-12 03:11:58 - training - INFO - Epoch [3/5][561/649] lr: 1.9e-05, eta: 1:01:33.989200, loss: 1.0827
2023-04-12 03:12:02 - training - INFO - Epoch [3/5][571/649] lr: 1.9e-05, eta: 1:00:33.067536, loss: 1.2144
2023-04-12 03:12:06 - training - INFO - Epoch [3/5][581/649] lr: 1.9e-05, eta: 0:59:34.128960, loss: 1.2243
2023-04-12 03:12:09 - training - INFO - Epoch [3/5][591/649] lr: 1.9e-05, eta: 0:58:37.048952, loss: 1.0414
2023-04-12 03:12:13 - training - INFO - Epoch [3/5][601/649] lr: 1.9e-05, eta: 0:57:41.749540, loss: 1.1722
2023-04-12 03:12:17 - training - INFO - Epoch [3/5][611/649] lr: 1.9e-05, eta: 0:56:48.151038, loss: 1.2181
2023-04-12 03:12:20 - training - INFO - Epoch [3/5][621/649] lr: 1.9e-05, eta: 0:55:56.153728, loss: 1.0545
2023-04-12 03:12:24 - training - INFO - Epoch [3/5][631/649] lr: 1.8e-05, eta: 0:55:05.677470, loss: 1.0461
2023-04-12 03:12:28 - training - INFO - Epoch [3/5][641/649] lr: 1.8e-05, eta: 0:54:16.661352, loss: 1.1312
2023-04-12 03:12:58 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.1883, Validation Metrics: {'exact_match': 39.58090803259604, 'f1': 44.910736333902804}, Test Metrics: {'exact_match': 38.79210220673635, 'f1': 44.610511439779735}
2023-04-12 03:12:58 - training - INFO - Epoch [4/5][1/649] lr: 1.8e-05, eta: 31 days, 5:35:11.758832, loss: 1.0959
2023-04-12 03:13:02 - training - INFO - Epoch [4/5][11/649] lr: 1.8e-05, eta: 2 days, 20:14:05.484546, loss: 0.9746
2023-04-12 03:13:05 - training - INFO - Epoch [4/5][21/649] lr: 1.8e-05, eta: 1 day, 11:47:21.363248, loss: 0.9098
2023-04-12 03:13:09 - training - INFO - Epoch [4/5][31/649] lr: 1.8e-05, eta: 1 day, 0:16:32.397882, loss: 1.1687
2023-04-12 03:13:13 - training - INFO - Epoch [4/5][41/649] lr: 1.8e-05, eta: 18:22:40.693620, loss: 1.2177
2023-04-12 03:13:17 - training - INFO - Epoch [4/5][51/649] lr: 1.7e-05, eta: 14:47:33.536448, loss: 0.8655
2023-04-12 03:13:20 - training - INFO - Epoch [4/5][61/649] lr: 1.7e-05, eta: 12:22:57.152608, loss: 0.5253
2023-04-12 03:13:24 - training - INFO - Epoch [4/5][71/649] lr: 1.7e-05, eta: 10:39:03.729180, loss: 0.9445
2023-04-12 03:13:28 - training - INFO - Epoch [4/5][81/649] lr: 1.7e-05, eta: 9:20:48.662236, loss: 0.5557
2023-04-12 03:13:31 - training - INFO - Epoch [4/5][91/649] lr: 1.7e-05, eta: 8:19:44.579668, loss: 0.8919
2023-04-12 03:13:35 - training - INFO - Epoch [4/5][101/649] lr: 1.7e-05, eta: 7:30:45.238200, loss: 1.0056
2023-04-12 03:13:39 - training - INFO - Epoch [4/5][111/649] lr: 1.7e-05, eta: 6:50:34.807000, loss: 1.0781
2023-04-12 03:13:42 - training - INFO - Epoch [4/5][121/649] lr: 1.6e-05, eta: 6:17:02.227320, loss: 1.4226
2023-04-12 03:13:46 - training - INFO - Epoch [4/5][131/649] lr: 1.6e-05, eta: 5:48:36.298926, loss: 0.9910
2023-04-12 03:13:50 - training - INFO - Epoch [4/5][141/649] lr: 1.6e-05, eta: 5:24:11.799552, loss: 1.0169
2023-04-12 03:13:53 - training - INFO - Epoch [4/5][151/649] lr: 1.6e-05, eta: 5:03:00.851416, loss: 0.7254
2023-04-12 03:13:57 - training - INFO - Epoch [4/5][161/649] lr: 1.6e-05, eta: 4:44:27.300096, loss: 1.5984
2023-04-12 03:14:01 - training - INFO - Epoch [4/5][171/649] lr: 1.6e-05, eta: 4:28:03.924204, loss: 1.2304
2023-04-12 03:14:05 - training - INFO - Epoch [4/5][181/649] lr: 1.6e-05, eta: 4:13:28.635856, loss: 1.3487
2023-04-12 03:14:08 - training - INFO - Epoch [4/5][191/649] lr: 1.5e-05, eta: 4:00:24.506208, loss: 0.8415
2023-04-12 03:14:12 - training - INFO - Epoch [4/5][201/649] lr: 1.5e-05, eta: 3:48:38.023432, loss: 1.0635
2023-04-12 03:14:16 - training - INFO - Epoch [4/5][211/649] lr: 1.5e-05, eta: 3:37:58.148020, loss: 1.0164
2023-04-12 03:14:19 - training - INFO - Epoch [4/5][221/649] lr: 1.5e-05, eta: 3:28:15.863520, loss: 0.8554
2023-04-12 03:14:23 - training - INFO - Epoch [4/5][231/649] lr: 1.5e-05, eta: 3:19:23.720362, loss: 0.9042
2023-04-12 03:14:27 - training - INFO - Epoch [4/5][241/649] lr: 1.5e-05, eta: 3:11:15.442216, loss: 0.8538
2023-04-12 03:14:31 - training - INFO - Epoch [4/5][251/649] lr: 1.5e-05, eta: 3:03:45.770268, loss: 1.1422
2023-04-12 03:14:34 - training - INFO - Epoch [4/5][261/649] lr: 1.5e-05, eta: 2:56:50.268480, loss: 1.2959
2023-04-12 03:14:38 - training - INFO - Epoch [4/5][271/649] lr: 1.4e-05, eta: 2:50:25.159216, loss: 1.4220
2023-04-12 03:14:42 - training - INFO - Epoch [4/5][281/649] lr: 1.4e-05, eta: 2:44:27.164892, loss: 1.4857
2023-04-12 03:14:45 - training - INFO - Epoch [4/5][291/649] lr: 1.4e-05, eta: 2:38:53.488510, loss: 0.7083
2023-04-12 03:14:49 - training - INFO - Epoch [4/5][301/649] lr: 1.4e-05, eta: 2:33:41.762048, loss: 0.8971
2023-04-12 03:14:53 - training - INFO - Epoch [4/5][311/649] lr: 1.4e-05, eta: 2:28:49.857852, loss: 1.2541
2023-04-12 03:14:56 - training - INFO - Epoch [4/5][321/649] lr: 1.4e-05, eta: 2:24:15.867492, loss: 1.1717
2023-04-12 03:15:00 - training - INFO - Epoch [4/5][331/649] lr: 1.4e-05, eta: 2:19:58.235420, loss: 0.8510
2023-04-12 03:15:04 - training - INFO - Epoch [4/5][341/649] lr: 1.3e-05, eta: 2:15:55.486152, loss: 1.6388
2023-04-12 03:15:08 - training - INFO - Epoch [4/5][351/649] lr: 1.3e-05, eta: 2:12:06.425798, loss: 1.0425
2023-04-12 03:15:11 - training - INFO - Epoch [4/5][361/649] lr: 1.3e-05, eta: 2:08:29.791432, loss: 0.8096
2023-04-12 03:15:15 - training - INFO - Epoch [4/5][371/649] lr: 1.3e-05, eta: 2:05:04.629036, loss: 1.9253
2023-04-12 03:15:19 - training - INFO - Epoch [4/5][381/649] lr: 1.3e-05, eta: 2:01:50.079328, loss: 0.7568
2023-04-12 03:15:22 - training - INFO - Epoch [4/5][391/649] lr: 1.3e-05, eta: 1:58:45.282130, loss: 1.1650
2023-04-12 03:15:26 - training - INFO - Epoch [4/5][401/649] lr: 1.3e-05, eta: 1:55:49.490328, loss: 0.7675
2023-04-12 03:15:30 - training - INFO - Epoch [4/5][411/649] lr: 1.2e-05, eta: 1:53:02.272120, loss: 0.7768
2023-04-12 03:15:33 - training - INFO - Epoch [4/5][421/649] lr: 1.2e-05, eta: 1:50:22.635824, loss: 1.4260
2023-04-12 03:15:37 - training - INFO - Epoch [4/5][431/649] lr: 1.2e-05, eta: 1:47:50.297736, loss: 1.2052
2023-04-12 03:15:41 - training - INFO - Epoch [4/5][441/649] lr: 1.2e-05, eta: 1:45:24.693988, loss: 0.8971
2023-04-12 03:15:45 - training - INFO - Epoch [4/5][451/649] lr: 1.2e-05, eta: 1:43:05.393522, loss: 1.0732
2023-04-12 03:15:48 - training - INFO - Epoch [4/5][461/649] lr: 1.2e-05, eta: 1:40:51.934368, loss: 1.2544
2023-04-12 03:15:52 - training - INFO - Epoch [4/5][471/649] lr: 1.2e-05, eta: 1:38:43.999056, loss: 0.8880
2023-04-12 03:15:56 - training - INFO - Epoch [4/5][481/649] lr: 1.1e-05, eta: 1:36:41.196524, loss: 1.2919
2023-04-12 03:15:59 - training - INFO - Epoch [4/5][491/649] lr: 1.1e-05, eta: 1:34:43.281084, loss: 0.7371
2023-04-12 03:16:03 - training - INFO - Epoch [4/5][501/649] lr: 1.1e-05, eta: 1:32:49.897424, loss: 0.9706
2023-04-12 03:16:07 - training - INFO - Epoch [4/5][511/649] lr: 1.1e-05, eta: 1:31:00.817782, loss: 1.4212
2023-04-12 03:16:11 - training - INFO - Epoch [4/5][521/649] lr: 1.1e-05, eta: 1:29:15.789876, loss: 0.8991
2023-04-12 03:16:14 - training - INFO - Epoch [4/5][531/649] lr: 1.1e-05, eta: 1:27:34.567258, loss: 0.7587
2023-04-12 03:16:18 - training - INFO - Epoch [4/5][541/649] lr: 1.1e-05, eta: 1:25:56.960640, loss: 1.0866
2023-04-12 03:16:22 - training - INFO - Epoch [4/5][551/649] lr: 1.0e-05, eta: 1:24:22.756074, loss: 1.2953
2023-04-12 03:16:25 - training - INFO - Epoch [4/5][561/649] lr: 1.0e-05, eta: 1:22:51.774500, loss: 0.6847
2023-04-12 03:16:29 - training - INFO - Epoch [4/5][571/649] lr: 1.0e-05, eta: 1:21:23.855102, loss: 1.3416
2023-04-12 03:16:33 - training - INFO - Epoch [4/5][581/649] lr: 1.0e-05, eta: 1:19:58.828368, loss: 1.2501
2023-04-12 03:16:36 - training - INFO - Epoch [4/5][591/649] lr: 9.9e-06, eta: 1:18:36.550792, loss: 1.0625
2023-04-12 03:16:40 - training - INFO - Epoch [4/5][601/649] lr: 9.8e-06, eta: 1:17:16.901780, loss: 1.1126
2023-04-12 03:16:44 - training - INFO - Epoch [4/5][611/649] lr: 9.6e-06, eta: 1:15:59.749008, loss: 0.7965
2023-04-12 03:16:48 - training - INFO - Epoch [4/5][621/649] lr: 9.5e-06, eta: 1:14:44.964416, loss: 1.0883
2023-04-12 03:16:51 - training - INFO - Epoch [4/5][631/649] lr: 9.3e-06, eta: 1:13:32.424158, loss: 0.9467
2023-04-12 03:16:55 - training - INFO - Epoch [4/5][641/649] lr: 9.2e-06, eta: 1:12:22.026780, loss: 0.6876
2023-04-12 03:17:25 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 1.0338, Validation Metrics: {'exact_match': 38.53317811408615, 'f1': 43.64745986587387}, Test Metrics: {'exact_match': 38.21138211382114, 'f1': 43.59358089323246}
2023-04-12 03:17:25 - training - INFO - Epoch [5/5][1/649] lr: 9.1e-06, eta: 41 days, 6:27:06.013428, loss: 1.0769
2023-04-12 03:17:29 - training - INFO - Epoch [5/5][11/649] lr: 8.9e-06, eta: 3 days, 18:03:54.317022, loss: 0.5746
2023-04-12 03:17:33 - training - INFO - Epoch [5/5][21/649] lr: 8.8e-06, eta: 1 day, 23:11:20.052576, loss: 1.0520
2023-04-12 03:17:36 - training - INFO - Epoch [5/5][31/649] lr: 8.6e-06, eta: 1 day, 7:58:27.073422, loss: 0.7764
2023-04-12 03:17:40 - training - INFO - Epoch [5/5][41/649] lr: 8.5e-06, eta: 1 day, 0:10:50.892168, loss: 1.1541
2023-04-12 03:17:44 - training - INFO - Epoch [5/5][51/649] lr: 8.4e-06, eta: 19:26:36.640954, loss: 0.7773
2023-04-12 03:17:48 - training - INFO - Epoch [5/5][61/649] lr: 8.2e-06, eta: 16:15:32.825200, loss: 0.8604
2023-04-12 03:17:51 - training - INFO - Epoch [5/5][71/649] lr: 8.1e-06, eta: 13:58:16.460904, loss: 1.0286
2023-04-12 03:17:55 - training - INFO - Epoch [5/5][81/649] lr: 7.9e-06, eta: 12:14:52.924988, loss: 0.5366
2023-04-12 03:17:59 - training - INFO - Epoch [5/5][91/649] lr: 7.8e-06, eta: 10:54:11.905326, loss: 1.1621
2023-04-12 03:18:02 - training - INFO - Epoch [5/5][101/649] lr: 7.7e-06, eta: 9:49:28.808424, loss: 1.0945
2023-04-12 03:18:06 - training - INFO - Epoch [5/5][111/649] lr: 7.5e-06, eta: 8:56:24.650608, loss: 1.0360
2023-04-12 03:18:10 - training - INFO - Epoch [5/5][121/649] lr: 7.4e-06, eta: 8:12:06.248576, loss: 0.9268
2023-04-12 03:18:14 - training - INFO - Epoch [5/5][131/649] lr: 7.2e-06, eta: 7:34:33.140676, loss: 1.1841
2023-04-12 03:18:17 - training - INFO - Epoch [5/5][141/649] lr: 7.1e-06, eta: 7:02:19.122208, loss: 0.7413
2023-04-12 03:18:21 - training - INFO - Epoch [5/5][151/649] lr: 7.0e-06, eta: 6:34:20.675038, loss: 1.4016
2023-04-12 03:18:25 - training - INFO - Epoch [5/5][161/649] lr: 6.8e-06, eta: 6:09:50.308284, loss: 1.1015
2023-04-12 03:18:28 - training - INFO - Epoch [5/5][171/649] lr: 6.7e-06, eta: 5:48:11.537244, loss: 0.7798
2023-04-12 03:18:32 - training - INFO - Epoch [5/5][181/649] lr: 6.5e-06, eta: 5:28:55.806160, loss: 0.8818
2023-04-12 03:18:36 - training - INFO - Epoch [5/5][191/649] lr: 6.4e-06, eta: 5:11:40.732278, loss: 0.6820
2023-04-12 03:18:39 - training - INFO - Epoch [5/5][201/649] lr: 6.3e-06, eta: 4:56:08.321128, loss: 0.9362
2023-04-12 03:18:43 - training - INFO - Epoch [5/5][211/649] lr: 6.1e-06, eta: 4:42:03.937196, loss: 0.6720
2023-04-12 03:18:47 - training - INFO - Epoch [5/5][221/649] lr: 6.0e-06, eta: 4:29:15.583920, loss: 0.9593
2023-04-12 03:18:51 - training - INFO - Epoch [5/5][231/649] lr: 5.8e-06, eta: 4:17:33.441080, loss: 1.3611
2023-04-12 03:18:54 - training - INFO - Epoch [5/5][241/649] lr: 5.7e-06, eta: 4:06:49.257384, loss: 1.0047
2023-04-12 03:18:58 - training - INFO - Epoch [5/5][251/649] lr: 5.6e-06, eta: 3:56:56.155710, loss: 1.0494
2023-04-12 03:19:02 - training - INFO - Epoch [5/5][261/649] lr: 5.4e-06, eta: 3:47:48.209016, loss: 0.8260
2023-04-12 03:19:05 - training - INFO - Epoch [5/5][271/649] lr: 5.3e-06, eta: 3:39:20.428814, loss: 0.7040
2023-04-12 03:19:09 - training - INFO - Epoch [5/5][281/649] lr: 5.1e-06, eta: 3:31:28.510536, loss: 0.8705
2023-04-12 03:19:13 - training - INFO - Epoch [5/5][291/649] lr: 5.0e-06, eta: 3:24:08.740322, loss: 0.4428
2023-04-12 03:19:17 - training - INFO - Epoch [5/5][301/649] lr: 4.9e-06, eta: 3:17:17.956480, loss: 0.5645
2023-04-12 03:19:20 - training - INFO - Epoch [5/5][311/649] lr: 4.7e-06, eta: 3:10:53.552622, loss: 0.9142
2023-04-12 03:19:24 - training - INFO - Epoch [5/5][321/649] lr: 4.6e-06, eta: 3:04:52.784648, loss: 0.7232
2023-04-12 03:19:28 - training - INFO - Epoch [5/5][331/649] lr: 4.4e-06, eta: 2:59:13.647846, loss: 0.8093
2023-04-12 03:19:31 - training - INFO - Epoch [5/5][341/649] lr: 4.3e-06, eta: 2:53:54.109752, loss: 0.9000
2023-04-12 03:19:35 - training - INFO - Epoch [5/5][351/649] lr: 4.2e-06, eta: 2:48:52.669592, loss: 0.8354
2023-04-12 03:19:39 - training - INFO - Epoch [5/5][361/649] lr: 4.0e-06, eta: 2:44:07.775616, loss: 0.5858
2023-04-12 03:19:43 - training - INFO - Epoch [5/5][371/649] lr: 3.9e-06, eta: 2:39:37.866534, loss: 1.0640
2023-04-12 03:19:46 - training - INFO - Epoch [5/5][381/649] lr: 3.7e-06, eta: 2:35:21.881808, loss: 0.9417
2023-04-12 03:19:50 - training - INFO - Epoch [5/5][391/649] lr: 3.6e-06, eta: 2:31:18.808028, loss: 0.8265
2023-04-12 03:19:54 - training - INFO - Epoch [5/5][401/649] lr: 3.5e-06, eta: 2:27:27.664092, loss: 0.7924
2023-04-12 03:19:57 - training - INFO - Epoch [5/5][411/649] lr: 3.3e-06, eta: 2:23:47.580208, loss: 0.6603
2023-04-12 03:20:01 - training - INFO - Epoch [5/5][421/649] lr: 3.2e-06, eta: 2:20:17.790496, loss: 0.9363
2023-04-12 03:20:05 - training - INFO - Epoch [5/5][431/649] lr: 3.0e-06, eta: 2:16:57.572244, loss: 1.0542
2023-04-12 03:20:09 - training - INFO - Epoch [5/5][441/649] lr: 2.9e-06, eta: 2:13:46.276152, loss: 0.7847
2023-04-12 03:20:12 - training - INFO - Epoch [5/5][451/649] lr: 2.8e-06, eta: 2:10:43.300036, loss: 0.5295
2023-04-12 03:20:16 - training - INFO - Epoch [5/5][461/649] lr: 2.6e-06, eta: 2:07:48.090912, loss: 1.1376
2023-04-12 03:20:20 - training - INFO - Epoch [5/5][471/649] lr: 2.5e-06, eta: 2:05:00.158116, loss: 1.0315
2023-04-12 03:20:23 - training - INFO - Epoch [5/5][481/649] lr: 2.4e-06, eta: 2:02:19.050192, loss: 0.6092
2023-04-12 03:20:27 - training - INFO - Epoch [5/5][491/649] lr: 2.2e-06, eta: 1:59:44.368062, loss: 1.1274
2023-04-12 03:20:31 - training - INFO - Epoch [5/5][501/649] lr: 2.1e-06, eta: 1:57:15.747712, loss: 0.6980
2023-04-12 03:20:34 - training - INFO - Epoch [5/5][511/649] lr: 1.9e-06, eta: 1:54:52.815898, loss: 0.6095
2023-04-12 03:20:38 - training - INFO - Epoch [5/5][521/649] lr: 1.8e-06, eta: 1:52:35.236704, loss: 0.7541
2023-04-12 03:20:42 - training - INFO - Epoch [5/5][531/649] lr: 1.7e-06, eta: 1:50:22.686516, loss: 1.0635
2023-04-12 03:20:46 - training - INFO - Epoch [5/5][541/649] lr: 1.5e-06, eta: 1:48:14.905248, loss: 0.8702
2023-04-12 03:20:49 - training - INFO - Epoch [5/5][551/649] lr: 1.4e-06, eta: 1:46:11.641362, loss: 0.7845
2023-04-12 03:20:53 - training - INFO - Epoch [5/5][561/649] lr: 1.2e-06, eta: 1:44:12.673240, loss: 1.4932
2023-04-12 03:20:57 - training - INFO - Epoch [5/5][571/649] lr: 1.1e-06, eta: 1:42:17.715094, loss: 0.6758
2023-04-12 03:21:01 - training - INFO - Epoch [5/5][581/649] lr: 9.5e-07, eta: 1:40:26.519448, loss: 0.7508
2023-04-12 03:21:04 - training - INFO - Epoch [5/5][591/649] lr: 8.1e-07, eta: 1:38:38.993264, loss: 0.6248
2023-04-12 03:21:08 - training - INFO - Epoch [5/5][601/649] lr: 6.7e-07, eta: 1:36:54.975640, loss: 0.8254
2023-04-12 03:21:12 - training - INFO - Epoch [5/5][611/649] lr: 5.3e-07, eta: 1:35:14.297058, loss: 0.7155
2023-04-12 03:21:15 - training - INFO - Epoch [5/5][621/649] lr: 3.9e-07, eta: 1:33:36.682496, loss: 1.2196
2023-04-12 03:21:19 - training - INFO - Epoch [5/5][631/649] lr: 2.5e-07, eta: 1:32:02.038404, loss: 1.0914
2023-04-12 03:21:23 - training - INFO - Epoch [5/5][641/649] lr: 1.1e-07, eta: 1:30:30.240984, loss: 1.0315
2023-04-12 03:21:54 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.9400, Validation Metrics: {'exact_match': 37.019790454016295, 'f1': 41.8859381771112}, Test Metrics: {'exact_match': 37.97909407665505, 'f1': 42.45476100876796}
2023-04-12 03:22:08 - training - INFO - Final Test - Train Loss: 0.9400, Test Metrics: {'exact_match': 37.97909407665505, 'f1': 42.45476100876796}
