2023-04-11 23:52:54 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-1380cc367820a3f3/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'csarron/bert-base-uncased-squad-v1'}, 'data': {'task_type': 'factoid', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/bert_factoid_squad'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 515.12it/s]
Map:   0%|          | 0/4429 [00:00<?, ? examples/s]Map:  23%|██▎       | 1000/4429 [00:00<00:02, 1314.60 examples/s]Map:  45%|████▌     | 2000/4429 [00:01<00:01, 1573.07 examples/s]Map:  68%|██████▊   | 3000/4429 [00:01<00:00, 1651.32 examples/s]Map:  90%|█████████ | 4000/4429 [00:02<00:00, 1686.53 examples/s]Map: 100%|██████████| 4429/4429 [00:02<00:00, 1701.28 examples/s]                                                                 Map:   0%|          | 0/553 [00:00<?, ? examples/s]Map: 100%|██████████| 553/553 [00:00<00:00, 1370.23 examples/s]                                                               Map:   0%|          | 0/555 [00:00<?, ? examples/s]Map: 100%|██████████| 555/555 [00:00<00:00, 1378.94 examples/s]                                                               2023-04-11 23:53:24 - training - INFO - First Test - Val Metrics:{'exact_match': 39.78300180831826, 'f1': 51.749982890494245} Test Metrics: {'exact_match': 39.27927927927928, 'f1': 53.06691851428693}
2023-04-11 23:53:24 - training - INFO - Epoch [1/5][1/415] lr: 4.5e-05, eta: 10:47:32.679614, loss: 4.7401
2023-04-11 23:53:28 - training - INFO - Epoch [1/5][11/415] lr: 4.5e-05, eta: 1:10:09.505296, loss: 2.3077
2023-04-11 23:53:32 - training - INFO - Epoch [1/5][21/415] lr: 4.5e-05, eta: 0:42:37.901658, loss: 1.7733
2023-04-11 23:53:35 - training - INFO - Epoch [1/5][31/415] lr: 4.5e-05, eta: 0:32:48.815548, loss: 1.7542
2023-04-11 23:53:39 - training - INFO - Epoch [1/5][41/415] lr: 4.5e-05, eta: 0:27:45.498186, loss: 1.9068
2023-04-11 23:53:43 - training - INFO - Epoch [1/5][51/415] lr: 4.4e-05, eta: 0:24:40.084408, loss: 2.5510
2023-04-11 23:53:47 - training - INFO - Epoch [1/5][61/415] lr: 4.4e-05, eta: 0:22:34.050466, loss: 1.2775
2023-04-11 23:53:50 - training - INFO - Epoch [1/5][71/415] lr: 4.4e-05, eta: 0:21:02.025012, loss: 1.9398
2023-04-11 23:53:54 - training - INFO - Epoch [1/5][81/415] lr: 4.4e-05, eta: 0:19:52.079002, loss: 1.7930
2023-04-11 23:53:58 - training - INFO - Epoch [1/5][91/415] lr: 4.3e-05, eta: 0:18:56.691136, loss: 1.4906
2023-04-11 23:54:01 - training - INFO - Epoch [1/5][101/415] lr: 4.3e-05, eta: 0:18:11.276550, loss: 1.7262
2023-04-11 23:54:05 - training - INFO - Epoch [1/5][111/415] lr: 4.3e-05, eta: 0:17:33.587800, loss: 1.6226
2023-04-11 23:54:09 - training - INFO - Epoch [1/5][121/415] lr: 4.3e-05, eta: 0:17:01.521890, loss: 1.6235
2023-04-11 23:54:12 - training - INFO - Epoch [1/5][131/415] lr: 4.3e-05, eta: 0:16:33.765024, loss: 1.4973
2023-04-11 23:54:16 - training - INFO - Epoch [1/5][141/415] lr: 4.2e-05, eta: 0:16:09.338206, loss: 1.5867
2023-04-11 23:54:20 - training - INFO - Epoch [1/5][151/415] lr: 4.2e-05, eta: 0:15:47.625796, loss: 1.4406
2023-04-11 23:54:24 - training - INFO - Epoch [1/5][161/415] lr: 4.2e-05, eta: 0:15:28.129224, loss: 1.7815
2023-04-11 23:54:27 - training - INFO - Epoch [1/5][171/415] lr: 4.2e-05, eta: 0:15:10.532784, loss: 1.2796
2023-04-11 23:54:31 - training - INFO - Epoch [1/5][181/415] lr: 4.1e-05, eta: 0:14:54.441500, loss: 1.3877
2023-04-11 23:54:35 - training - INFO - Epoch [1/5][191/415] lr: 4.1e-05, eta: 0:14:39.615108, loss: 1.2844
2023-04-11 23:54:38 - training - INFO - Epoch [1/5][201/415] lr: 4.1e-05, eta: 0:14:25.913558, loss: 1.1296
2023-04-11 23:54:42 - training - INFO - Epoch [1/5][211/415] lr: 4.1e-05, eta: 0:14:13.175168, loss: 1.3801
2023-04-11 23:54:46 - training - INFO - Epoch [1/5][221/415] lr: 4.1e-05, eta: 0:14:01.254354, loss: 1.5775
2023-04-11 23:54:49 - training - INFO - Epoch [1/5][231/415] lr: 4.0e-05, eta: 0:13:50.043408, loss: 1.4301
2023-04-11 23:54:53 - training - INFO - Epoch [1/5][241/415] lr: 4.0e-05, eta: 0:13:39.484386, loss: 1.4517
2023-04-11 23:54:57 - training - INFO - Epoch [1/5][251/415] lr: 4.0e-05, eta: 0:13:29.451072, loss: 1.1892
2023-04-11 23:55:01 - training - INFO - Epoch [1/5][261/415] lr: 4.0e-05, eta: 0:13:19.935906, loss: 1.3845
2023-04-11 23:55:04 - training - INFO - Epoch [1/5][271/415] lr: 3.9e-05, eta: 0:13:10.797832, loss: 1.5522
2023-04-11 23:55:08 - training - INFO - Epoch [1/5][281/415] lr: 3.9e-05, eta: 0:13:02.051244, loss: 1.4143
2023-04-11 23:55:12 - training - INFO - Epoch [1/5][291/415] lr: 3.9e-05, eta: 0:12:53.683336, loss: 1.5127
2023-04-11 23:55:15 - training - INFO - Epoch [1/5][301/415] lr: 3.9e-05, eta: 0:12:45.619372, loss: 1.4960
2023-04-11 23:55:19 - training - INFO - Epoch [1/5][311/415] lr: 3.9e-05, eta: 0:12:37.858500, loss: 2.0784
2023-04-11 23:55:23 - training - INFO - Epoch [1/5][321/415] lr: 3.8e-05, eta: 0:12:30.345414, loss: 0.9133
2023-04-11 23:55:27 - training - INFO - Epoch [1/5][331/415] lr: 3.8e-05, eta: 0:12:23.039920, loss: 0.9278
2023-04-11 23:55:30 - training - INFO - Epoch [1/5][341/415] lr: 3.8e-05, eta: 0:12:15.958152, loss: 1.4861
2023-04-11 23:55:34 - training - INFO - Epoch [1/5][351/415] lr: 3.8e-05, eta: 0:12:09.050292, loss: 1.3859
2023-04-11 23:55:38 - training - INFO - Epoch [1/5][361/415] lr: 3.8e-05, eta: 0:12:02.320736, loss: 0.9262
2023-04-11 23:55:41 - training - INFO - Epoch [1/5][371/415] lr: 3.7e-05, eta: 0:11:55.753272, loss: 1.5096
2023-04-11 23:55:45 - training - INFO - Epoch [1/5][381/415] lr: 3.7e-05, eta: 0:11:49.333702, loss: 1.4871
2023-04-11 23:55:49 - training - INFO - Epoch [1/5][391/415] lr: 3.7e-05, eta: 0:11:43.056528, loss: 1.2229
2023-04-11 23:55:52 - training - INFO - Epoch [1/5][401/415] lr: 3.7e-05, eta: 0:11:36.911310, loss: 1.8302
2023-04-11 23:55:56 - training - INFO - Epoch [1/5][411/415] lr: 3.6e-05, eta: 0:11:30.886144, loss: 1.5642
2023-04-11 23:56:15 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 1.5235, Validation Metrics: {'exact_match': 78.48101265822785, 'f1': 81.88101072726157}, Test Metrics: {'exact_match': 80.0, 'f1': 84.09044286282139}
2023-04-11 23:56:15 - training - INFO - Epoch [2/5][1/415] lr: 3.6e-05, eta: 4 days, 13:12:05.949212, loss: 0.9515
2023-04-11 23:56:19 - training - INFO - Epoch [2/5][11/415] lr: 3.6e-05, eta: 10:04:20.360256, loss: 0.6570
2023-04-11 23:56:22 - training - INFO - Epoch [2/5][21/415] lr: 3.6e-05, eta: 5:21:03.619752, loss: 0.6427
2023-04-11 23:56:26 - training - INFO - Epoch [2/5][31/415] lr: 3.6e-05, eta: 3:40:30.376628, loss: 1.0237
2023-04-11 23:56:30 - training - INFO - Epoch [2/5][41/415] lr: 3.5e-05, eta: 2:48:58.273668, loss: 0.8080
2023-04-11 23:56:34 - training - INFO - Epoch [2/5][51/415] lr: 3.5e-05, eta: 2:17:37.239936, loss: 0.9893
2023-04-11 23:56:37 - training - INFO - Epoch [2/5][61/415] lr: 3.5e-05, eta: 1:56:31.705728, loss: 0.5862
2023-04-11 23:56:41 - training - INFO - Epoch [2/5][71/415] lr: 3.5e-05, eta: 1:41:26.242188, loss: 0.7003
2023-04-11 23:56:45 - training - INFO - Epoch [2/5][81/415] lr: 3.5e-05, eta: 1:29:59.460876, loss: 1.0859
2023-04-11 23:56:49 - training - INFO - Epoch [2/5][91/415] lr: 3.4e-05, eta: 1:21:02.752256, loss: 1.1561
2023-04-11 23:56:52 - training - INFO - Epoch [2/5][101/415] lr: 3.4e-05, eta: 1:13:51.691194, loss: 0.6646
2023-04-11 23:56:56 - training - INFO - Epoch [2/5][111/415] lr: 3.4e-05, eta: 1:07:57.548780, loss: 0.8712
2023-04-11 23:57:00 - training - INFO - Epoch [2/5][121/415] lr: 3.4e-05, eta: 1:03:01.484362, loss: 1.3173
2023-04-11 23:57:03 - training - INFO - Epoch [2/5][131/415] lr: 3.3e-05, eta: 0:58:50.179584, loss: 1.0051
2023-04-11 23:57:07 - training - INFO - Epoch [2/5][141/415] lr: 3.3e-05, eta: 0:55:13.763950, loss: 1.4896
2023-04-11 23:57:11 - training - INFO - Epoch [2/5][151/415] lr: 3.3e-05, eta: 0:52:05.551468, loss: 0.4680
2023-04-11 23:57:15 - training - INFO - Epoch [2/5][161/415] lr: 3.3e-05, eta: 0:49:20.286186, loss: 0.6779
2023-04-11 23:57:18 - training - INFO - Epoch [2/5][171/415] lr: 3.3e-05, eta: 0:46:53.870192, loss: 0.6398
2023-04-11 23:57:22 - training - INFO - Epoch [2/5][181/415] lr: 3.2e-05, eta: 0:44:43.254422, loss: 0.7421
2023-04-11 23:57:26 - training - INFO - Epoch [2/5][191/415] lr: 3.2e-05, eta: 0:42:45.921336, loss: 0.9758
2023-04-11 23:57:29 - training - INFO - Epoch [2/5][201/415] lr: 3.2e-05, eta: 0:40:59.894856, loss: 0.9555
2023-04-11 23:57:33 - training - INFO - Epoch [2/5][211/415] lr: 3.2e-05, eta: 0:39:23.596736, loss: 1.1977
2023-04-11 23:57:37 - training - INFO - Epoch [2/5][221/415] lr: 3.1e-05, eta: 0:37:55.632972, loss: 1.1006
2023-04-11 23:57:40 - training - INFO - Epoch [2/5][231/415] lr: 3.1e-05, eta: 0:36:34.953768, loss: 0.5365
2023-04-11 23:57:44 - training - INFO - Epoch [2/5][241/415] lr: 3.1e-05, eta: 0:35:20.665204, loss: 0.4806
2023-04-11 23:57:48 - training - INFO - Epoch [2/5][251/415] lr: 3.1e-05, eta: 0:34:12.001824, loss: 0.5805
2023-04-11 23:57:52 - training - INFO - Epoch [2/5][261/415] lr: 3.1e-05, eta: 0:33:08.310888, loss: 1.0689
2023-04-11 23:57:55 - training - INFO - Epoch [2/5][271/415] lr: 3.0e-05, eta: 0:32:09.040652, loss: 1.1112
2023-04-11 23:57:59 - training - INFO - Epoch [2/5][281/415] lr: 3.0e-05, eta: 0:31:13.723566, loss: 0.5788
2023-04-11 23:58:03 - training - INFO - Epoch [2/5][291/415] lr: 3.0e-05, eta: 0:30:22.013472, loss: 0.8678
2023-04-11 23:58:06 - training - INFO - Epoch [2/5][301/415] lr: 3.0e-05, eta: 0:29:33.457156, loss: 1.4191
2023-04-11 23:58:10 - training - INFO - Epoch [2/5][311/415] lr: 3.0e-05, eta: 0:28:47.790372, loss: 0.3466
2023-04-11 23:58:14 - training - INFO - Epoch [2/5][321/415] lr: 2.9e-05, eta: 0:28:04.709984, loss: 0.6113
2023-04-11 23:58:18 - training - INFO - Epoch [2/5][331/415] lr: 2.9e-05, eta: 0:27:24.046128, loss: 1.0689
2023-04-11 23:58:21 - training - INFO - Epoch [2/5][341/415] lr: 2.9e-05, eta: 0:26:45.595566, loss: 0.7904
2023-04-11 23:58:25 - training - INFO - Epoch [2/5][351/415] lr: 2.9e-05, eta: 0:26:09.058948, loss: 0.8290
2023-04-11 23:58:29 - training - INFO - Epoch [2/5][361/415] lr: 2.8e-05, eta: 0:25:34.333378, loss: 0.5909
2023-04-11 23:58:32 - training - INFO - Epoch [2/5][371/415] lr: 2.8e-05, eta: 0:25:01.302384, loss: 0.7838
2023-04-11 23:58:36 - training - INFO - Epoch [2/5][381/415] lr: 2.8e-05, eta: 0:24:29.804182, loss: 1.5993
2023-04-11 23:58:40 - training - INFO - Epoch [2/5][391/415] lr: 2.8e-05, eta: 0:23:59.841892, loss: 0.7773
2023-04-11 23:58:44 - training - INFO - Epoch [2/5][401/415] lr: 2.8e-05, eta: 0:23:31.101648, loss: 0.6824
2023-04-11 23:58:47 - training - INFO - Epoch [2/5][411/415] lr: 2.7e-05, eta: 0:23:03.561088, loss: 1.0947
2023-04-11 23:59:06 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 0.9448, Validation Metrics: {'exact_match': 79.20433996383363, 'f1': 81.47933132338487}, Test Metrics: {'exact_match': 80.18018018018019, 'f1': 82.99676339150024}
2023-04-11 23:59:06 - training - INFO - Epoch [3/5][1/415] lr: 2.7e-05, eta: 8 days, 15:48:00.758024, loss: 0.5436
2023-04-11 23:59:10 - training - INFO - Epoch [3/5][11/415] lr: 2.7e-05, eta: 18:59:33.366384, loss: 0.7136
2023-04-11 23:59:14 - training - INFO - Epoch [3/5][21/415] lr: 2.7e-05, eta: 10:00:03.243224, loss: 0.5702
2023-04-11 23:59:17 - training - INFO - Epoch [3/5][31/415] lr: 2.7e-05, eta: 6:48:35.290408, loss: 0.3565
2023-04-11 23:59:21 - training - INFO - Epoch [3/5][41/415] lr: 2.6e-05, eta: 5:10:29.129376, loss: 1.1039
2023-04-11 23:59:25 - training - INFO - Epoch [3/5][51/415] lr: 2.6e-05, eta: 4:10:49.879064, loss: 0.9406
2023-04-11 23:59:28 - training - INFO - Epoch [3/5][61/415] lr: 2.6e-05, eta: 3:30:42.917224, loss: 0.7958
2023-04-11 23:59:32 - training - INFO - Epoch [3/5][71/415] lr: 2.6e-05, eta: 3:01:52.948332, loss: 0.9214
2023-04-11 23:59:36 - training - INFO - Epoch [3/5][81/415] lr: 2.5e-05, eta: 2:40:09.143826, loss: 0.8483
2023-04-11 23:59:40 - training - INFO - Epoch [3/5][91/415] lr: 2.5e-05, eta: 2:23:11.021568, loss: 0.6041
2023-04-11 23:59:43 - training - INFO - Epoch [3/5][101/415] lr: 2.5e-05, eta: 2:09:33.856776, loss: 1.0219
2023-04-11 23:59:47 - training - INFO - Epoch [3/5][111/415] lr: 2.5e-05, eta: 1:58:23.316640, loss: 0.9178
2023-04-11 23:59:51 - training - INFO - Epoch [3/5][121/415] lr: 2.5e-05, eta: 1:49:02.990494, loss: 0.5047
2023-04-11 23:59:54 - training - INFO - Epoch [3/5][131/415] lr: 2.4e-05, eta: 1:41:07.585584, loss: 0.6372
2023-04-11 23:59:58 - training - INFO - Epoch [3/5][141/415] lr: 2.4e-05, eta: 1:34:19.100608, loss: 0.6995
2023-04-12 00:00:02 - training - INFO - Epoch [3/5][151/415] lr: 2.4e-05, eta: 1:28:24.244816, loss: 0.5392
2023-04-12 00:00:05 - training - INFO - Epoch [3/5][161/415] lr: 2.4e-05, eta: 1:23:12.965670, loss: 0.9290
2023-04-12 00:00:09 - training - INFO - Epoch [3/5][171/415] lr: 2.3e-05, eta: 1:18:37.681696, loss: 1.0610
2023-04-12 00:00:13 - training - INFO - Epoch [3/5][181/415] lr: 2.3e-05, eta: 1:14:32.404476, loss: 0.5819
2023-04-12 00:00:17 - training - INFO - Epoch [3/5][191/415] lr: 2.3e-05, eta: 1:10:52.449876, loss: 0.5845
2023-04-12 00:00:20 - training - INFO - Epoch [3/5][201/415] lr: 2.3e-05, eta: 1:07:33.986720, loss: 0.7748
2023-04-12 00:00:24 - training - INFO - Epoch [3/5][211/415] lr: 2.3e-05, eta: 1:04:34.072360, loss: 0.4472
2023-04-12 00:00:28 - training - INFO - Epoch [3/5][221/415] lr: 2.2e-05, eta: 1:01:50.031984, loss: 0.8700
2023-04-12 00:00:31 - training - INFO - Epoch [3/5][231/415] lr: 2.2e-05, eta: 0:59:19.871504, loss: 1.1290
2023-04-12 00:00:35 - training - INFO - Epoch [3/5][241/415] lr: 2.2e-05, eta: 0:57:01.842354, loss: 0.4800
2023-04-12 00:00:39 - training - INFO - Epoch [3/5][251/415] lr: 2.2e-05, eta: 0:54:54.559872, loss: 0.4587
2023-04-12 00:00:43 - training - INFO - Epoch [3/5][261/415] lr: 2.2e-05, eta: 0:52:56.733034, loss: 0.4583
2023-04-12 00:00:46 - training - INFO - Epoch [3/5][271/415] lr: 2.1e-05, eta: 0:51:07.362848, loss: 0.5886
2023-04-12 00:00:50 - training - INFO - Epoch [3/5][281/415] lr: 2.1e-05, eta: 0:49:25.503528, loss: 0.5258
2023-04-12 00:00:54 - training - INFO - Epoch [3/5][291/415] lr: 2.1e-05, eta: 0:47:50.395344, loss: 0.6330
2023-04-12 00:00:57 - training - INFO - Epoch [3/5][301/415] lr: 2.1e-05, eta: 0:46:21.353482, loss: 1.1305
2023-04-12 00:01:01 - training - INFO - Epoch [3/5][311/415] lr: 2.0e-05, eta: 0:44:57.762816, loss: 0.5943
2023-04-12 00:01:05 - training - INFO - Epoch [3/5][321/415] lr: 2.0e-05, eta: 0:43:39.148222, loss: 0.7480
2023-04-12 00:01:09 - training - INFO - Epoch [3/5][331/415] lr: 2.0e-05, eta: 0:42:25.104656, loss: 0.9369
2023-04-12 00:01:12 - training - INFO - Epoch [3/5][341/415] lr: 2.0e-05, eta: 0:41:15.139344, loss: 0.9854
2023-04-12 00:01:16 - training - INFO - Epoch [3/5][351/415] lr: 2.0e-05, eta: 0:40:08.953820, loss: 0.9711
2023-04-12 00:01:20 - training - INFO - Epoch [3/5][361/415] lr: 1.9e-05, eta: 0:39:06.226040, loss: 0.8331
2023-04-12 00:01:23 - training - INFO - Epoch [3/5][371/415] lr: 1.9e-05, eta: 0:38:06.691320, loss: 1.0763
2023-04-12 00:01:27 - training - INFO - Epoch [3/5][381/415] lr: 1.9e-05, eta: 0:37:10.067994, loss: 0.6491
2023-04-12 00:01:31 - training - INFO - Epoch [3/5][391/415] lr: 1.9e-05, eta: 0:36:16.201204, loss: 0.3226
2023-04-12 00:01:34 - training - INFO - Epoch [3/5][401/415] lr: 1.8e-05, eta: 0:35:24.814896, loss: 1.1115
2023-04-12 00:01:38 - training - INFO - Epoch [3/5][411/415] lr: 1.8e-05, eta: 0:34:35.740160, loss: 0.7481
2023-04-12 00:01:57 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 0.7581, Validation Metrics: {'exact_match': 81.19349005424955, 'f1': 83.8769795487166}, Test Metrics: {'exact_match': 83.6036036036036, 'f1': 86.03145241999732}
2023-04-12 00:01:57 - training - INFO - Epoch [4/5][1/415] lr: 1.8e-05, eta: 12 days, 18:20:37.107850, loss: 0.3574
2023-04-12 00:02:01 - training - INFO - Epoch [4/5][11/415] lr: 1.8e-05, eta: 1 day, 3:54:29.253696, loss: 0.6081
2023-04-12 00:02:05 - training - INFO - Epoch [4/5][21/415] lr: 1.8e-05, eta: 14:38:54.159790, loss: 0.2838
2023-04-12 00:02:08 - training - INFO - Epoch [4/5][31/415] lr: 1.7e-05, eta: 9:56:33.518264, loss: 1.1350
2023-04-12 00:02:12 - training - INFO - Epoch [4/5][41/415] lr: 1.7e-05, eta: 7:31:54.786180, loss: 0.8573
2023-04-12 00:02:16 - training - INFO - Epoch [4/5][51/415] lr: 1.7e-05, eta: 6:03:58.037056, loss: 0.4619
2023-04-12 00:02:19 - training - INFO - Epoch [4/5][61/415] lr: 1.7e-05, eta: 5:04:50.175238, loss: 0.3960
2023-04-12 00:02:23 - training - INFO - Epoch [4/5][71/415] lr: 1.7e-05, eta: 4:22:20.606376, loss: 0.4795
2023-04-12 00:02:27 - training - INFO - Epoch [4/5][81/415] lr: 1.6e-05, eta: 3:50:19.702142, loss: 0.6386
2023-04-12 00:02:31 - training - INFO - Epoch [4/5][91/415] lr: 1.6e-05, eta: 3:25:20.195584, loss: 0.4992
2023-04-12 00:02:34 - training - INFO - Epoch [4/5][101/415] lr: 1.6e-05, eta: 3:05:16.843542, loss: 0.6401
2023-04-12 00:02:38 - training - INFO - Epoch [4/5][111/415] lr: 1.6e-05, eta: 2:48:49.681556, loss: 1.0071
2023-04-12 00:02:42 - training - INFO - Epoch [4/5][121/415] lr: 1.6e-05, eta: 2:35:05.088688, loss: 0.9312
2023-04-12 00:02:45 - training - INFO - Epoch [4/5][131/415] lr: 1.5e-05, eta: 2:23:25.817784, loss: 0.5718
2023-04-12 00:02:49 - training - INFO - Epoch [4/5][141/415] lr: 1.5e-05, eta: 2:13:25.239876, loss: 1.0000
2023-04-12 00:02:53 - training - INFO - Epoch [4/5][151/415] lr: 1.5e-05, eta: 2:04:43.759712, loss: 0.9815
2023-04-12 00:02:57 - training - INFO - Epoch [4/5][161/415] lr: 1.5e-05, eta: 1:57:06.516024, loss: 0.6173
2023-04-12 00:03:00 - training - INFO - Epoch [4/5][171/415] lr: 1.4e-05, eta: 1:50:22.308112, loss: 0.7830
2023-04-12 00:03:04 - training - INFO - Epoch [4/5][181/415] lr: 1.4e-05, eta: 1:44:22.416300, loss: 0.5504
2023-04-12 00:03:08 - training - INFO - Epoch [4/5][191/415] lr: 1.4e-05, eta: 1:38:59.794188, loss: 0.3880
2023-04-12 00:03:11 - training - INFO - Epoch [4/5][201/415] lr: 1.4e-05, eta: 1:34:08.929380, loss: 0.5759
2023-04-12 00:03:15 - training - INFO - Epoch [4/5][211/415] lr: 1.4e-05, eta: 1:29:45.261896, loss: 0.3206
2023-04-12 00:03:19 - training - INFO - Epoch [4/5][221/415] lr: 1.3e-05, eta: 1:25:45.096582, loss: 0.5447
2023-04-12 00:03:23 - training - INFO - Epoch [4/5][231/415] lr: 1.3e-05, eta: 1:22:05.502868, loss: 0.6106
2023-04-12 00:03:26 - training - INFO - Epoch [4/5][241/415] lr: 1.3e-05, eta: 1:18:43.786116, loss: 0.2590
2023-04-12 00:03:30 - training - INFO - Epoch [4/5][251/415] lr: 1.3e-05, eta: 1:15:37.781856, loss: 0.6331
2023-04-12 00:03:34 - training - INFO - Epoch [4/5][261/415] lr: 1.2e-05, eta: 1:12:45.759242, loss: 0.5359
2023-04-12 00:03:37 - training - INFO - Epoch [4/5][271/415] lr: 1.2e-05, eta: 1:10:06.181144, loss: 0.7297
2023-04-12 00:03:41 - training - INFO - Epoch [4/5][281/415] lr: 1.2e-05, eta: 1:07:37.667406, loss: 0.7323
2023-04-12 00:03:45 - training - INFO - Epoch [4/5][291/415] lr: 1.2e-05, eta: 1:05:19.109040, loss: 0.7027
2023-04-12 00:03:48 - training - INFO - Epoch [4/5][301/415] lr: 1.2e-05, eta: 1:03:09.523004, loss: 0.8035
2023-04-12 00:03:52 - training - INFO - Epoch [4/5][311/415] lr: 1.1e-05, eta: 1:01:08.045724, loss: 0.5256
2023-04-12 00:03:56 - training - INFO - Epoch [4/5][321/415] lr: 1.1e-05, eta: 0:59:13.886394, loss: 0.7371
2023-04-12 00:04:00 - training - INFO - Epoch [4/5][331/415] lr: 1.1e-05, eta: 0:57:26.468384, loss: 0.6659
2023-04-12 00:04:03 - training - INFO - Epoch [4/5][341/415] lr: 1.1e-05, eta: 0:55:45.078474, loss: 0.7823
2023-04-12 00:04:07 - training - INFO - Epoch [4/5][351/415] lr: 1.0e-05, eta: 0:54:09.240040, loss: 0.6575
2023-04-12 00:04:11 - training - INFO - Epoch [4/5][361/415] lr: 1.0e-05, eta: 0:52:38.530062, loss: 0.8146
2023-04-12 00:04:14 - training - INFO - Epoch [4/5][371/415] lr: 1.0e-05, eta: 0:51:12.525000, loss: 0.6602
2023-04-12 00:04:18 - training - INFO - Epoch [4/5][381/415] lr: 9.8e-06, eta: 0:49:50.828148, loss: 0.3204
2023-04-12 00:04:22 - training - INFO - Epoch [4/5][391/415] lr: 9.6e-06, eta: 0:48:33.112868, loss: 0.7957
2023-04-12 00:04:26 - training - INFO - Epoch [4/5][401/415] lr: 9.4e-06, eta: 0:47:19.083912, loss: 1.3167
2023-04-12 00:04:29 - training - INFO - Epoch [4/5][411/415] lr: 9.2e-06, eta: 0:46:08.499968, loss: 0.3766
2023-04-12 00:04:48 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 0.6471, Validation Metrics: {'exact_match': 81.73598553345388, 'f1': 84.28824555108993}, Test Metrics: {'exact_match': 81.44144144144144, 'f1': 83.47671086525577}
2023-04-12 00:04:48 - training - INFO - Epoch [5/5][1/415] lr: 9.1e-06, eta: 16 days, 20:52:24.536164, loss: 0.6089
2023-04-12 00:04:52 - training - INFO - Epoch [5/5][11/415] lr: 8.8e-06, eta: 1 day, 12:49:19.372128, loss: 0.4149
2023-04-12 00:04:56 - training - INFO - Epoch [5/5][21/415] lr: 8.6e-06, eta: 19:17:41.701634, loss: 0.5530
2023-04-12 00:04:59 - training - INFO - Epoch [5/5][31/415] lr: 8.4e-06, eta: 13:04:30.198812, loss: 0.6122
2023-04-12 00:05:03 - training - INFO - Epoch [5/5][41/415] lr: 8.2e-06, eta: 9:53:19.617180, loss: 0.3716
2023-04-12 00:05:07 - training - INFO - Epoch [5/5][51/415] lr: 8.0e-06, eta: 7:57:05.697144, loss: 0.6039
2023-04-12 00:05:11 - training - INFO - Epoch [5/5][61/415] lr: 7.7e-06, eta: 6:38:57.104970, loss: 0.7064
2023-04-12 00:05:14 - training - INFO - Epoch [5/5][71/415] lr: 7.5e-06, eta: 5:42:48.278448, loss: 0.6486
2023-04-12 00:05:18 - training - INFO - Epoch [5/5][81/415] lr: 7.3e-06, eta: 5:00:30.507714, loss: 0.5441
2023-04-12 00:05:22 - training - INFO - Epoch [5/5][91/415] lr: 7.1e-06, eta: 4:27:29.675136, loss: 0.4915
2023-04-12 00:05:25 - training - INFO - Epoch [5/5][101/415] lr: 6.9e-06, eta: 4:01:00.229056, loss: 0.7184
2023-04-12 00:05:29 - training - INFO - Epoch [5/5][111/415] lr: 6.7e-06, eta: 3:39:16.610140, loss: 0.6317
2023-04-12 00:05:33 - training - INFO - Epoch [5/5][121/415] lr: 6.4e-06, eta: 3:21:07.706646, loss: 0.4437
2023-04-12 00:05:36 - training - INFO - Epoch [5/5][131/415] lr: 6.2e-06, eta: 3:05:44.627352, loss: 0.6562
2023-04-12 00:05:40 - training - INFO - Epoch [5/5][141/415] lr: 6.0e-06, eta: 2:52:31.812360, loss: 0.7219
2023-04-12 00:05:44 - training - INFO - Epoch [5/5][151/415] lr: 5.8e-06, eta: 2:41:03.478552, loss: 0.6800
2023-04-12 00:05:48 - training - INFO - Epoch [5/5][161/415] lr: 5.6e-06, eta: 2:31:00.213756, loss: 0.5446
2023-04-12 00:05:51 - training - INFO - Epoch [5/5][171/415] lr: 5.3e-06, eta: 2:22:07.071616, loss: 0.6337
2023-04-12 00:05:55 - training - INFO - Epoch [5/5][181/415] lr: 5.1e-06, eta: 2:14:12.539870, loss: 0.7079
2023-04-12 00:05:59 - training - INFO - Epoch [5/5][191/415] lr: 4.9e-06, eta: 2:07:07.202556, loss: 0.4673
2023-04-12 00:06:02 - training - INFO - Epoch [5/5][201/415] lr: 4.7e-06, eta: 2:00:43.783962, loss: 0.5588
2023-04-12 00:06:06 - training - INFO - Epoch [5/5][211/415] lr: 4.5e-06, eta: 1:54:56.376872, loss: 0.4512
2023-04-12 00:06:10 - training - INFO - Epoch [5/5][221/415] lr: 4.2e-06, eta: 1:49:40.081458, loss: 0.6533
2023-04-12 00:06:14 - training - INFO - Epoch [5/5][231/415] lr: 4.0e-06, eta: 1:44:50.857632, loss: 0.4169
2023-04-12 00:06:17 - training - INFO - Epoch [5/5][241/415] lr: 3.8e-06, eta: 1:40:25.317228, loss: 0.6579
2023-04-12 00:06:21 - training - INFO - Epoch [5/5][251/415] lr: 3.6e-06, eta: 1:36:20.660928, loss: 0.5900
2023-04-12 00:06:25 - training - INFO - Epoch [5/5][261/415] lr: 3.4e-06, eta: 1:32:34.486140, loss: 0.4468
2023-04-12 00:06:28 - training - INFO - Epoch [5/5][271/415] lr: 3.2e-06, eta: 1:29:04.739664, loss: 0.4615
2023-04-12 00:06:32 - training - INFO - Epoch [5/5][281/415] lr: 2.9e-06, eta: 1:25:49.696734, loss: 0.4844
2023-04-12 00:06:36 - training - INFO - Epoch [5/5][291/415] lr: 2.7e-06, eta: 1:22:47.767432, loss: 0.4150
2023-04-12 00:06:40 - training - INFO - Epoch [5/5][301/415] lr: 2.5e-06, eta: 1:19:57.646402, loss: 0.5771
2023-04-12 00:06:43 - training - INFO - Epoch [5/5][311/415] lr: 2.3e-06, eta: 1:17:18.219264, loss: 0.5409
2023-04-12 00:06:47 - training - INFO - Epoch [5/5][321/415] lr: 2.1e-06, eta: 1:14:48.505294, loss: 0.6083
2023-04-12 00:06:51 - training - INFO - Epoch [5/5][331/415] lr: 1.8e-06, eta: 1:12:27.610624, loss: 0.4584
2023-04-12 00:06:54 - training - INFO - Epoch [5/5][341/415] lr: 1.6e-06, eta: 1:10:14.766174, loss: 0.5849
2023-04-12 00:06:58 - training - INFO - Epoch [5/5][351/415] lr: 1.4e-06, eta: 1:08:09.265936, loss: 0.6620
2023-04-12 00:07:02 - training - INFO - Epoch [5/5][361/415] lr: 1.2e-06, eta: 1:06:10.539276, loss: 0.5605
2023-04-12 00:07:05 - training - INFO - Epoch [5/5][371/415] lr: 9.6e-07, eta: 1:04:18.021288, loss: 0.2465
2023-04-12 00:07:09 - training - INFO - Epoch [5/5][381/415] lr: 7.4e-07, eta: 1:02:31.196988, loss: 0.2989
2023-04-12 00:07:13 - training - INFO - Epoch [5/5][391/415] lr: 5.3e-07, eta: 1:00:49.649000, loss: 0.9537
2023-04-12 00:07:17 - training - INFO - Epoch [5/5][401/415] lr: 3.1e-07, eta: 0:59:12.972930, loss: 0.6235
2023-04-12 00:07:20 - training - INFO - Epoch [5/5][411/415] lr: 8.8e-08, eta: 0:57:40.835456, loss: 0.6297
2023-04-12 00:07:39 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.5690, Validation Metrics: {'exact_match': 80.28933092224231, 'f1': 82.55382395531541}, Test Metrics: {'exact_match': 80.90090090090091, 'f1': 83.05043438634772}
2023-04-12 00:07:48 - training - INFO - Final Test - Train Loss: 0.5690, Test Metrics: {'exact_match': 80.90090090090091, 'f1': 83.05043438634772}
