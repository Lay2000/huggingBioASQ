2023-04-12 02:35:20 - datasets.builder - WARNING - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-44a167365c0b341b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
{'model': {'model_checkpoint': 'csarron/bert-base-uncased-squad-v1'}, 'data': {'task_type': 'list', 'max_length': 384, 'stride': 128}, 'hyperparameters': {'batch_size': 16, 'train_epochs': 5, 'lr': 4.54e-05, 'optimizer': 'AdamW', 'scheduler': 'linear', 'num_warmup_steps': 0}, 'others': {'n_best': 20, 'max_answer_length': 30, 'output_dir': 'models/bert_list_squad'}}
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 574.85it/s]
Map:   0%|          | 0/6878 [00:00<?, ? examples/s]Map:  15%|█▍        | 1000/6878 [00:00<00:03, 1640.09 examples/s]Map:  29%|██▉       | 2000/6878 [00:01<00:02, 1710.78 examples/s]Map:  44%|████▎     | 3000/6878 [00:01<00:02, 1698.80 examples/s]Map:  58%|█████▊    | 4000/6878 [00:02<00:01, 1723.30 examples/s]Map:  73%|███████▎  | 5000/6878 [00:02<00:01, 1729.10 examples/s]Map:  87%|████████▋ | 6000/6878 [00:03<00:00, 1741.04 examples/s]Map: 100%|██████████| 6878/6878 [00:04<00:00, 1597.22 examples/s]                                                                 Map:   0%|          | 0/859 [00:00<?, ? examples/s]Map: 100%|██████████| 859/859 [00:00<00:00, 1311.79 examples/s]                                                               Map:   0%|          | 0/861 [00:00<?, ? examples/s]Map: 100%|██████████| 861/861 [00:00<00:00, 1341.53 examples/s]                                                               2023-04-12 02:36:00 - training - INFO - First Test - Val Metrics:{'exact_match': 10.360884749708964, 'f1': 25.683471365640195} Test Metrics: {'exact_match': 11.962833914053427, 'f1': 27.032146761225512}
2023-04-12 02:36:01 - training - INFO - Epoch [1/5][1/649] lr: 4.5e-05, eta: 1 day, 0:50:24.652236, loss: 5.1497
2023-04-12 02:36:04 - training - INFO - Epoch [1/5][11/649] lr: 4.5e-05, eta: 2:33:06.189936, loss: 2.7367
2023-04-12 02:36:08 - training - INFO - Epoch [1/5][21/649] lr: 4.5e-05, eta: 1:29:22.550128, loss: 2.6196
2023-04-12 02:36:12 - training - INFO - Epoch [1/5][31/649] lr: 4.5e-05, eta: 1:06:44.383666, loss: 2.6062
2023-04-12 02:36:16 - training - INFO - Epoch [1/5][41/649] lr: 4.5e-05, eta: 0:55:06.954132, loss: 2.1819
2023-04-12 02:36:19 - training - INFO - Epoch [1/5][51/649] lr: 4.5e-05, eta: 0:48:01.182834, loss: 1.7224
2023-04-12 02:36:23 - training - INFO - Epoch [1/5][61/649] lr: 4.5e-05, eta: 0:43:14.001616, loss: 3.1754
2023-04-12 02:36:27 - training - INFO - Epoch [1/5][71/649] lr: 4.4e-05, eta: 0:39:46.879740, loss: 1.4131
2023-04-12 02:36:30 - training - INFO - Epoch [1/5][81/649] lr: 4.4e-05, eta: 0:37:10.059972, loss: 2.2788
2023-04-12 02:36:34 - training - INFO - Epoch [1/5][91/649] lr: 4.4e-05, eta: 0:35:06.581832, loss: 2.2919
2023-04-12 02:36:38 - training - INFO - Epoch [1/5][101/649] lr: 4.4e-05, eta: 0:33:26.711448, loss: 2.3053
2023-04-12 02:36:41 - training - INFO - Epoch [1/5][111/649] lr: 4.4e-05, eta: 0:32:04.203918, loss: 2.6788
2023-04-12 02:36:45 - training - INFO - Epoch [1/5][121/649] lr: 4.4e-05, eta: 0:30:54.778156, loss: 2.1645
2023-04-12 02:36:49 - training - INFO - Epoch [1/5][131/649] lr: 4.4e-05, eta: 0:29:55.277052, loss: 1.8431
2023-04-12 02:36:52 - training - INFO - Epoch [1/5][141/649] lr: 4.3e-05, eta: 0:29:03.786848, loss: 1.8175
2023-04-12 02:36:56 - training - INFO - Epoch [1/5][151/649] lr: 4.3e-05, eta: 0:28:18.655504, loss: 1.8799
2023-04-12 02:37:00 - training - INFO - Epoch [1/5][161/649] lr: 4.3e-05, eta: 0:27:38.544360, loss: 1.7131
2023-04-12 02:37:03 - training - INFO - Epoch [1/5][171/649] lr: 4.3e-05, eta: 0:27:02.789192, loss: 1.7721
2023-04-12 02:37:07 - training - INFO - Epoch [1/5][181/649] lr: 4.3e-05, eta: 0:26:30.648024, loss: 2.1298
2023-04-12 02:37:11 - training - INFO - Epoch [1/5][191/649] lr: 4.3e-05, eta: 0:26:01.433850, loss: 1.8851
2023-04-12 02:37:15 - training - INFO - Epoch [1/5][201/649] lr: 4.3e-05, eta: 0:25:34.793932, loss: 2.6532
2023-04-12 02:37:18 - training - INFO - Epoch [1/5][211/649] lr: 4.2e-05, eta: 0:25:10.237214, loss: 2.3928
2023-04-12 02:37:22 - training - INFO - Epoch [1/5][221/649] lr: 4.2e-05, eta: 0:24:47.605392, loss: 2.0583
2023-04-12 02:37:26 - training - INFO - Epoch [1/5][231/649] lr: 4.2e-05, eta: 0:24:26.630484, loss: 2.5590
2023-04-12 02:37:29 - training - INFO - Epoch [1/5][241/649] lr: 4.2e-05, eta: 0:24:07.065852, loss: 2.6874
2023-04-12 02:37:33 - training - INFO - Epoch [1/5][251/649] lr: 4.2e-05, eta: 0:23:48.790692, loss: 1.3757
2023-04-12 02:37:37 - training - INFO - Epoch [1/5][261/649] lr: 4.2e-05, eta: 0:23:31.721448, loss: 2.6781
2023-04-12 02:37:40 - training - INFO - Epoch [1/5][271/649] lr: 4.2e-05, eta: 0:23:15.594110, loss: 1.8462
2023-04-12 02:37:44 - training - INFO - Epoch [1/5][281/649] lr: 4.1e-05, eta: 0:23:00.346656, loss: 2.6102
2023-04-12 02:37:48 - training - INFO - Epoch [1/5][291/649] lr: 4.1e-05, eta: 0:22:45.840980, loss: 1.6197
2023-04-12 02:37:51 - training - INFO - Epoch [1/5][301/649] lr: 4.1e-05, eta: 0:22:32.084992, loss: 2.4001
2023-04-12 02:37:55 - training - INFO - Epoch [1/5][311/649] lr: 4.1e-05, eta: 0:22:19.004250, loss: 1.6534
2023-04-12 02:37:59 - training - INFO - Epoch [1/5][321/649] lr: 4.1e-05, eta: 0:22:06.495992, loss: 1.9371
2023-04-12 02:38:03 - training - INFO - Epoch [1/5][331/649] lr: 4.1e-05, eta: 0:21:54.482088, loss: 1.3771
2023-04-12 02:38:06 - training - INFO - Epoch [1/5][341/649] lr: 4.1e-05, eta: 0:21:42.987048, loss: 1.7347
2023-04-12 02:38:10 - training - INFO - Epoch [1/5][351/649] lr: 4.0e-05, eta: 0:21:31.953950, loss: 1.5818
2023-04-12 02:38:14 - training - INFO - Epoch [1/5][361/649] lr: 4.0e-05, eta: 0:21:21.349664, loss: 2.0676
2023-04-12 02:38:17 - training - INFO - Epoch [1/5][371/649] lr: 4.0e-05, eta: 0:21:11.193192, loss: 1.6191
2023-04-12 02:38:21 - training - INFO - Epoch [1/5][381/649] lr: 4.0e-05, eta: 0:21:01.337104, loss: 1.4722
2023-04-12 02:38:25 - training - INFO - Epoch [1/5][391/649] lr: 4.0e-05, eta: 0:20:51.772962, loss: 2.0510
2023-04-12 02:38:28 - training - INFO - Epoch [1/5][401/649] lr: 4.0e-05, eta: 0:20:42.503784, loss: 1.8940
2023-04-12 02:38:32 - training - INFO - Epoch [1/5][411/649] lr: 4.0e-05, eta: 0:20:33.492832, loss: 1.7802
2023-04-12 02:38:36 - training - INFO - Epoch [1/5][421/649] lr: 4.0e-05, eta: 0:20:24.754680, loss: 2.1506
2023-04-12 02:38:39 - training - INFO - Epoch [1/5][431/649] lr: 3.9e-05, eta: 0:20:16.298034, loss: 2.0665
2023-04-12 02:38:43 - training - INFO - Epoch [1/5][441/649] lr: 3.9e-05, eta: 0:20:08.050124, loss: 1.7435
2023-04-12 02:38:47 - training - INFO - Epoch [1/5][451/649] lr: 3.9e-05, eta: 0:19:59.986678, loss: 1.5042
2023-04-12 02:38:51 - training - INFO - Epoch [1/5][461/649] lr: 3.9e-05, eta: 0:19:52.106016, loss: 2.0977
2023-04-12 02:38:54 - training - INFO - Epoch [1/5][471/649] lr: 3.9e-05, eta: 0:19:44.387040, loss: 1.5357
2023-04-12 02:38:58 - training - INFO - Epoch [1/5][481/649] lr: 3.9e-05, eta: 0:19:36.833808, loss: 1.2906
2023-04-12 02:39:02 - training - INFO - Epoch [1/5][491/649] lr: 3.9e-05, eta: 0:19:29.450298, loss: 1.0064
2023-04-12 02:39:05 - training - INFO - Epoch [1/5][501/649] lr: 3.8e-05, eta: 0:19:22.212968, loss: 1.6862
2023-04-12 02:39:09 - training - INFO - Epoch [1/5][511/649] lr: 3.8e-05, eta: 0:19:15.136872, loss: 1.9782
2023-04-12 02:39:13 - training - INFO - Epoch [1/5][521/649] lr: 3.8e-05, eta: 0:19:08.174172, loss: 1.9105
2023-04-12 02:39:17 - training - INFO - Epoch [1/5][531/649] lr: 3.8e-05, eta: 0:19:01.356416, loss: 2.1772
2023-04-12 02:39:20 - training - INFO - Epoch [1/5][541/649] lr: 3.8e-05, eta: 0:18:54.636256, loss: 2.4890
2023-04-12 02:39:24 - training - INFO - Epoch [1/5][551/649] lr: 3.8e-05, eta: 0:18:48.031680, loss: 1.4948
2023-04-12 02:39:28 - training - INFO - Epoch [1/5][561/649] lr: 3.8e-05, eta: 0:18:41.533556, loss: 1.2393
2023-04-12 02:39:31 - training - INFO - Epoch [1/5][571/649] lr: 3.7e-05, eta: 0:18:35.130198, loss: 1.3537
2023-04-12 02:39:35 - training - INFO - Epoch [1/5][581/649] lr: 3.7e-05, eta: 0:18:28.820736, loss: 1.3735
2023-04-12 02:39:39 - training - INFO - Epoch [1/5][591/649] lr: 3.7e-05, eta: 0:18:22.585722, loss: 2.2635
2023-04-12 02:39:42 - training - INFO - Epoch [1/5][601/649] lr: 3.7e-05, eta: 0:18:16.466800, loss: 1.8257
2023-04-12 02:39:46 - training - INFO - Epoch [1/5][611/649] lr: 3.7e-05, eta: 0:18:10.441758, loss: 1.9364
2023-04-12 02:39:50 - training - INFO - Epoch [1/5][621/649] lr: 3.7e-05, eta: 0:18:04.501824, loss: 1.5774
2023-04-12 02:39:54 - training - INFO - Epoch [1/5][631/649] lr: 3.7e-05, eta: 0:17:58.614820, loss: 2.2611
2023-04-12 02:39:57 - training - INFO - Epoch [1/5][641/649] lr: 3.6e-05, eta: 0:17:52.785504, loss: 1.8893
2023-04-12 02:40:27 - training - INFO - Epoch [1/5][Evaluation] - Train Loss: 1.9862, Validation Metrics: {'exact_match': 35.273573923166474, 'f1': 43.65433589822416}, Test Metrics: {'exact_match': 38.443670150987224, 'f1': 46.37219584968261}
2023-04-12 02:40:28 - training - INFO - Epoch [2/5][1/649] lr: 3.6e-05, eta: 11 days, 1:24:02.519176, loss: 1.4419
2023-04-12 02:40:31 - training - INFO - Epoch [2/5][11/649] lr: 3.6e-05, eta: 1 day, 0:21:17.090424, loss: 1.4748
2023-04-12 02:40:35 - training - INFO - Epoch [2/5][21/649] lr: 3.6e-05, eta: 12:52:32.524816, loss: 0.9711
2023-04-12 02:40:39 - training - INFO - Epoch [2/5][31/649] lr: 3.6e-05, eta: 8:48:06.957774, loss: 1.1823
2023-04-12 02:40:43 - training - INFO - Epoch [2/5][41/649] lr: 3.6e-05, eta: 6:42:53.718624, loss: 1.9718
2023-04-12 02:40:46 - training - INFO - Epoch [2/5][51/649] lr: 3.6e-05, eta: 5:26:45.142504, loss: 1.3987
2023-04-12 02:40:50 - training - INFO - Epoch [2/5][61/649] lr: 3.5e-05, eta: 4:35:33.378496, loss: 1.2101
2023-04-12 02:40:54 - training - INFO - Epoch [2/5][71/649] lr: 3.5e-05, eta: 3:58:46.058484, loss: 1.2829
2023-04-12 02:40:57 - training - INFO - Epoch [2/5][81/649] lr: 3.5e-05, eta: 3:31:02.869044, loss: 1.3943
2023-04-12 02:41:01 - training - INFO - Epoch [2/5][91/649] lr: 3.5e-05, eta: 3:09:24.426566, loss: 1.4459
2023-04-12 02:41:05 - training - INFO - Epoch [2/5][101/649] lr: 3.5e-05, eta: 2:52:02.273904, loss: 2.1067
2023-04-12 02:41:09 - training - INFO - Epoch [2/5][111/649] lr: 3.5e-05, eta: 2:37:47.187200, loss: 0.9803
2023-04-12 02:41:12 - training - INFO - Epoch [2/5][121/649] lr: 3.5e-05, eta: 2:25:52.916920, loss: 1.0349
2023-04-12 02:41:16 - training - INFO - Epoch [2/5][131/649] lr: 3.4e-05, eta: 2:15:47.011842, loss: 1.5784
2023-04-12 02:41:20 - training - INFO - Epoch [2/5][141/649] lr: 3.4e-05, eta: 2:07:06.667680, loss: 1.2788
2023-04-12 02:41:23 - training - INFO - Epoch [2/5][151/649] lr: 3.4e-05, eta: 1:59:34.862240, loss: 1.3517
2023-04-12 02:41:27 - training - INFO - Epoch [2/5][161/649] lr: 3.4e-05, eta: 1:52:58.567236, loss: 1.7813
2023-04-12 02:41:31 - training - INFO - Epoch [2/5][171/649] lr: 3.4e-05, eta: 1:47:08.121324, loss: 1.3183
2023-04-12 02:41:34 - training - INFO - Epoch [2/5][181/649] lr: 3.4e-05, eta: 1:41:56.044272, loss: 1.4098
2023-04-12 02:41:38 - training - INFO - Epoch [2/5][191/649] lr: 3.4e-05, eta: 1:37:16.190946, loss: 1.5567
2023-04-12 02:41:42 - training - INFO - Epoch [2/5][201/649] lr: 3.4e-05, eta: 1:33:03.843588, loss: 0.9827
2023-04-12 02:41:46 - training - INFO - Epoch [2/5][211/649] lr: 3.3e-05, eta: 1:29:15.286094, loss: 1.5277
2023-04-12 02:41:49 - training - INFO - Epoch [2/5][221/649] lr: 3.3e-05, eta: 1:25:46.944768, loss: 1.7268
2023-04-12 02:41:53 - training - INFO - Epoch [2/5][231/649] lr: 3.3e-05, eta: 1:22:36.281880, loss: 0.9949
2023-04-12 02:41:57 - training - INFO - Epoch [2/5][241/649] lr: 3.3e-05, eta: 1:19:41.145372, loss: 1.5911
2023-04-12 02:42:00 - training - INFO - Epoch [2/5][251/649] lr: 3.3e-05, eta: 1:16:59.658168, loss: 1.7579
2023-04-12 02:42:04 - training - INFO - Epoch [2/5][261/649] lr: 3.3e-05, eta: 1:14:30.354272, loss: 1.0495
2023-04-12 02:42:08 - training - INFO - Epoch [2/5][271/649] lr: 3.3e-05, eta: 1:12:11.970036, loss: 1.6011
2023-04-12 02:42:12 - training - INFO - Epoch [2/5][281/649] lr: 3.2e-05, eta: 1:10:02.889756, loss: 0.9727
2023-04-12 02:42:15 - training - INFO - Epoch [2/5][291/649] lr: 3.2e-05, eta: 1:08:02.448678, loss: 1.3436
2023-04-12 02:42:19 - training - INFO - Epoch [2/5][301/649] lr: 3.2e-05, eta: 1:06:09.783808, loss: 1.3983
2023-04-12 02:42:23 - training - INFO - Epoch [2/5][311/649] lr: 3.2e-05, eta: 1:04:24.066264, loss: 1.2528
2023-04-12 02:42:27 - training - INFO - Epoch [2/5][321/649] lr: 3.2e-05, eta: 1:02:44.851756, loss: 1.5034
2023-04-12 02:42:30 - training - INFO - Epoch [2/5][331/649] lr: 3.2e-05, eta: 1:01:11.293234, loss: 1.4714
2023-04-12 02:42:34 - training - INFO - Epoch [2/5][341/649] lr: 3.2e-05, eta: 0:59:43.068456, loss: 1.4761
2023-04-12 02:42:38 - training - INFO - Epoch [2/5][351/649] lr: 3.1e-05, eta: 0:58:19.610016, loss: 1.3043
2023-04-12 02:42:41 - training - INFO - Epoch [2/5][361/649] lr: 3.1e-05, eta: 0:57:00.556664, loss: 1.7701
2023-04-12 02:42:45 - training - INFO - Epoch [2/5][371/649] lr: 3.1e-05, eta: 0:55:45.588912, loss: 1.6916
2023-04-12 02:42:49 - training - INFO - Epoch [2/5][381/649] lr: 3.1e-05, eta: 0:54:34.365376, loss: 0.9208
2023-04-12 02:42:53 - training - INFO - Epoch [2/5][391/649] lr: 3.1e-05, eta: 0:53:26.560328, loss: 0.9683
2023-04-12 02:42:56 - training - INFO - Epoch [2/5][401/649] lr: 3.1e-05, eta: 0:52:21.934596, loss: 1.3894
2023-04-12 02:43:00 - training - INFO - Epoch [2/5][411/649] lr: 3.1e-05, eta: 0:51:20.302940, loss: 2.4550
2023-04-12 02:43:04 - training - INFO - Epoch [2/5][421/649] lr: 3.0e-05, eta: 0:50:21.431488, loss: 1.1834
2023-04-12 02:43:07 - training - INFO - Epoch [2/5][431/649] lr: 3.0e-05, eta: 0:49:25.120242, loss: 1.5114
2023-04-12 02:43:11 - training - INFO - Epoch [2/5][441/649] lr: 3.0e-05, eta: 0:48:31.202528, loss: 1.5323
2023-04-12 02:43:15 - training - INFO - Epoch [2/5][451/649] lr: 3.0e-05, eta: 0:47:39.482978, loss: 1.6526
2023-04-12 02:43:18 - training - INFO - Epoch [2/5][461/649] lr: 3.0e-05, eta: 0:46:49.849440, loss: 1.5224
2023-04-12 02:43:22 - training - INFO - Epoch [2/5][471/649] lr: 3.0e-05, eta: 0:46:02.146698, loss: 1.2302
2023-04-12 02:43:26 - training - INFO - Epoch [2/5][481/649] lr: 3.0e-05, eta: 0:45:16.274012, loss: 1.2741
2023-04-12 02:43:30 - training - INFO - Epoch [2/5][491/649] lr: 2.9e-05, eta: 0:44:32.120826, loss: 1.5664
2023-04-12 02:43:33 - training - INFO - Epoch [2/5][501/649] lr: 2.9e-05, eta: 0:43:49.586176, loss: 1.5957
2023-04-12 02:43:37 - training - INFO - Epoch [2/5][511/649] lr: 2.9e-05, eta: 0:43:08.562136, loss: 0.9349
2023-04-12 02:43:41 - training - INFO - Epoch [2/5][521/649] lr: 2.9e-05, eta: 0:42:28.999344, loss: 1.8278
2023-04-12 02:43:44 - training - INFO - Epoch [2/5][531/649] lr: 2.9e-05, eta: 0:41:50.767538, loss: 1.6645
2023-04-12 02:43:48 - training - INFO - Epoch [2/5][541/649] lr: 2.9e-05, eta: 0:41:13.803072, loss: 1.2574
2023-04-12 02:43:52 - training - INFO - Epoch [2/5][551/649] lr: 2.9e-05, eta: 0:40:38.053836, loss: 0.9648
2023-04-12 02:43:56 - training - INFO - Epoch [2/5][561/649] lr: 2.8e-05, eta: 0:40:03.433428, loss: 1.2517
2023-04-12 02:43:59 - training - INFO - Epoch [2/5][571/649] lr: 2.8e-05, eta: 0:39:29.877958, loss: 1.5694
2023-04-12 02:44:03 - training - INFO - Epoch [2/5][581/649] lr: 2.8e-05, eta: 0:38:57.364296, loss: 1.1077
2023-04-12 02:44:07 - training - INFO - Epoch [2/5][591/649] lr: 2.8e-05, eta: 0:38:25.829702, loss: 1.2815
2023-04-12 02:44:10 - training - INFO - Epoch [2/5][601/649] lr: 2.8e-05, eta: 0:37:55.230744, loss: 0.9802
2023-04-12 02:44:14 - training - INFO - Epoch [2/5][611/649] lr: 2.8e-05, eta: 0:37:25.506072, loss: 1.3201
2023-04-12 02:44:18 - training - INFO - Epoch [2/5][621/649] lr: 2.8e-05, eta: 0:36:56.631872, loss: 1.4797
2023-04-12 02:44:22 - training - INFO - Epoch [2/5][631/649] lr: 2.7e-05, eta: 0:36:28.555816, loss: 1.1215
2023-04-12 02:44:25 - training - INFO - Epoch [2/5][641/649] lr: 2.7e-05, eta: 0:36:01.239276, loss: 1.0041
2023-04-12 02:44:55 - training - INFO - Epoch [2/5][Evaluation] - Train Loss: 1.4559, Validation Metrics: {'exact_match': 40.51222351571595, 'f1': 47.25249061772379}, Test Metrics: {'exact_match': 38.908246225319395, 'f1': 45.53983118443049}
2023-04-12 02:44:56 - training - INFO - Epoch [3/5][1/649] lr: 2.7e-05, eta: 21 days, 2:51:13.389696, loss: 1.3980
2023-04-12 02:44:59 - training - INFO - Epoch [3/5][11/649] lr: 2.7e-05, eta: 1 day, 22:14:14.523312, loss: 1.0524
2023-04-12 02:45:03 - training - INFO - Epoch [3/5][21/649] lr: 2.7e-05, eta: 1 day, 0:18:09.662208, loss: 0.9641
2023-04-12 02:45:07 - training - INFO - Epoch [3/5][31/649] lr: 2.7e-05, eta: 16:31:07.317832, loss: 0.5791
2023-04-12 02:45:10 - training - INFO - Epoch [3/5][41/649] lr: 2.7e-05, eta: 12:31:52.992840, loss: 1.2364
2023-04-12 02:45:14 - training - INFO - Epoch [3/5][51/649] lr: 2.7e-05, eta: 10:06:26.185342, loss: 0.9887
2023-04-12 02:45:18 - training - INFO - Epoch [3/5][61/649] lr: 2.6e-05, eta: 8:28:39.356400, loss: 1.1878
2023-04-12 02:45:22 - training - INFO - Epoch [3/5][71/649] lr: 2.6e-05, eta: 7:18:24.305994, loss: 1.3302
2023-04-12 02:45:25 - training - INFO - Epoch [3/5][81/649] lr: 2.6e-05, eta: 6:25:29.292452, loss: 1.2083
2023-04-12 02:45:29 - training - INFO - Epoch [3/5][91/649] lr: 2.6e-05, eta: 5:44:11.215558, loss: 0.9482
2023-04-12 02:45:33 - training - INFO - Epoch [3/5][101/649] lr: 2.6e-05, eta: 5:11:03.000936, loss: 1.1851
2023-04-12 02:45:36 - training - INFO - Epoch [3/5][111/649] lr: 2.6e-05, eta: 4:43:52.230708, loss: 0.8138
2023-04-12 02:45:40 - training - INFO - Epoch [3/5][121/649] lr: 2.6e-05, eta: 4:21:10.355756, loss: 1.0447
2023-04-12 02:45:44 - training - INFO - Epoch [3/5][131/649] lr: 2.5e-05, eta: 4:01:55.873632, loss: 1.0378
2023-04-12 02:45:48 - training - INFO - Epoch [3/5][141/649] lr: 2.5e-05, eta: 3:45:24.652576, loss: 1.4421
2023-04-12 02:45:51 - training - INFO - Epoch [3/5][151/649] lr: 2.5e-05, eta: 3:31:04.196818, loss: 1.3507
2023-04-12 02:45:55 - training - INFO - Epoch [3/5][161/649] lr: 2.5e-05, eta: 3:18:30.235296, loss: 1.2904
2023-04-12 02:45:59 - training - INFO - Epoch [3/5][171/649] lr: 2.5e-05, eta: 3:07:23.994202, loss: 0.7142
2023-04-12 02:46:02 - training - INFO - Epoch [3/5][181/649] lr: 2.5e-05, eta: 2:57:30.932792, loss: 0.8985
2023-04-12 02:46:06 - training - INFO - Epoch [3/5][191/649] lr: 2.5e-05, eta: 2:48:39.566430, loss: 0.8712
2023-04-12 02:46:10 - training - INFO - Epoch [3/5][201/649] lr: 2.4e-05, eta: 2:40:40.810688, loss: 0.8314
2023-04-12 02:46:14 - training - INFO - Epoch [3/5][211/649] lr: 2.4e-05, eta: 2:33:26.982468, loss: 1.2358
2023-04-12 02:46:17 - training - INFO - Epoch [3/5][221/649] lr: 2.4e-05, eta: 2:26:52.120464, loss: 1.5306
2023-04-12 02:46:21 - training - INFO - Epoch [3/5][231/649] lr: 2.4e-05, eta: 2:20:51.099272, loss: 0.7963
2023-04-12 02:46:25 - training - INFO - Epoch [3/5][241/649] lr: 2.4e-05, eta: 2:15:19.736900, loss: 0.8845
2023-04-12 02:46:28 - training - INFO - Epoch [3/5][251/649] lr: 2.4e-05, eta: 2:10:14.513652, loss: 1.0681
2023-04-12 02:46:32 - training - INFO - Epoch [3/5][261/649] lr: 2.4e-05, eta: 2:05:32.448536, loss: 1.1068
2023-04-12 02:46:36 - training - INFO - Epoch [3/5][271/649] lr: 2.3e-05, eta: 2:01:10.856018, loss: 1.1620
2023-04-12 02:46:39 - training - INFO - Epoch [3/5][281/649] lr: 2.3e-05, eta: 1:57:07.617324, loss: 1.6816
2023-04-12 02:46:43 - training - INFO - Epoch [3/5][291/649] lr: 2.3e-05, eta: 1:53:20.846500, loss: 1.0500
2023-04-12 02:46:47 - training - INFO - Epoch [3/5][301/649] lr: 2.3e-05, eta: 1:49:48.925184, loss: 1.3043
2023-04-12 02:46:51 - training - INFO - Epoch [3/5][311/649] lr: 2.3e-05, eta: 1:46:30.351756, loss: 1.1343
2023-04-12 02:46:54 - training - INFO - Epoch [3/5][321/649] lr: 2.3e-05, eta: 1:43:23.953140, loss: 1.5317
2023-04-12 02:46:58 - training - INFO - Epoch [3/5][331/649] lr: 2.3e-05, eta: 1:40:28.602674, loss: 1.6476
2023-04-12 02:47:02 - training - INFO - Epoch [3/5][341/649] lr: 2.2e-05, eta: 1:37:43.295064, loss: 1.4234
2023-04-12 02:47:05 - training - INFO - Epoch [3/5][351/649] lr: 2.2e-05, eta: 1:35:07.159004, loss: 1.1965
2023-04-12 02:47:09 - training - INFO - Epoch [3/5][361/649] lr: 2.2e-05, eta: 1:32:39.498336, loss: 1.1779
2023-04-12 02:47:13 - training - INFO - Epoch [3/5][371/649] lr: 2.2e-05, eta: 1:30:19.602390, loss: 1.3086
2023-04-12 02:47:17 - training - INFO - Epoch [3/5][381/649] lr: 2.2e-05, eta: 1:28:06.843760, loss: 1.3003
2023-04-12 02:47:20 - training - INFO - Epoch [3/5][391/649] lr: 2.2e-05, eta: 1:26:00.668442, loss: 0.7801
2023-04-12 02:47:24 - training - INFO - Epoch [3/5][401/649] lr: 2.2e-05, eta: 1:24:00.617436, loss: 1.1219
2023-04-12 02:47:28 - training - INFO - Epoch [3/5][411/649] lr: 2.1e-05, eta: 1:22:06.243010, loss: 1.1086
2023-04-12 02:47:31 - training - INFO - Epoch [3/5][421/649] lr: 2.1e-05, eta: 1:20:17.086008, loss: 1.1463
2023-04-12 02:47:35 - training - INFO - Epoch [3/5][431/649] lr: 2.1e-05, eta: 1:18:32.881572, loss: 1.3814
2023-04-12 02:47:39 - training - INFO - Epoch [3/5][441/649] lr: 2.1e-05, eta: 1:16:53.230528, loss: 1.5863
2023-04-12 02:47:42 - training - INFO - Epoch [3/5][451/649] lr: 2.1e-05, eta: 1:15:17.822562, loss: 0.8490
2023-04-12 02:47:46 - training - INFO - Epoch [3/5][461/649] lr: 2.1e-05, eta: 1:13:46.409664, loss: 1.1310
2023-04-12 02:47:50 - training - INFO - Epoch [3/5][471/649] lr: 2.1e-05, eta: 1:12:18.710762, loss: 1.2049
2023-04-12 02:47:54 - training - INFO - Epoch [3/5][481/649] lr: 2.1e-05, eta: 1:10:54.473180, loss: 1.3038
2023-04-12 02:47:57 - training - INFO - Epoch [3/5][491/649] lr: 2.0e-05, eta: 1:09:33.579594, loss: 1.5665
2023-04-12 02:48:01 - training - INFO - Epoch [3/5][501/649] lr: 2.0e-05, eta: 1:08:15.716352, loss: 0.9020
2023-04-12 02:48:05 - training - INFO - Epoch [3/5][511/649] lr: 2.0e-05, eta: 1:07:00.773504, loss: 1.4255
2023-04-12 02:48:08 - training - INFO - Epoch [3/5][521/649] lr: 2.0e-05, eta: 1:05:48.557856, loss: 0.9985
2023-04-12 02:48:12 - training - INFO - Epoch [3/5][531/649] lr: 2.0e-05, eta: 1:04:38.922078, loss: 1.2706
2023-04-12 02:48:16 - training - INFO - Epoch [3/5][541/649] lr: 2.0e-05, eta: 1:03:31.715232, loss: 1.2924
2023-04-12 02:48:20 - training - INFO - Epoch [3/5][551/649] lr: 2.0e-05, eta: 1:02:26.858304, loss: 1.1224
2023-04-12 02:48:23 - training - INFO - Epoch [3/5][561/649] lr: 1.9e-05, eta: 1:01:24.165760, loss: 0.7923
2023-04-12 02:48:27 - training - INFO - Epoch [3/5][571/649] lr: 1.9e-05, eta: 1:00:23.513334, loss: 1.2437
2023-04-12 02:48:31 - training - INFO - Epoch [3/5][581/649] lr: 1.9e-05, eta: 0:59:24.810288, loss: 1.1177
2023-04-12 02:48:34 - training - INFO - Epoch [3/5][591/649] lr: 1.9e-05, eta: 0:58:27.966964, loss: 1.0558
2023-04-12 02:48:38 - training - INFO - Epoch [3/5][601/649] lr: 1.9e-05, eta: 0:57:32.894784, loss: 1.1174
2023-04-12 02:48:42 - training - INFO - Epoch [3/5][611/649] lr: 1.9e-05, eta: 0:56:39.506250, loss: 1.2226
2023-04-12 02:48:45 - training - INFO - Epoch [3/5][621/649] lr: 1.9e-05, eta: 0:55:47.738560, loss: 1.0674
2023-04-12 02:48:49 - training - INFO - Epoch [3/5][631/649] lr: 1.8e-05, eta: 0:54:57.482580, loss: 1.0227
2023-04-12 02:48:53 - training - INFO - Epoch [3/5][641/649] lr: 1.8e-05, eta: 0:54:08.685300, loss: 1.2129
2023-04-12 02:49:23 - training - INFO - Epoch [3/5][Evaluation] - Train Loss: 1.2088, Validation Metrics: {'exact_match': 36.90337601862631, 'f1': 42.87912385118437}, Test Metrics: {'exact_match': 38.79210220673635, 'f1': 43.88294696657066}
2023-04-12 02:49:24 - training - INFO - Epoch [4/5][1/649] lr: 1.8e-05, eta: 31 days, 4:11:33.307052, loss: 1.0701
2023-04-12 02:49:27 - training - INFO - Epoch [4/5][11/649] lr: 1.8e-05, eta: 2 days, 20:06:33.038244, loss: 1.0907
2023-04-12 02:49:31 - training - INFO - Epoch [4/5][21/649] lr: 1.8e-05, eta: 1 day, 11:43:25.447048, loss: 0.8972
2023-04-12 02:49:35 - training - INFO - Epoch [4/5][31/649] lr: 1.8e-05, eta: 1 day, 0:13:53.504150, loss: 1.4777
2023-04-12 02:49:38 - training - INFO - Epoch [4/5][41/649] lr: 1.8e-05, eta: 18:20:41.139564, loss: 1.3827
2023-04-12 02:49:42 - training - INFO - Epoch [4/5][51/649] lr: 1.7e-05, eta: 14:45:58.185966, loss: 0.9148
2023-04-12 02:49:46 - training - INFO - Epoch [4/5][61/649] lr: 1.7e-05, eta: 12:21:38.342240, loss: 0.7298
2023-04-12 02:49:49 - training - INFO - Epoch [4/5][71/649] lr: 1.7e-05, eta: 10:37:56.453076, loss: 0.9943
2023-04-12 02:49:53 - training - INFO - Epoch [4/5][81/649] lr: 1.7e-05, eta: 9:19:50.140892, loss: 0.5155
2023-04-12 02:49:57 - training - INFO - Epoch [4/5][91/649] lr: 1.7e-05, eta: 8:18:52.936072, loss: 0.9124
2023-04-12 02:50:01 - training - INFO - Epoch [4/5][101/649] lr: 1.7e-05, eta: 7:29:59.188032, loss: 0.9386
2023-04-12 02:50:04 - training - INFO - Epoch [4/5][111/649] lr: 1.7e-05, eta: 6:49:53.416262, loss: 1.0052
2023-04-12 02:50:08 - training - INFO - Epoch [4/5][121/649] lr: 1.6e-05, eta: 6:16:24.586244, loss: 1.4285
2023-04-12 02:50:12 - training - INFO - Epoch [4/5][131/649] lr: 1.6e-05, eta: 5:48:01.830060, loss: 1.0857
2023-04-12 02:50:15 - training - INFO - Epoch [4/5][141/649] lr: 1.6e-05, eta: 5:23:40.117024, loss: 1.0284
2023-04-12 02:50:19 - training - INFO - Epoch [4/5][151/649] lr: 1.6e-05, eta: 5:02:31.591458, loss: 0.7560
2023-04-12 02:50:23 - training - INFO - Epoch [4/5][161/649] lr: 1.6e-05, eta: 4:44:00.139308, loss: 1.5659
2023-04-12 02:50:26 - training - INFO - Epoch [4/5][171/649] lr: 1.6e-05, eta: 4:27:38.327006, loss: 0.9620
2023-04-12 02:50:30 - training - INFO - Epoch [4/5][181/649] lr: 1.6e-05, eta: 4:13:04.727464, loss: 1.4878
2023-04-12 02:50:34 - training - INFO - Epoch [4/5][191/649] lr: 1.5e-05, eta: 4:00:01.982958, loss: 0.6496
2023-04-12 02:50:38 - training - INFO - Epoch [4/5][201/649] lr: 1.5e-05, eta: 3:48:16.992436, loss: 1.7072
2023-04-12 02:50:41 - training - INFO - Epoch [4/5][211/649] lr: 1.5e-05, eta: 3:37:38.360272, loss: 1.2506
2023-04-12 02:50:45 - training - INFO - Epoch [4/5][221/649] lr: 1.5e-05, eta: 3:27:57.093552, loss: 0.8079
2023-04-12 02:50:49 - training - INFO - Epoch [4/5][231/649] lr: 1.5e-05, eta: 3:19:05.823230, loss: 0.8697
2023-04-12 02:50:52 - training - INFO - Epoch [4/5][241/649] lr: 1.5e-05, eta: 3:10:58.352460, loss: 0.9072
2023-04-12 02:50:56 - training - INFO - Epoch [4/5][251/649] lr: 1.5e-05, eta: 3:03:29.461950, loss: 1.2549
2023-04-12 02:51:00 - training - INFO - Epoch [4/5][261/649] lr: 1.5e-05, eta: 2:56:34.686032, loss: 1.0688
2023-04-12 02:51:04 - training - INFO - Epoch [4/5][271/649] lr: 1.4e-05, eta: 2:50:10.256502, loss: 1.3465
2023-04-12 02:51:07 - training - INFO - Epoch [4/5][281/649] lr: 1.4e-05, eta: 2:44:12.931764, loss: 1.5058
2023-04-12 02:51:11 - training - INFO - Epoch [4/5][291/649] lr: 1.4e-05, eta: 2:38:39.876478, loss: 0.7073
2023-04-12 02:51:15 - training - INFO - Epoch [4/5][301/649] lr: 1.4e-05, eta: 2:33:28.693632, loss: 0.9191
2023-04-12 02:51:18 - training - INFO - Epoch [4/5][311/649] lr: 1.4e-05, eta: 2:28:37.291530, loss: 1.1889
2023-04-12 02:51:22 - training - INFO - Epoch [4/5][321/649] lr: 1.4e-05, eta: 2:24:03.785524, loss: 1.5123
2023-04-12 02:51:26 - training - INFO - Epoch [4/5][331/649] lr: 1.4e-05, eta: 2:19:46.605646, loss: 0.8717
2023-04-12 02:51:30 - training - INFO - Epoch [4/5][341/649] lr: 1.3e-05, eta: 2:15:44.273808, loss: 1.3224
2023-04-12 02:51:33 - training - INFO - Epoch [4/5][351/649] lr: 1.3e-05, eta: 2:11:55.558828, loss: 1.1668
2023-04-12 02:51:37 - training - INFO - Epoch [4/5][361/649] lr: 1.3e-05, eta: 2:08:19.331164, loss: 0.8061
2023-04-12 02:51:41 - training - INFO - Epoch [4/5][371/649] lr: 1.3e-05, eta: 2:04:54.547044, loss: 1.8379
2023-04-12 02:51:44 - training - INFO - Epoch [4/5][381/649] lr: 1.3e-05, eta: 2:01:40.327408, loss: 0.8443
2023-04-12 02:51:48 - training - INFO - Epoch [4/5][391/649] lr: 1.3e-05, eta: 1:58:35.866784, loss: 1.0586
2023-04-12 02:51:52 - training - INFO - Epoch [4/5][401/649] lr: 1.3e-05, eta: 1:55:40.378152, loss: 0.6468
2023-04-12 02:51:55 - training - INFO - Epoch [4/5][411/649] lr: 1.2e-05, eta: 1:52:53.254332, loss: 0.8410
2023-04-12 02:51:59 - training - INFO - Epoch [4/5][421/649] lr: 1.2e-05, eta: 1:50:13.901192, loss: 1.3187
2023-04-12 02:52:03 - training - INFO - Epoch [4/5][431/649] lr: 1.2e-05, eta: 1:47:41.762874, loss: 1.1993
2023-04-12 02:52:07 - training - INFO - Epoch [4/5][441/649] lr: 1.2e-05, eta: 1:45:16.382932, loss: 0.8923
2023-04-12 02:52:10 - training - INFO - Epoch [4/5][451/649] lr: 1.2e-05, eta: 1:42:57.268570, loss: 1.0900
2023-04-12 02:52:14 - training - INFO - Epoch [4/5][461/649] lr: 1.2e-05, eta: 1:40:44.030592, loss: 1.2699
2023-04-12 02:52:18 - training - INFO - Epoch [4/5][471/649] lr: 1.2e-05, eta: 1:38:36.281788, loss: 0.8193
2023-04-12 02:52:21 - training - INFO - Epoch [4/5][481/649] lr: 1.1e-05, eta: 1:36:33.683972, loss: 1.3215
2023-04-12 02:52:25 - training - INFO - Epoch [4/5][491/649] lr: 1.1e-05, eta: 1:34:35.933412, loss: 0.8186
2023-04-12 02:52:29 - training - INFO - Epoch [4/5][501/649] lr: 1.1e-05, eta: 1:32:42.757536, loss: 1.1124
2023-04-12 02:52:33 - training - INFO - Epoch [4/5][511/649] lr: 1.1e-05, eta: 1:30:53.837880, loss: 1.2637
2023-04-12 02:52:36 - training - INFO - Epoch [4/5][521/649] lr: 1.1e-05, eta: 1:29:08.966256, loss: 0.9566
2023-04-12 02:52:40 - training - INFO - Epoch [4/5][531/649] lr: 1.1e-05, eta: 1:27:27.923386, loss: 0.8073
2023-04-12 02:52:44 - training - INFO - Epoch [4/5][541/649] lr: 1.1e-05, eta: 1:25:50.449408, loss: 1.1073
2023-04-12 02:52:47 - training - INFO - Epoch [4/5][551/649] lr: 1.0e-05, eta: 1:24:16.379376, loss: 1.3175
2023-04-12 02:52:51 - training - INFO - Epoch [4/5][561/649] lr: 1.0e-05, eta: 1:22:45.542252, loss: 0.7914
2023-04-12 02:52:55 - training - INFO - Epoch [4/5][571/649] lr: 1.0e-05, eta: 1:21:17.777100, loss: 1.6564
2023-04-12 02:52:59 - training - INFO - Epoch [4/5][581/649] lr: 1.0e-05, eta: 1:19:52.898304, loss: 1.3223
2023-04-12 02:53:02 - training - INFO - Epoch [4/5][591/649] lr: 9.9e-06, eta: 1:18:30.757110, loss: 1.1789
2023-04-12 02:53:06 - training - INFO - Epoch [4/5][601/649] lr: 9.8e-06, eta: 1:17:11.222468, loss: 0.9905
2023-04-12 02:53:10 - training - INFO - Epoch [4/5][611/649] lr: 9.6e-06, eta: 1:15:54.170196, loss: 0.7518
2023-04-12 02:53:13 - training - INFO - Epoch [4/5][621/649] lr: 9.5e-06, eta: 1:14:39.485504, loss: 1.1126
2023-04-12 02:53:17 - training - INFO - Epoch [4/5][631/649] lr: 9.3e-06, eta: 1:13:27.057616, loss: 1.0486
2023-04-12 02:53:21 - training - INFO - Epoch [4/5][641/649] lr: 9.2e-06, eta: 1:12:16.766700, loss: 0.6454
2023-04-12 02:53:51 - training - INFO - Epoch [4/5][Evaluation] - Train Loss: 1.0530, Validation Metrics: {'exact_match': 37.60186263096624, 'f1': 43.448041304244164}, Test Metrics: {'exact_match': 37.86295005807201, 'f1': 43.62840400410467}
2023-04-12 02:53:51 - training - INFO - Epoch [5/5][1/649] lr: 9.1e-06, eta: 41 days, 5:24:11.217172, loss: 1.0824
2023-04-12 02:53:55 - training - INFO - Epoch [5/5][11/649] lr: 8.9e-06, eta: 3 days, 17:58:12.211566, loss: 0.7077
2023-04-12 02:53:59 - training - INFO - Epoch [5/5][21/649] lr: 8.8e-06, eta: 1 day, 23:08:21.017408, loss: 1.1640
2023-04-12 02:54:02 - training - INFO - Epoch [5/5][31/649] lr: 8.6e-06, eta: 1 day, 7:56:25.834914, loss: 0.7797
2023-04-12 02:54:06 - training - INFO - Epoch [5/5][41/649] lr: 8.5e-06, eta: 1 day, 0:09:19.424376, loss: 1.0540
2023-04-12 02:54:10 - training - INFO - Epoch [5/5][51/649] lr: 8.4e-06, eta: 19:25:22.591258, loss: 0.6488
2023-04-12 02:54:13 - training - INFO - Epoch [5/5][61/649] lr: 8.2e-06, eta: 16:14:30.195920, loss: 0.8834
2023-04-12 02:54:17 - training - INFO - Epoch [5/5][71/649] lr: 8.1e-06, eta: 13:57:22.661604, loss: 0.8578
2023-04-12 02:54:21 - training - INFO - Epoch [5/5][81/649] lr: 7.9e-06, eta: 12:14:05.987048, loss: 0.8400
2023-04-12 02:54:25 - training - INFO - Epoch [5/5][91/649] lr: 7.8e-06, eta: 10:53:30.351376, loss: 1.1737
2023-04-12 02:54:28 - training - INFO - Epoch [5/5][101/649] lr: 7.7e-06, eta: 9:48:51.583464, loss: 1.1338
2023-04-12 02:54:32 - training - INFO - Epoch [5/5][111/649] lr: 7.5e-06, eta: 8:55:50.925634, loss: 1.4703
2023-04-12 02:54:36 - training - INFO - Epoch [5/5][121/649] lr: 7.4e-06, eta: 8:11:35.320976, loss: 0.9481
2023-04-12 02:54:39 - training - INFO - Epoch [5/5][131/649] lr: 7.2e-06, eta: 7:34:04.878012, loss: 1.2495
2023-04-12 02:54:43 - training - INFO - Epoch [5/5][141/649] lr: 7.1e-06, eta: 7:01:52.933760, loss: 0.7675
2023-04-12 02:54:47 - training - INFO - Epoch [5/5][151/649] lr: 7.0e-06, eta: 6:33:56.374762, loss: 1.4186
2023-04-12 02:54:50 - training - INFO - Epoch [5/5][161/649] lr: 6.8e-06, eta: 6:09:27.674808, loss: 1.0803
2023-04-12 02:54:54 - training - INFO - Epoch [5/5][171/649] lr: 6.7e-06, eta: 5:47:50.280534, loss: 0.6771
2023-04-12 02:54:58 - training - INFO - Epoch [5/5][181/649] lr: 6.5e-06, eta: 5:28:35.847264, loss: 0.9242
2023-04-12 02:55:02 - training - INFO - Epoch [5/5][191/649] lr: 6.4e-06, eta: 5:11:21.995988, loss: 0.6682
2023-04-12 02:55:05 - training - INFO - Epoch [5/5][201/649] lr: 6.3e-06, eta: 4:55:50.559388, loss: 1.0808
2023-04-12 02:55:09 - training - INFO - Epoch [5/5][211/649] lr: 6.1e-06, eta: 4:41:47.052986, loss: 0.6542
2023-04-12 02:55:13 - training - INFO - Epoch [5/5][221/649] lr: 6.0e-06, eta: 4:28:59.577888, loss: 0.9742
2023-04-12 02:55:16 - training - INFO - Epoch [5/5][231/649] lr: 5.8e-06, eta: 4:17:18.214352, loss: 1.3881
2023-04-12 02:55:20 - training - INFO - Epoch [5/5][241/649] lr: 5.7e-06, eta: 4:06:34.727036, loss: 0.9696
2023-04-12 02:55:24 - training - INFO - Epoch [5/5][251/649] lr: 5.6e-06, eta: 3:56:42.206664, loss: 0.9106
2023-04-12 02:55:28 - training - INFO - Epoch [5/5][261/649] lr: 5.4e-06, eta: 3:47:34.822792, loss: 0.8045
2023-04-12 02:55:31 - training - INFO - Epoch [5/5][271/649] lr: 5.3e-06, eta: 3:39:07.596004, loss: 0.8823
2023-04-12 02:55:35 - training - INFO - Epoch [5/5][281/649] lr: 5.1e-06, eta: 3:31:16.201044, loss: 0.8487
2023-04-12 02:55:39 - training - INFO - Epoch [5/5][291/649] lr: 5.0e-06, eta: 3:23:56.918414, loss: 0.4802
2023-04-12 02:55:42 - training - INFO - Epoch [5/5][301/649] lr: 4.9e-06, eta: 3:17:06.589696, loss: 0.6695
2023-04-12 02:55:46 - training - INFO - Epoch [5/5][311/649] lr: 4.7e-06, eta: 3:10:42.388752, loss: 0.9654
2023-04-12 02:55:50 - training - INFO - Epoch [5/5][321/649] lr: 4.6e-06, eta: 3:04:41.886900, loss: 0.8498
2023-04-12 02:55:53 - training - INFO - Epoch [5/5][331/649] lr: 4.4e-06, eta: 2:59:02.985520, loss: 0.8309
2023-04-12 02:55:57 - training - INFO - Epoch [5/5][341/649] lr: 4.3e-06, eta: 2:53:43.704720, loss: 0.9315
2023-04-12 02:56:01 - training - INFO - Epoch [5/5][351/649] lr: 4.2e-06, eta: 2:48:42.401680, loss: 0.8029
2023-04-12 02:56:05 - training - INFO - Epoch [5/5][361/649] lr: 4.0e-06, eta: 2:43:57.600864, loss: 0.5700
2023-04-12 02:56:08 - training - INFO - Epoch [5/5][371/649] lr: 3.9e-06, eta: 2:39:27.982848, loss: 1.0970
2023-04-12 02:56:12 - training - INFO - Epoch [5/5][381/649] lr: 3.7e-06, eta: 2:35:12.296000, loss: 0.9235
2023-04-12 02:56:16 - training - INFO - Epoch [5/5][391/649] lr: 3.6e-06, eta: 2:31:09.526820, loss: 0.8148
2023-04-12 02:56:19 - training - INFO - Epoch [5/5][401/649] lr: 3.5e-06, eta: 2:27:18.662832, loss: 0.8175
2023-04-12 02:56:23 - training - INFO - Epoch [5/5][411/649] lr: 3.3e-06, eta: 2:23:38.820314, loss: 0.6240
2023-04-12 02:56:27 - training - INFO - Epoch [5/5][421/649] lr: 3.2e-06, eta: 2:20:09.287432, loss: 0.8086
2023-04-12 02:56:31 - training - INFO - Epoch [5/5][431/649] lr: 3.0e-06, eta: 2:16:49.299084, loss: 1.1988
2023-04-12 02:56:34 - training - INFO - Epoch [5/5][441/649] lr: 2.9e-06, eta: 2:13:38.206240, loss: 0.8511
2023-04-12 02:56:38 - training - INFO - Epoch [5/5][451/649] lr: 2.8e-06, eta: 2:10:35.420956, loss: 0.5666
2023-04-12 02:56:42 - training - INFO - Epoch [5/5][461/649] lr: 2.6e-06, eta: 2:07:40.418208, loss: 1.0492
2023-04-12 02:56:45 - training - INFO - Epoch [5/5][471/649] lr: 2.5e-06, eta: 2:04:52.679412, loss: 0.9138
2023-04-12 02:56:49 - training - INFO - Epoch [5/5][481/649] lr: 2.4e-06, eta: 2:02:11.758760, loss: 0.6285
2023-04-12 02:56:53 - training - INFO - Epoch [5/5][491/649] lr: 2.2e-06, eta: 1:59:37.215924, loss: 1.0370
2023-04-12 02:56:57 - training - INFO - Epoch [5/5][501/649] lr: 2.1e-06, eta: 1:57:08.709352, loss: 0.8289
2023-04-12 02:57:00 - training - INFO - Epoch [5/5][511/649] lr: 1.9e-06, eta: 1:54:45.855134, loss: 0.8215
2023-04-12 02:57:04 - training - INFO - Epoch [5/5][521/649] lr: 1.8e-06, eta: 1:52:28.350432, loss: 0.8723
2023-04-12 02:57:08 - training - INFO - Epoch [5/5][531/649] lr: 1.7e-06, eta: 1:50:15.882518, loss: 1.0780
2023-04-12 02:57:11 - training - INFO - Epoch [5/5][541/649] lr: 1.5e-06, eta: 1:48:08.174992, loss: 0.8168
2023-04-12 02:57:15 - training - INFO - Epoch [5/5][551/649] lr: 1.4e-06, eta: 1:46:04.973712, loss: 0.8733
2023-04-12 02:57:19 - training - INFO - Epoch [5/5][561/649] lr: 1.2e-06, eta: 1:44:06.049128, loss: 1.6872
2023-04-12 02:57:22 - training - INFO - Epoch [5/5][571/649] lr: 1.1e-06, eta: 1:42:11.139728, loss: 0.7301
2023-04-12 02:57:26 - training - INFO - Epoch [5/5][581/649] lr: 9.5e-07, eta: 1:40:20.053920, loss: 1.1080
2023-04-12 02:57:30 - training - INFO - Epoch [5/5][591/649] lr: 8.1e-07, eta: 1:38:32.602432, loss: 0.6782
2023-04-12 02:57:34 - training - INFO - Epoch [5/5][601/649] lr: 6.7e-07, eta: 1:36:48.608888, loss: 0.9288
2023-04-12 02:57:37 - training - INFO - Epoch [5/5][611/649] lr: 5.3e-07, eta: 1:35:07.906974, loss: 0.7396
2023-04-12 02:57:41 - training - INFO - Epoch [5/5][621/649] lr: 3.9e-07, eta: 1:33:30.342912, loss: 1.0963
2023-04-12 02:57:45 - training - INFO - Epoch [5/5][631/649] lr: 2.5e-07, eta: 1:31:55.751734, loss: 1.0901
2023-04-12 02:57:48 - training - INFO - Epoch [5/5][641/649] lr: 1.1e-07, eta: 1:30:24.001800, loss: 1.0553
2023-04-12 02:58:18 - training - INFO - Epoch [5/5][Evaluation] - Train Loss: 0.9564, Validation Metrics: {'exact_match': 36.43771827706636, 'f1': 42.219453034354075}, Test Metrics: {'exact_match': 38.32752613240418, 'f1': 43.24989244849873}
2023-04-12 02:58:32 - training - INFO - Final Test - Train Loss: 0.9564, Test Metrics: {'exact_match': 38.32752613240418, 'f1': 43.24989244849873}
